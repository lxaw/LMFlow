Search.setIndex({"alltitles": {"1 Introduction": [[112, "introduction"]], "1. Decompose your conversations": [[108, "decompose-your-conversations"]], "1. NLL Task Setting": [[106, "nll-task-setting"]], "1.1 Dataset description": [[112, "dataset-description"]], "2 Reward Modeling": [[112, "reward-modeling"]], "2. Choose proper Formatter": [[108, "choose-proper-formatter"]], "2. LM-Evaluation Task Setting": [[106, "lm-evaluation-task-setting"]], "2.1 Supervised Finetuning (SFT)": [[112, "supervised-finetuning-sft"]], "2.2 Reward Modeling": [[112, "id1"]], "2.3 LoRA Merge and Get Reward Model": [[112, "lora-merge-and-get-reward-model"]], "2023": [[104, "id1"]], "3 RAFT Alignment": [[112, "raft-alignment"]], "3. Build the template": [[108, "build-the-template"]], "3.1 Algorithms Overview": [[112, "algorithms-overview"]], "3.2 Hyper-parameters": [[112, "hyper-parameters"]], "3.3 Examples": [[112, "examples"]], "3.3.1 SFT": [[112, "sft"]], "3.3.2 RAFT Alignment": [[112, "id2"]], "3.3.3 End Note": [[112, "end-note"]], "4. Register your template": [[108, "register-your-template"]], "5. Use your template": [[108, "use-your-template"]], "API Reference": [[3, null]], "About": [[2, null]], "Attributes": [[4, "attributes"], [5, "attributes"], [8, "attributes"], [13, "attributes"], [14, "attributes"], [15, "attributes"], [16, "attributes"], [46, "attributes"], [51, "attributes"], [53, "attributes"], [55, "attributes"], [56, "attributes"], [57, "attributes"], [58, "attributes"], [59, "attributes"], [60, "attributes"], [61, "attributes"], [63, "attributes"], [64, "attributes"], [66, "attributes"], [67, "attributes"], [69, "attributes"], [70, "attributes"], [71, "attributes"], [73, "attributes"], [74, "attributes"], [75, "attributes"], [76, "attributes"], [77, "attributes"], [78, "attributes"], [79, "attributes"], [80, "attributes"], [81, "attributes"], [82, "attributes"], [83, "attributes"], [84, "attributes"], [85, "attributes"], [86, "attributes"], [87, "attributes"], [94, "attributes"], [96, "attributes"], [97, "attributes"], [101, "attributes"], [102, "attributes"]], "Blogs": [[104, null]], "Changelog": [[1, null]], "Chat Performance": [[103, "chat-performance"]], "ChatGLM-3": [[114, "chatglm-3"]], "ChatML": [[114, "chatml"]], "Checkpoints": [[107, null], [115, "checkpoints"]], "Citation": [[115, "citation"]], "Classes": [[4, "classes"], [5, "classes"], [6, "classes"], [7, "classes"], [9, "classes"], [10, "classes"], [11, "classes"], [12, "classes"], [13, "classes"], [14, "classes"], [15, "classes"], [16, "classes"], [19, "classes"], [20, "classes"], [21, "classes"], [22, "classes"], [23, "classes"], [25, "classes"], [26, "classes"], [27, "classes"], [28, "classes"], [29, "classes"], [30, "classes"], [31, "classes"], [32, "classes"], [33, "classes"], [34, "classes"], [36, "classes"], [37, "classes"], [38, "classes"], [39, "classes"], [41, "classes"], [42, "classes"], [43, "classes"], [44, "classes"], [45, "classes"], [46, "classes"], [47, "classes"], [48, "classes"], [49, "classes"], [50, "classes"], [51, "classes"], [52, "classes"], [53, "classes"], [55, "classes"], [56, "classes"], [57, "classes"], [58, "classes"], [59, "classes"], [60, "classes"], [61, "classes"], [65, "classes"], [66, "classes"], [67, "classes"], [68, "classes"], [69, "classes"], [75, "classes"], [79, "classes"], [80, "classes"], [81, "classes"], [83, "classes"], [87, "classes"], [88, "classes"], [94, "classes"], [96, "classes"], [100, "classes"]], "CommonSense Performance": [[103, "commonsense-performance"]], "Conclusion": [[103, "conclusion"]], "Content": [[115, "content"]], "Contributors": [[0, null]], "Conversation": [[105, "conversation"]], "Conversation Template": [[105, "conversation-template"], [109, null]], "Create Your Task Dataset File": [[106, "create-your-task-dataset-file"]], "Customize Conversation Template": [[105, "customize-conversation-template"], [108, null]], "Data Format": [[105, "data-format"]], "Data preparation": [[110, "data-preparation"]], "Dataset": [[105, null]], "Dataset Format in General": [[105, "dataset-format-in-general"]], "DeepSeek": [[114, "deepseek"]], "Disclaimer": [[115, "disclaimer"]], "Evaluation": [[110, "evaluation"]], "Examples": [[110, null], [113, "examples"]], "Features": [[115, "features"]], "Finetune": [[111, null]], "Finetuning": [[109, null], [110, "finetuning"]], "Formatted Dataset": [[105, null]], "Full Parameters": [[109, "full-parameters"]], "Functions": [[4, "functions"], [6, "functions"], [7, "functions"], [23, "functions"], [24, "functions"], [33, "functions"], [50, "functions"], [55, "functions"], [63, "functions"], [64, "functions"], [68, "functions"], [70, "functions"], [71, "functions"], [73, "functions"], [88, "functions"], [89, "functions"], [90, "functions"], [91, "functions"], [93, "functions"], [94, "functions"], [97, "functions"], [98, "functions"], [100, "functions"], [101, "functions"]], "Gemma": [[114, "gemma"]], "Hymba": [[114, "hymba"]], "Indices and tables": [[115, "indices-and-tables"]], "Inference": [[110, "inference"]], "Installation": [[115, "installation"]], "Instruction Following": [[103, "instruction-following"]], "Instruction Tuning": [[115, "instruction-tuning"]], "InternLM2": [[114, "internlm2"]], "Introduction": [[103, "introduction"], [113, "introduction"], [115, "introduction"]], "LLaMA Checkpoint": [[107, "llama-checkpoint"]], "LMFlow": [[115, null]], "LMFlow Benchmark Guide": [[106, null]], "LMFlow Benchmark: An Automatic Evaluation Framework for Open-Source LLMs": [[103, null]], "Layerwise Importance Sampled AdamW (LISA)": [[109, "layerwise-importance-sampled-adamw-lisa"]], "Llama-2": [[114, "llama-2"]], "Llama-3": [[114, "llama-3"]], "Low-Rank Adaptation (LoRA)": [[109, "low-rank-adaptation-lora"]], "Merge LoRA Weight": [[109, null]], "Metric": [[103, "metric"]], "Mixtral 8x22B": [[114, "mixtral-8x22b"]], "Mixtral 8x7B": [[114, "mixtral-8x7b"]], "Module Contents": [[4, "module-contents"], [5, "module-contents"], [7, "module-contents"], [9, "module-contents"], [10, "module-contents"], [11, "module-contents"], [12, "module-contents"], [13, "module-contents"], [14, "module-contents"], [15, "module-contents"], [16, "module-contents"], [19, "module-contents"], [20, "module-contents"], [21, "module-contents"], [22, "module-contents"], [23, "module-contents"], [25, "module-contents"], [26, "module-contents"], [27, "module-contents"], [28, "module-contents"], [29, "module-contents"], [30, "module-contents"], [31, "module-contents"], [32, "module-contents"], [33, "module-contents"], [34, "module-contents"], [36, "module-contents"], [37, "module-contents"], [38, "module-contents"], [39, "module-contents"], [41, "module-contents"], [42, "module-contents"], [43, "module-contents"], [44, "module-contents"], [45, "module-contents"], [46, "module-contents"], [47, "module-contents"], [48, "module-contents"], [49, "module-contents"], [50, "module-contents"], [51, "module-contents"], [52, "module-contents"], [53, "module-contents"], [55, "module-contents"], [56, "module-contents"], [57, "module-contents"], [58, "module-contents"], [59, "module-contents"], [60, "module-contents"], [61, "module-contents"], [63, "module-contents"], [64, "module-contents"], [65, "module-contents"], [66, "module-contents"], [67, "module-contents"], [68, "module-contents"], [69, "module-contents"], [70, "module-contents"], [71, "module-contents"], [73, "module-contents"], [74, "module-contents"], [75, "module-contents"], [76, "module-contents"], [77, "module-contents"], [78, "module-contents"], [79, "module-contents"], [80, "module-contents"], [82, "module-contents"], [83, "module-contents"], [84, "module-contents"], [85, "module-contents"], [86, "module-contents"], [87, "module-contents"], [88, "module-contents"], [89, "module-contents"], [90, "module-contents"], [91, "module-contents"], [93, "module-contents"], [94, "module-contents"], [96, "module-contents"], [97, "module-contents"], [98, "module-contents"], [100, "module-contents"], [101, "module-contents"], [102, "module-contents"]], "NOTICE": [[114, null], [114, null], [114, null], [114, null]], "Package Contents": [[6, "package-contents"], [8, "package-contents"], [24, "package-contents"], [81, "package-contents"]], "Paired Conversation": [[105, "paired-conversation"]], "Phi-3": [[114, "phi-3"]], "Qwen-2": [[114, "qwen-2"]], "RAFT": [[112, null]], "References": [[103, "references"]], "Returns": [[15, "returns"]], "Reward Modeling": [[113, null]], "Setup": [[106, "setup"]], "Step 1 Supervised Finetuning (SFT)": [[113, "step-1-supervised-finetuning-sft"]], "Step 2 Reward Modeling": [[113, "step-2-reward-modeling"]], "Submodules": [[6, "submodules"], [8, "submodules"], [17, "submodules"], [18, "submodules"], [24, "submodules"], [35, "submodules"], [54, "submodules"], [62, "submodules"], [72, "submodules"], [81, "submodules"], [92, "submodules"], [95, "submodules"], [99, "submodules"]], "Support": [[115, "support"]], "Supported Conversation Template": [[114, null]], "Supported Dataset and Detailed Formats": [[105, "supported-dataset-and-detailed-formats"]], "Task Registration": [[106, "task-registration"]], "Task Tuning": [[115, "task-tuning"]], "Text2Text": [[105, "text2text"]], "TextOnly": [[105, "textonly"]], "Version 0.0.1 (Mar 28, 2023)": [[1, "version-0-0-1-mar-28-2023"]], "Vision": [[115, "vision"]], "Work in Progress": [[105, null], [114, null], [114, null]], "Yi": [[114, "yi"]], "Yi-1.5": [[114, "yi-1-5"]], "Zephyr": [[114, "zephyr"]], "lmflow": [[8, null]], "lmflow.args": [[4, null]], "lmflow.datasets": [[6, null]], "lmflow.datasets.dataset": [[5, null]], "lmflow.datasets.multi_modal_dataset": [[7, null]], "lmflow.models": [[17, null]], "lmflow.models.auto_model": [[9, null]], "lmflow.models.base_model": [[10, null]], "lmflow.models.decoder_model": [[11, null]], "lmflow.models.encoder_decoder_model": [[12, null]], "lmflow.models.hf_decoder_model": [[13, null]], "lmflow.models.hf_encoder_decoder_model": [[14, null]], "lmflow.models.hf_model_mixin": [[15, null]], "lmflow.models.hf_text_regression_model": [[16, null]], "lmflow.models.interfaces": [[18, null]], "lmflow.models.interfaces.tunable": [[19, null]], "lmflow.models.regression_model": [[20, null]], "lmflow.models.text_regression_model": [[21, null]], "lmflow.models.vision2seq_model": [[22, null]], "lmflow.models.vision_encoder": [[24, null]], "lmflow.models.vision_encoder.clip_encoder": [[23, null]], "lmflow.optim": [[35, null]], "lmflow.optim.adabelief": [[25, null]], "lmflow.optim.adabound": [[26, null]], "lmflow.optim.adadelta": [[27, null]], "lmflow.optim.adagrad": [[28, null]], "lmflow.optim.adam": [[29, null]], "lmflow.optim.adamax": [[30, null]], "lmflow.optim.adamp": [[31, null]], "lmflow.optim.adamw_schedule_free": [[32, null]], "lmflow.optim.adan": [[33, null]], "lmflow.optim.dummy": [[34, null]], "lmflow.optim.lamb": [[36, null]], "lmflow.optim.lars": [[37, null]], "lmflow.optim.nadam": [[38, null]], "lmflow.optim.novograd": [[39, null]], "lmflow.optim.optimizers": [[40, null]], "lmflow.optim.radam": [[41, null]], "lmflow.optim.sgd_schedule_free": [[42, null]], "lmflow.optim.sgdp": [[43, null]], "lmflow.optim.sophia": [[44, null]], "lmflow.optim.yogi": [[45, null]], "lmflow.pipeline": [[54, null]], "lmflow.pipeline.auto_pipeline": [[46, null]], "lmflow.pipeline.base_aligner": [[47, null]], "lmflow.pipeline.base_pipeline": [[48, null]], "lmflow.pipeline.base_tuner": [[49, null]], "lmflow.pipeline.dpo_aligner": [[50, null]], "lmflow.pipeline.dpov2_aligner": [[51, null]], "lmflow.pipeline.evaluator": [[52, null]], "lmflow.pipeline.finetuner": [[53, null]], "lmflow.pipeline.inferencer": [[55, null]], "lmflow.pipeline.iterative_dpo_aligner": [[56, null]], "lmflow.pipeline.raft_aligner": [[57, null]], "lmflow.pipeline.rm_inferencer": [[58, null]], "lmflow.pipeline.rm_tuner": [[59, null]], "lmflow.pipeline.utils": [[62, null]], "lmflow.pipeline.utils.dpov2_dataprocessor": [[60, null]], "lmflow.pipeline.utils.dpov2_trainer": [[61, null]], "lmflow.pipeline.utils.memory_safe_dpov2_align": [[63, null]], "lmflow.pipeline.utils.memory_safe_vllm_inference": [[64, null]], "lmflow.pipeline.utils.peft_trainer": [[65, null]], "lmflow.pipeline.utils.raft_trainer": [[66, null]], "lmflow.pipeline.utils.rm_dataprocessor": [[67, null]], "lmflow.pipeline.utils.rm_trainer": [[68, null]], "lmflow.pipeline.vllm_inferencer": [[69, null]], "lmflow.tokenization": [[72, null]], "lmflow.tokenization.hf_decoder_model": [[70, null]], "lmflow.tokenization.hf_text_regression_model": [[71, null]], "lmflow.utils": [[95, null]], "lmflow.utils.common": [[73, null]], "lmflow.utils.constants": [[74, null]], "lmflow.utils.conversation_template": [[81, null]], "lmflow.utils.conversation_template.base": [[75, null]], "lmflow.utils.conversation_template.chatglm": [[76, null]], "lmflow.utils.conversation_template.chatml": [[77, null]], "lmflow.utils.conversation_template.deepseek": [[78, null]], "lmflow.utils.conversation_template.gemma": [[79, null]], "lmflow.utils.conversation_template.hymba": [[80, null]], "lmflow.utils.conversation_template.internlm": [[82, null]], "lmflow.utils.conversation_template.llama": [[83, null]], "lmflow.utils.conversation_template.phi": [[84, null]], "lmflow.utils.conversation_template.qwen": [[85, null]], "lmflow.utils.conversation_template.yi": [[86, null]], "lmflow.utils.conversation_template.zephyr": [[87, null]], "lmflow.utils.data_utils": [[88, null]], "lmflow.utils.flash_attention": [[92, null]], "lmflow.utils.flash_attention.bloom_flash_attention": [[89, null]], "lmflow.utils.flash_attention.gpt2_flash_attention": [[90, null]], "lmflow.utils.flash_attention.gpt_neo_flash_attention": [[91, null]], "lmflow.utils.flash_attention.llama_flash_attention": [[93, null]], "lmflow.utils.flash_attention.triton_flash_attention": [[94, null]], "lmflow.utils.llava_conversation_lib": [[96, null]], "lmflow.utils.model": [[97, null]], "lmflow.utils.multimodal": [[98, null]], "lmflow.utils.position_interpolation": [[99, null]], "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch": [[100, null]], "lmflow.utils.versioning": [[101, null]], "lmflow.version": [[102, null]], "}": [[75, "id5"], [75, "id10"], [80, "id5"], [81, "id5"], [81, "id10"]]}, "docnames": ["about/authors", "about/changelog", "about/index", "autoapi/index", "autoapi/lmflow/args/index", "autoapi/lmflow/datasets/dataset/index", "autoapi/lmflow/datasets/index", "autoapi/lmflow/datasets/multi_modal_dataset/index", "autoapi/lmflow/index", "autoapi/lmflow/models/auto_model/index", "autoapi/lmflow/models/base_model/index", "autoapi/lmflow/models/decoder_model/index", "autoapi/lmflow/models/encoder_decoder_model/index", "autoapi/lmflow/models/hf_decoder_model/index", "autoapi/lmflow/models/hf_encoder_decoder_model/index", "autoapi/lmflow/models/hf_model_mixin/index", "autoapi/lmflow/models/hf_text_regression_model/index", "autoapi/lmflow/models/index", "autoapi/lmflow/models/interfaces/index", "autoapi/lmflow/models/interfaces/tunable/index", "autoapi/lmflow/models/regression_model/index", "autoapi/lmflow/models/text_regression_model/index", "autoapi/lmflow/models/vision2seq_model/index", "autoapi/lmflow/models/vision_encoder/clip_encoder/index", "autoapi/lmflow/models/vision_encoder/index", "autoapi/lmflow/optim/adabelief/index", "autoapi/lmflow/optim/adabound/index", "autoapi/lmflow/optim/adadelta/index", "autoapi/lmflow/optim/adagrad/index", "autoapi/lmflow/optim/adam/index", "autoapi/lmflow/optim/adamax/index", "autoapi/lmflow/optim/adamp/index", "autoapi/lmflow/optim/adamw_schedule_free/index", "autoapi/lmflow/optim/adan/index", "autoapi/lmflow/optim/dummy/index", "autoapi/lmflow/optim/index", "autoapi/lmflow/optim/lamb/index", "autoapi/lmflow/optim/lars/index", "autoapi/lmflow/optim/nadam/index", "autoapi/lmflow/optim/novograd/index", "autoapi/lmflow/optim/optimizers/index", "autoapi/lmflow/optim/radam/index", "autoapi/lmflow/optim/sgd_schedule_free/index", "autoapi/lmflow/optim/sgdp/index", "autoapi/lmflow/optim/sophia/index", "autoapi/lmflow/optim/yogi/index", "autoapi/lmflow/pipeline/auto_pipeline/index", "autoapi/lmflow/pipeline/base_aligner/index", "autoapi/lmflow/pipeline/base_pipeline/index", "autoapi/lmflow/pipeline/base_tuner/index", "autoapi/lmflow/pipeline/dpo_aligner/index", "autoapi/lmflow/pipeline/dpov2_aligner/index", "autoapi/lmflow/pipeline/evaluator/index", "autoapi/lmflow/pipeline/finetuner/index", "autoapi/lmflow/pipeline/index", "autoapi/lmflow/pipeline/inferencer/index", "autoapi/lmflow/pipeline/iterative_dpo_aligner/index", "autoapi/lmflow/pipeline/raft_aligner/index", "autoapi/lmflow/pipeline/rm_inferencer/index", "autoapi/lmflow/pipeline/rm_tuner/index", "autoapi/lmflow/pipeline/utils/dpov2_dataprocessor/index", "autoapi/lmflow/pipeline/utils/dpov2_trainer/index", "autoapi/lmflow/pipeline/utils/index", "autoapi/lmflow/pipeline/utils/memory_safe_dpov2_align/index", "autoapi/lmflow/pipeline/utils/memory_safe_vllm_inference/index", "autoapi/lmflow/pipeline/utils/peft_trainer/index", "autoapi/lmflow/pipeline/utils/raft_trainer/index", "autoapi/lmflow/pipeline/utils/rm_dataprocessor/index", "autoapi/lmflow/pipeline/utils/rm_trainer/index", "autoapi/lmflow/pipeline/vllm_inferencer/index", "autoapi/lmflow/tokenization/hf_decoder_model/index", "autoapi/lmflow/tokenization/hf_text_regression_model/index", "autoapi/lmflow/tokenization/index", "autoapi/lmflow/utils/common/index", "autoapi/lmflow/utils/constants/index", "autoapi/lmflow/utils/conversation_template/base/index", "autoapi/lmflow/utils/conversation_template/chatglm/index", "autoapi/lmflow/utils/conversation_template/chatml/index", "autoapi/lmflow/utils/conversation_template/deepseek/index", "autoapi/lmflow/utils/conversation_template/gemma/index", "autoapi/lmflow/utils/conversation_template/hymba/index", "autoapi/lmflow/utils/conversation_template/index", "autoapi/lmflow/utils/conversation_template/internlm/index", "autoapi/lmflow/utils/conversation_template/llama/index", "autoapi/lmflow/utils/conversation_template/phi/index", "autoapi/lmflow/utils/conversation_template/qwen/index", "autoapi/lmflow/utils/conversation_template/yi/index", "autoapi/lmflow/utils/conversation_template/zephyr/index", "autoapi/lmflow/utils/data_utils/index", "autoapi/lmflow/utils/flash_attention/bloom_flash_attention/index", "autoapi/lmflow/utils/flash_attention/gpt2_flash_attention/index", "autoapi/lmflow/utils/flash_attention/gpt_neo_flash_attention/index", "autoapi/lmflow/utils/flash_attention/index", "autoapi/lmflow/utils/flash_attention/llama_flash_attention/index", "autoapi/lmflow/utils/flash_attention/triton_flash_attention/index", "autoapi/lmflow/utils/index", "autoapi/lmflow/utils/llava_conversation_lib/index", "autoapi/lmflow/utils/model/index", "autoapi/lmflow/utils/multimodal/index", "autoapi/lmflow/utils/position_interpolation/index", "autoapi/lmflow/utils/position_interpolation/llama_rope_scaled_monkey_patch/index", "autoapi/lmflow/utils/versioning/index", "autoapi/lmflow/version/index", "blogs/benchmark", "blogs/index", "examples/DATASETS", "examples/TASK_GUIDE", "examples/checkpoints", "examples/customize_conversation_template", "examples/finetuning", "examples/index", "examples/medical_finetune", "examples/raft", "examples/reward_modeling", "examples/supported_conversation_template", "index"], "envversion": {"sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1}, "filenames": ["about/authors.md", "about/changelog.md", "about/index.md", "autoapi/index.rst", "autoapi/lmflow/args/index.rst", "autoapi/lmflow/datasets/dataset/index.rst", "autoapi/lmflow/datasets/index.rst", "autoapi/lmflow/datasets/multi_modal_dataset/index.rst", "autoapi/lmflow/index.rst", "autoapi/lmflow/models/auto_model/index.rst", "autoapi/lmflow/models/base_model/index.rst", "autoapi/lmflow/models/decoder_model/index.rst", "autoapi/lmflow/models/encoder_decoder_model/index.rst", "autoapi/lmflow/models/hf_decoder_model/index.rst", "autoapi/lmflow/models/hf_encoder_decoder_model/index.rst", "autoapi/lmflow/models/hf_model_mixin/index.rst", "autoapi/lmflow/models/hf_text_regression_model/index.rst", "autoapi/lmflow/models/index.rst", "autoapi/lmflow/models/interfaces/index.rst", "autoapi/lmflow/models/interfaces/tunable/index.rst", "autoapi/lmflow/models/regression_model/index.rst", "autoapi/lmflow/models/text_regression_model/index.rst", "autoapi/lmflow/models/vision2seq_model/index.rst", "autoapi/lmflow/models/vision_encoder/clip_encoder/index.rst", "autoapi/lmflow/models/vision_encoder/index.rst", "autoapi/lmflow/optim/adabelief/index.rst", "autoapi/lmflow/optim/adabound/index.rst", "autoapi/lmflow/optim/adadelta/index.rst", "autoapi/lmflow/optim/adagrad/index.rst", "autoapi/lmflow/optim/adam/index.rst", "autoapi/lmflow/optim/adamax/index.rst", "autoapi/lmflow/optim/adamp/index.rst", "autoapi/lmflow/optim/adamw_schedule_free/index.rst", "autoapi/lmflow/optim/adan/index.rst", "autoapi/lmflow/optim/dummy/index.rst", "autoapi/lmflow/optim/index.rst", "autoapi/lmflow/optim/lamb/index.rst", "autoapi/lmflow/optim/lars/index.rst", "autoapi/lmflow/optim/nadam/index.rst", "autoapi/lmflow/optim/novograd/index.rst", "autoapi/lmflow/optim/optimizers/index.rst", "autoapi/lmflow/optim/radam/index.rst", "autoapi/lmflow/optim/sgd_schedule_free/index.rst", "autoapi/lmflow/optim/sgdp/index.rst", "autoapi/lmflow/optim/sophia/index.rst", "autoapi/lmflow/optim/yogi/index.rst", "autoapi/lmflow/pipeline/auto_pipeline/index.rst", "autoapi/lmflow/pipeline/base_aligner/index.rst", "autoapi/lmflow/pipeline/base_pipeline/index.rst", "autoapi/lmflow/pipeline/base_tuner/index.rst", "autoapi/lmflow/pipeline/dpo_aligner/index.rst", "autoapi/lmflow/pipeline/dpov2_aligner/index.rst", "autoapi/lmflow/pipeline/evaluator/index.rst", "autoapi/lmflow/pipeline/finetuner/index.rst", "autoapi/lmflow/pipeline/index.rst", "autoapi/lmflow/pipeline/inferencer/index.rst", "autoapi/lmflow/pipeline/iterative_dpo_aligner/index.rst", "autoapi/lmflow/pipeline/raft_aligner/index.rst", "autoapi/lmflow/pipeline/rm_inferencer/index.rst", "autoapi/lmflow/pipeline/rm_tuner/index.rst", "autoapi/lmflow/pipeline/utils/dpov2_dataprocessor/index.rst", "autoapi/lmflow/pipeline/utils/dpov2_trainer/index.rst", "autoapi/lmflow/pipeline/utils/index.rst", "autoapi/lmflow/pipeline/utils/memory_safe_dpov2_align/index.rst", "autoapi/lmflow/pipeline/utils/memory_safe_vllm_inference/index.rst", "autoapi/lmflow/pipeline/utils/peft_trainer/index.rst", "autoapi/lmflow/pipeline/utils/raft_trainer/index.rst", "autoapi/lmflow/pipeline/utils/rm_dataprocessor/index.rst", "autoapi/lmflow/pipeline/utils/rm_trainer/index.rst", "autoapi/lmflow/pipeline/vllm_inferencer/index.rst", "autoapi/lmflow/tokenization/hf_decoder_model/index.rst", "autoapi/lmflow/tokenization/hf_text_regression_model/index.rst", "autoapi/lmflow/tokenization/index.rst", "autoapi/lmflow/utils/common/index.rst", "autoapi/lmflow/utils/constants/index.rst", "autoapi/lmflow/utils/conversation_template/base/index.rst", "autoapi/lmflow/utils/conversation_template/chatglm/index.rst", "autoapi/lmflow/utils/conversation_template/chatml/index.rst", "autoapi/lmflow/utils/conversation_template/deepseek/index.rst", "autoapi/lmflow/utils/conversation_template/gemma/index.rst", "autoapi/lmflow/utils/conversation_template/hymba/index.rst", "autoapi/lmflow/utils/conversation_template/index.rst", "autoapi/lmflow/utils/conversation_template/internlm/index.rst", "autoapi/lmflow/utils/conversation_template/llama/index.rst", "autoapi/lmflow/utils/conversation_template/phi/index.rst", "autoapi/lmflow/utils/conversation_template/qwen/index.rst", "autoapi/lmflow/utils/conversation_template/yi/index.rst", "autoapi/lmflow/utils/conversation_template/zephyr/index.rst", "autoapi/lmflow/utils/data_utils/index.rst", "autoapi/lmflow/utils/flash_attention/bloom_flash_attention/index.rst", "autoapi/lmflow/utils/flash_attention/gpt2_flash_attention/index.rst", "autoapi/lmflow/utils/flash_attention/gpt_neo_flash_attention/index.rst", "autoapi/lmflow/utils/flash_attention/index.rst", "autoapi/lmflow/utils/flash_attention/llama_flash_attention/index.rst", "autoapi/lmflow/utils/flash_attention/triton_flash_attention/index.rst", "autoapi/lmflow/utils/index.rst", "autoapi/lmflow/utils/llava_conversation_lib/index.rst", "autoapi/lmflow/utils/model/index.rst", "autoapi/lmflow/utils/multimodal/index.rst", "autoapi/lmflow/utils/position_interpolation/index.rst", "autoapi/lmflow/utils/position_interpolation/llama_rope_scaled_monkey_patch/index.rst", "autoapi/lmflow/utils/versioning/index.rst", "autoapi/lmflow/version/index.rst", "blogs/benchmark.md", "blogs/index.md", "examples/DATASETS.md", "examples/TASK_GUIDE.md", "examples/checkpoints.md", "examples/customize_conversation_template.md", "examples/finetuning.md", "examples/index.md", "examples/medical_finetune.md", "examples/raft.md", "examples/reward_modeling.md", "examples/supported_conversation_template.md", "index.md"], "indexentries": {"__call__() (lmflow.datasets.multi_modal_dataset.datacollatorforsuperviseddataset method)": [[7, "lmflow.datasets.multi_modal_dataset.DataCollatorForSupervisedDataset.__call__", false]], "__call__() (lmflow.pipeline.utils.dpov2_dataprocessor.preferencedatacollatorwithpadding method)": [[60, "lmflow.pipeline.utils.dpov2_dataprocessor.PreferenceDataCollatorWithPadding.__call__", false]], "__call__() (lmflow.pipeline.utils.rm_dataprocessor.rewarddatacollatorwithpadding method)": [[67, "lmflow.pipeline.utils.rm_dataprocessor.RewardDataCollatorWithPadding.__call__", false]], "__distributed_inference() (lmflow.pipeline.rm_inferencer.rewardmodelinferencer method)": [[58, "lmflow.pipeline.rm_inferencer.RewardModelInferencer.__distributed_inference", false]], "__filter_args() (lmflow.pipeline.iterative_dpo_aligner.iterativedpoaligner method)": [[56, "lmflow.pipeline.iterative_dpo_aligner.IterativeDPOAligner.__filter_args", false]], "__getitem__() (lmflow.datasets.multi_modal_dataset.custommultimodaldataset method)": [[7, "lmflow.datasets.multi_modal_dataset.CustomMultiModalDataset.__getitem__", false]], "__inference() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.__inference", false]], "__inference() (lmflow.models.hf_text_regression_model.hftextregressionmodel method)": [[16, "lmflow.models.hf_text_regression_model.HFTextRegressionModel.__inference", false]], "__inference() (lmflow.pipeline.rm_inferencer.rewardmodelinferencer method)": [[58, "lmflow.pipeline.rm_inferencer.RewardModelInferencer.__inference", false]], "__len__() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.__len__", false]], "__len__() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.__len__", false]], "__len__() (lmflow.datasets.multi_modal_dataset.custommultimodaldataset method)": [[7, "lmflow.datasets.multi_modal_dataset.CustomMultiModalDataset.__len__", false]], "__model_module_inject() (lmflow.models.hf_model_mixin.hfmodelmixin method)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.__model_module_inject", false]], "__post_init__() (lmflow.args.datasetarguments method)": [[4, "lmflow.args.DatasetArguments.__post_init__", false]], "__post_init__() (lmflow.args.inferencerarguments method)": [[4, "lmflow.args.InferencerArguments.__post_init__", false]], "__post_init__() (lmflow.args.modelarguments method)": [[4, "lmflow.args.ModelArguments.__post_init__", false]], "__post_init__() (lmflow.utils.conversation_template.base.conversationtemplate method)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate.__post_init__", false]], "__post_init__() (lmflow.utils.conversation_template.base.emptyformatter method)": [[75, "lmflow.utils.conversation_template.base.EmptyFormatter.__post_init__", false]], "__post_init__() (lmflow.utils.conversation_template.base.stringformatter method)": [[75, "lmflow.utils.conversation_template.base.StringFormatter.__post_init__", false]], "__post_init__() (lmflow.utils.conversation_template.base.templatecomponent method)": [[75, "lmflow.utils.conversation_template.base.TemplateComponent.__post_init__", false]], "__post_init__() (lmflow.utils.conversation_template.conversationtemplate method)": [[81, "lmflow.utils.conversation_template.ConversationTemplate.__post_init__", false]], "__post_process_model_output() (lmflow.pipeline.rm_inferencer.rewardmodelinferencer method)": [[58, "lmflow.pipeline.rm_inferencer.RewardModelInferencer.__post_process_model_output", false]], "__prepare_dtype() (lmflow.models.hf_model_mixin.hfmodelmixin method)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.__prepare_dtype", false]], "__prepare_inputs_for_inference() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.__prepare_inputs_for_inference", false]], "__prepare_inputs_for_vllm_inference() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.__prepare_inputs_for_vllm_inference", false]], "__prepare_model_config() (lmflow.models.hf_model_mixin.hfmodelmixin method)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.__prepare_model_config", false]], "__prepare_model_for_inference() (lmflow.models.hf_model_mixin.hfmodelmixin method)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.__prepare_model_for_inference", false]], "__prepare_model_for_training() (lmflow.models.hf_model_mixin.hfmodelmixin method)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.__prepare_model_for_training", false]], "__prepare_model_for_vllm_inference() (lmflow.models.hf_model_mixin.hfmodelmixin method)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.__prepare_model_for_vllm_inference", false]], "__prepare_model_post_process() (lmflow.models.hf_model_mixin.hfmodelmixin method)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.__prepare_model_post_process", false]], "__prepare_peft_config() (lmflow.models.hf_model_mixin.hfmodelmixin method)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.__prepare_peft_config", false]], "__prepare_quant_config() (lmflow.models.hf_model_mixin.hfmodelmixin method)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.__prepare_quant_config", false]], "__prepare_tokenizer() (lmflow.models.hf_model_mixin.hfmodelmixin method)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.__prepare_tokenizer", false]], "__prepare_training_args() (lmflow.pipeline.dpov2_aligner.dpov2aligner method)": [[51, "lmflow.pipeline.dpov2_aligner.DPOv2Aligner.__prepare_training_args", false]], "__repr__() (lmflow.utils.conversation_template.base.templatecomponent method)": [[75, "lmflow.utils.conversation_template.base.TemplateComponent.__repr__", false]], "__setstate__() (lmflow.optim.adabelief.adabelief method)": [[25, "lmflow.optim.adabelief.AdaBelief.__setstate__", false]], "__setstate__() (lmflow.optim.adabound.adabound method)": [[26, "lmflow.optim.adabound.AdaBound.__setstate__", false]], "__setstate__() (lmflow.optim.adamax.adamax method)": [[30, "lmflow.optim.adamax.Adamax.__setstate__", false]], "__setstate__() (lmflow.optim.adan.adan method)": [[33, "lmflow.optim.adan.Adan.__setstate__", false]], "__setstate__() (lmflow.optim.lars.lars method)": [[37, "lmflow.optim.lars.LARS.__setstate__", false]], "__setstate__() (lmflow.optim.nadam.nadam method)": [[38, "lmflow.optim.nadam.NAdam.__setstate__", false]], "__setstate__() (lmflow.optim.novograd.novograd method)": [[39, "lmflow.optim.novograd.NovoGrad.__setstate__", false]], "__setstate__() (lmflow.optim.radam.radam method)": [[41, "lmflow.optim.radam.RAdam.__setstate__", false]], "__setstate__() (lmflow.optim.sophia.sophiag method)": [[44, "lmflow.optim.sophia.SophiaG.__setstate__", false]], "__str__() (lmflow.utils.conversation_template.base.templatecomponent method)": [[75, "lmflow.utils.conversation_template.base.TemplateComponent.__str__", false]], "__version__ (in module lmflow)": [[8, "lmflow.__version__", false]], "__version__ (in module lmflow.version)": [[102, "lmflow.version.__version__", false]], "__vllm_inference() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.__vllm_inference", false]], "__vllm_inference() (lmflow.models.hf_text_regression_model.hftextregressionmodel method)": [[16, "lmflow.models.hf_text_regression_model.HFTextRegressionModel.__vllm_inference", false]], "__vllm_inference() (lmflow.pipeline.rm_inferencer.rewardmodelinferencer method)": [[58, "lmflow.pipeline.rm_inferencer.RewardModelInferencer.__vllm_inference", false]], "_activated (lmflow.models.hf_model_mixin.hfmodelmixin attribute)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin._activated", false]], "_add_sm_patterns_to_gitignore() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._add_sm_patterns_to_gitignore", false]], "_align_single_iteration() (lmflow.pipeline.iterative_dpo_aligner.iterativedpoaligner method)": [[56, "lmflow.pipeline.iterative_dpo_aligner.IterativeDPOAligner._align_single_iteration", false]], "_attn() (in module lmflow.utils.flash_attention.gpt_neo_flash_attention)": [[91, "lmflow.utils.flash_attention.gpt_neo_flash_attention._attn", false]], "_bwd_kernel() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[94, "lmflow.utils.flash_attention.triton_flash_attention._bwd_kernel", false]], "_bwd_kernel_one_col_block() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[94, "lmflow.utils.flash_attention.triton_flash_attention._bwd_kernel_one_col_block", false]], "_bwd_preprocess_do_o_dot() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[94, "lmflow.utils.flash_attention.triton_flash_attention._bwd_preprocess_do_o_dot", false]], "_bwd_store_dk_dv() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[94, "lmflow.utils.flash_attention.triton_flash_attention._bwd_store_dk_dv", false]], "_calc_response_lengths() (lmflow.pipeline.dpov2_aligner.dpov2aligner method)": [[51, "lmflow.pipeline.dpov2_aligner.DPOv2Aligner._calc_response_lengths", false]], "_calc_reward_with_length_penalty() (lmflow.pipeline.dpov2_aligner.dpov2aligner method)": [[51, "lmflow.pipeline.dpov2_aligner.DPOv2Aligner._calc_reward_with_length_penalty", false]], "_channel_view() (lmflow.optim.adamp.adamp static method)": [[31, "lmflow.optim.adamp.AdamP._channel_view", false]], "_channel_view() (lmflow.optim.sgdp.sgdp static method)": [[43, "lmflow.optim.sgdp.SGDP._channel_view", false]], "_check_data_format() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset._check_data_format", false]], "_check_data_format() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset._check_data_format", false]], "_check_if_alignable() (lmflow.pipeline.base_aligner.basealigner method)": [[47, "lmflow.pipeline.base_aligner.BaseAligner._check_if_alignable", false]], "_check_if_tunable() (lmflow.pipeline.base_tuner.basetuner method)": [[49, "lmflow.pipeline.base_tuner.BaseTuner._check_if_tunable", false]], "_clean_text() (lmflow.pipeline.raft_aligner.raftaligner method)": [[57, "lmflow.pipeline.raft_aligner.RaftAligner._clean_text", false]], "_cosine_similarity() (lmflow.optim.adamp.adamp static method)": [[31, "lmflow.optim.adamp.AdamP._cosine_similarity", false]], "_cosine_similarity() (lmflow.optim.sgdp.sgdp static method)": [[43, "lmflow.optim.sgdp.SGDP._cosine_similarity", false]], "_discard_sample() (lmflow.pipeline.raft_aligner.raftaligner method)": [[57, "lmflow.pipeline.raft_aligner.RaftAligner._discard_sample", false]], "_distributed_inference() (lmflow.pipeline.vllm_inferencer.vllminferencer method)": [[69, "lmflow.pipeline.vllm_inferencer.VLLMInferencer._distributed_inference", false]], "_do_reward_model_inference() (lmflow.pipeline.iterative_dpo_aligner.iterativedpoaligner method)": [[56, "lmflow.pipeline.iterative_dpo_aligner.IterativeDPOAligner._do_reward_model_inference", false]], "_do_single_dpo_align() (lmflow.pipeline.iterative_dpo_aligner.iterativedpoaligner method)": [[56, "lmflow.pipeline.iterative_dpo_aligner.IterativeDPOAligner._do_single_dpo_align", false]], "_do_target_model_inference() (lmflow.pipeline.iterative_dpo_aligner.iterativedpoaligner method)": [[56, "lmflow.pipeline.iterative_dpo_aligner.IterativeDPOAligner._do_target_model_inference", false]], "_encode() (lmflow.utils.conversation_template.base.conversationtemplate method)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate._encode", false]], "_encode() (lmflow.utils.conversation_template.base.conversationtemplatefortool method)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplateForTool._encode", false]], "_encode() (lmflow.utils.conversation_template.conversationtemplate method)": [[81, "lmflow.utils.conversation_template.ConversationTemplate._encode", false]], "_encode() (lmflow.utils.conversation_template.conversationtemplatefortool method)": [[81, "lmflow.utils.conversation_template.ConversationTemplateForTool._encode", false]], "_encode() (lmflow.utils.conversation_template.llama.llama2conversationtemplate method)": [[83, "lmflow.utils.conversation_template.llama.Llama2ConversationTemplate._encode", false]], "_encode() (lmflow.utils.conversation_template.llama.llama2conversationtemplatefortool method)": [[83, "lmflow.utils.conversation_template.llama.Llama2ConversationTemplateForTool._encode", false]], "_encode() (lmflow.utils.conversation_template.zephyr.zephyrconversationtemplate method)": [[87, "lmflow.utils.conversation_template.zephyr.ZephyrConversationTemplate._encode", false]], "_encode_template() (lmflow.utils.conversation_template.base.conversationtemplate method)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate._encode_template", false]], "_encode_template() (lmflow.utils.conversation_template.base.conversationtemplatefortool method)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplateForTool._encode_template", false]], "_encode_template() (lmflow.utils.conversation_template.conversationtemplate method)": [[81, "lmflow.utils.conversation_template.ConversationTemplate._encode_template", false]], "_encode_template() (lmflow.utils.conversation_template.conversationtemplatefortool method)": [[81, "lmflow.utils.conversation_template.ConversationTemplateForTool._encode_template", false]], "_ensure_id_list() (lmflow.utils.conversation_template.base.conversationtemplate method)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate._ensure_id_list", false]], "_ensure_id_list() (lmflow.utils.conversation_template.conversationtemplate method)": [[81, "lmflow.utils.conversation_template.ConversationTemplate._ensure_id_list", false]], "_evaluate_acc_with_accelerator() (lmflow.pipeline.evaluator.evaluator method)": [[52, "lmflow.pipeline.evaluator.Evaluator._evaluate_acc_with_accelerator", false]], "_evaluate_acc_with_deepspeed() (lmflow.pipeline.evaluator.evaluator method)": [[52, "lmflow.pipeline.evaluator.Evaluator._evaluate_acc_with_deepspeed", false]], "_evaluate_nll() (lmflow.pipeline.evaluator.evaluator method)": [[52, "lmflow.pipeline.evaluator.Evaluator._evaluate_nll", false]], "_evaluate_ppl() (lmflow.pipeline.evaluator.evaluator method)": [[52, "lmflow.pipeline.evaluator.Evaluator._evaluate_ppl", false]], "_flash_attn_backward() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[94, "lmflow.utils.flash_attention.triton_flash_attention._flash_attn_backward", false]], "_flash_attn_forward() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[94, "lmflow.utils.flash_attention.triton_flash_attention._flash_attn_forward", false]], "_fwd_kernel() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[94, "lmflow.utils.flash_attention.triton_flash_attention._fwd_kernel", false]], "_gather_and_numpify() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._gather_and_numpify", false]], "_get_batch_dataset_local() (lmflow.pipeline.raft_aligner.raftaligner method)": [[57, "lmflow.pipeline.raft_aligner.RaftAligner._get_batch_dataset_local", false]], "_get_batch_dataset_top() (lmflow.pipeline.raft_aligner.raftaligner method)": [[57, "lmflow.pipeline.raft_aligner.RaftAligner._get_batch_dataset_top", false]], "_get_collator_with_removed_columns() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_collator_with_removed_columns", false]], "_get_eval_sampler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_eval_sampler", false]], "_get_output_dir() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_output_dir", false]], "_get_train_sampler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_train_sampler", false]], "_hp_search_setup() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._hp_search_setup", false]], "_inference() (lmflow.pipeline.rm_inferencer.rewardmodelinferencer method)": [[58, "lmflow.pipeline.rm_inferencer.RewardModelInferencer._inference", false]], "_inference() (lmflow.pipeline.vllm_inferencer.vllminferencer method)": [[69, "lmflow.pipeline.vllm_inferencer.VLLMInferencer._inference", false]], "_initialize_trainer() (lmflow.pipeline.dpo_aligner.dpoaligner method)": [[50, "lmflow.pipeline.dpo_aligner.DPOAligner._initialize_trainer", false]], "_initialize_trainer() (lmflow.pipeline.raft_aligner.raftaligner method)": [[57, "lmflow.pipeline.raft_aligner.RaftAligner._initialize_trainer", false]], "_inner_training_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._inner_training_loop", false]], "_is_native_cpu_amp_available (in module lmflow.pipeline.utils.raft_trainer)": [[66, "lmflow.pipeline.utils.raft_trainer._is_native_cpu_amp_available", false]], "_is_package_available() (in module lmflow.utils.versioning)": [[101, "lmflow.utils.versioning._is_package_available", false]], "_is_packages_available() (in module lmflow.utils.versioning)": [[101, "lmflow.utils.versioning._is_packages_available", false]], "_issue_warnings_after_load() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._issue_warnings_after_load", false]], "_layer_view() (lmflow.optim.adamp.adamp static method)": [[31, "lmflow.optim.adamp.AdamP._layer_view", false]], "_layer_view() (lmflow.optim.sgdp.sgdp static method)": [[43, "lmflow.optim.sgdp.SGDP._layer_view", false]], "_load_best_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_best_model", false]], "_load_dataset() (lmflow.pipeline.dpo_aligner.dpoaligner method)": [[50, "lmflow.pipeline.dpo_aligner.DPOAligner._load_dataset", false]], "_load_dataset() (lmflow.pipeline.raft_aligner.raftaligner method)": [[57, "lmflow.pipeline.raft_aligner.RaftAligner._load_dataset", false]], "_load_from_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_from_checkpoint", false]], "_load_input_dataset() (lmflow.pipeline.raft_aligner.raftaligner method)": [[57, "lmflow.pipeline.raft_aligner.RaftAligner._load_input_dataset", false]], "_load_optimizer_and_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_optimizer_and_scheduler", false]], "_load_rng_state() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_rng_state", false]], "_loggers_initialized (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._loggers_initialized", false]], "_match() (lmflow.pipeline.evaluator.evaluator method)": [[52, "lmflow.pipeline.evaluator.Evaluator._match", false]], "_maybe_log_save_evaluate() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._maybe_log_save_evaluate", false]], "_memory_tracker (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._memory_tracker", false]], "_move_model_to_device() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._move_model_to_device", false]], "_multi_tensor_adan() (in module lmflow.optim.adan)": [[33, "lmflow.optim.adan._multi_tensor_adan", false]], "_nested_gather() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._nested_gather", false]], "_one_train() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._one_train", false]], "_pad_across_processes() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._pad_across_processes", false]], "_parse_dpo_aligner_args() (lmflow.pipeline.iterative_dpo_aligner.iterativedpoaligner method)": [[56, "lmflow.pipeline.iterative_dpo_aligner.IterativeDPOAligner._parse_dpo_aligner_args", false]], "_parse_reward_model_inference_args() (lmflow.pipeline.iterative_dpo_aligner.iterativedpoaligner method)": [[56, "lmflow.pipeline.iterative_dpo_aligner.IterativeDPOAligner._parse_reward_model_inference_args", false]], "_parse_target_model_inference_args() (lmflow.pipeline.iterative_dpo_aligner.iterativedpoaligner method)": [[56, "lmflow.pipeline.iterative_dpo_aligner.IterativeDPOAligner._parse_target_model_inference_args", false]], "_prepare_attn_mask() (in module lmflow.utils.flash_attention.bloom_flash_attention)": [[89, "lmflow.utils.flash_attention.bloom_flash_attention._prepare_attn_mask", false]], "_prepare_decoder_attention_mask() (in module lmflow.utils.flash_attention.gpt2_flash_attention)": [[90, "lmflow.utils.flash_attention.gpt2_flash_attention._prepare_decoder_attention_mask", false]], "_prepare_decoder_attention_mask() (in module lmflow.utils.flash_attention.llama_flash_attention)": [[93, "lmflow.utils.flash_attention.llama_flash_attention._prepare_decoder_attention_mask", false]], "_prepare_input() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._prepare_input", false]], "_prepare_inputs() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._prepare_inputs", false]], "_projection() (lmflow.optim.adamp.adamp method)": [[31, "lmflow.optim.adamp.AdamP._projection", false]], "_projection() (lmflow.optim.sgdp.sgdp method)": [[43, "lmflow.optim.sgdp.SGDP._projection", false]], "_push_from_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._push_from_checkpoint", false]], "_remove_unused_columns() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._remove_unused_columns", false]], "_report_to_hp_search() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._report_to_hp_search", false]], "_rotate_checkpoints() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._rotate_checkpoints", false]], "_sampling_paired_idx_from_rewards() (lmflow.pipeline.dpov2_aligner.dpov2aligner method)": [[51, "lmflow.pipeline.dpov2_aligner.DPOv2Aligner._sampling_paired_idx_from_rewards", false]], "_sampling_paired_idx_from_rewards_fast() (lmflow.pipeline.dpov2_aligner.dpov2aligner method)": [[51, "lmflow.pipeline.dpov2_aligner.DPOv2Aligner._sampling_paired_idx_from_rewards_fast", false]], "_save() (lmflow.pipeline.utils.peft_trainer.peftsavingcallback method)": [[65, "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback._save", false]], "_save() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save", false]], "_save_checkpoint() (lmflow.pipeline.utils.peft_trainer.pefttrainer method)": [[65, "lmflow.pipeline.utils.peft_trainer.PeftTrainer._save_checkpoint", false]], "_save_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save_checkpoint", false]], "_save_tpu() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save_tpu", false]], "_set_signature_columns_if_needed() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._set_signature_columns_if_needed", false]], "_signature_columns (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._signature_columns", false]], "_single_tensor_adan() (in module lmflow.optim.adan)": [[33, "lmflow.optim.adan._single_tensor_adan", false]], "_sorted_checkpoints() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._sorted_checkpoints", false]], "_train_batch_size (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._train_batch_size", false]], "_tune_save_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._tune_save_checkpoint", false]], "_wrap_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._wrap_model", false]], "accelerate_config_file (lmflow.args.dpov2alignerarguments attribute)": [[4, "lmflow.args.DPOv2AlignerArguments.accelerate_config_file", false]], "activate_model_for_inference() (lmflow.models.hf_model_mixin.hfmodelmixin method)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.activate_model_for_inference", false]], "adabelief (class in lmflow.optim.adabelief)": [[25, "lmflow.optim.adabelief.AdaBelief", false]], "adabelief (lmflow.args.optimizernames attribute)": [[4, "lmflow.args.OptimizerNames.ADABELIEF", false]], "adabound (class in lmflow.optim.adabound)": [[26, "lmflow.optim.adabound.AdaBound", false]], "adabound (lmflow.args.optimizernames attribute)": [[4, "lmflow.args.OptimizerNames.ADABOUND", false]], "adadelta (class in lmflow.optim.adadelta)": [[27, "lmflow.optim.adadelta.Adadelta", false]], "adadelta (lmflow.args.optimizernames attribute)": [[4, "lmflow.args.OptimizerNames.ADADELTA", false]], "adagrad (class in lmflow.optim.adagrad)": [[28, "lmflow.optim.adagrad.AdaGrad", false]], "adagrad (lmflow.args.optimizernames attribute)": [[4, "lmflow.args.OptimizerNames.ADAGRAD", false]], "adam (class in lmflow.optim.adam)": [[29, "lmflow.optim.adam.Adam", false]], "adam (lmflow.args.optimizernames attribute)": [[4, "lmflow.args.OptimizerNames.ADAM", false]], "adam (lmflow.optim.lamb.lamb attribute)": [[36, "lmflow.optim.lamb.Lamb.adam", false]], "adamax (class in lmflow.optim.adamax)": [[30, "lmflow.optim.adamax.Adamax", false]], "adamax (lmflow.args.optimizernames attribute)": [[4, "lmflow.args.OptimizerNames.ADAMAX", false]], "adamp (class in lmflow.optim.adamp)": [[31, "lmflow.optim.adamp.AdamP", false]], "adamp (lmflow.args.optimizernames attribute)": [[4, "lmflow.args.OptimizerNames.ADAMP", false]], "adamw_schedule_free (lmflow.args.optimizernames attribute)": [[4, "lmflow.args.OptimizerNames.ADAMW_SCHEDULE_FREE", false]], "adamwschedulefree (class in lmflow.optim.adamw_schedule_free)": [[32, "lmflow.optim.adamw_schedule_free.AdamWScheduleFree", false]], "adan (class in lmflow.optim.adan)": [[33, "lmflow.optim.adan.Adan", false]], "adan (lmflow.args.optimizernames attribute)": [[4, "lmflow.args.OptimizerNames.ADAN", false]], "adapt_llava_model_to_lmflow_type() (in module lmflow.utils.multimodal)": [[98, "lmflow.utils.multimodal.adapt_llava_model_to_lmflow_type", false]], "add_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.add_callback", false]], "add_dataclass_attr_prefix() (in module lmflow.utils.common)": [[73, "lmflow.utils.common.add_dataclass_attr_prefix", false]], "add_special_starter() (lmflow.utils.conversation_template.base.conversationtemplate method)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate.add_special_starter", false]], "add_special_starter() (lmflow.utils.conversation_template.conversationtemplate method)": [[81, "lmflow.utils.conversation_template.ConversationTemplate.add_special_starter", false]], "add_special_stopper() (lmflow.utils.conversation_template.base.conversationtemplate method)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate.add_special_stopper", false]], "add_special_stopper() (lmflow.utils.conversation_template.conversationtemplate method)": [[81, "lmflow.utils.conversation_template.ConversationTemplate.add_special_stopper", false]], "additional_stop_token_ids (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.additional_stop_token_ids", false]], "align() (lmflow.pipeline.base_aligner.basealigner method)": [[47, "lmflow.pipeline.base_aligner.BaseAligner.align", false]], "align() (lmflow.pipeline.dpo_aligner.dpoaligner method)": [[50, "lmflow.pipeline.dpo_aligner.DPOAligner.align", false]], "align() (lmflow.pipeline.dpov2_aligner.dpov2aligner method)": [[51, "lmflow.pipeline.dpov2_aligner.DPOv2Aligner.align", false]], "align() (lmflow.pipeline.dpov2_aligner.memorysafedpov2aligner method)": [[51, "lmflow.pipeline.dpov2_aligner.MemorySafeDPOv2Aligner.align", false]], "align() (lmflow.pipeline.iterative_dpo_aligner.iterativedpoaligner method)": [[56, "lmflow.pipeline.iterative_dpo_aligner.IterativeDPOAligner.align", false]], "align() (lmflow.pipeline.raft_aligner.raftaligner method)": [[57, "lmflow.pipeline.raft_aligner.RaftAligner.align", false]], "aligner_args (lmflow.pipeline.dpo_aligner.dpoaligner attribute)": [[50, "lmflow.pipeline.dpo_aligner.DPOAligner.aligner_args", false]], "aligner_args (lmflow.pipeline.dpov2_aligner.dpov2aligner attribute)": [[51, "lmflow.pipeline.dpov2_aligner.DPOv2Aligner.aligner_args", false]], "aligner_args (lmflow.pipeline.dpov2_aligner.memorysafedpov2aligner attribute)": [[51, "lmflow.pipeline.dpov2_aligner.MemorySafeDPOv2Aligner.aligner_args", false]], "aligner_args (lmflow.pipeline.iterative_dpo_aligner.iterativedpoaligner attribute)": [[56, "lmflow.pipeline.iterative_dpo_aligner.IterativeDPOAligner.aligner_args", false]], "aligner_args (lmflow.pipeline.raft_aligner.raftaligner attribute)": [[57, "lmflow.pipeline.raft_aligner.RaftAligner.aligner_args", false]], "aligner_file_path (lmflow.pipeline.dpov2_aligner.memorysafedpov2aligner attribute)": [[51, "lmflow.pipeline.dpov2_aligner.MemorySafeDPOv2Aligner.aligner_file_path", false]], "answer_extraction() (in module lmflow.utils.data_utils)": [[88, "lmflow.utils.data_utils.answer_extraction", false]], "answer_type (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.answer_type", false]], "append_message() (lmflow.utils.llava_conversation_lib.conversation method)": [[96, "lmflow.utils.llava_conversation_lib.Conversation.append_message", false]], "apply_chat_template (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.apply_chat_template", false]], "arch_type (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.arch_type", false]], "args (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.args", false]], "assistant_formatter (lmflow.utils.conversation_template.base.conversationtemplate attribute)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate.assistant_formatter", false]], "assistant_formatter (lmflow.utils.conversation_template.conversationtemplate attribute)": [[81, "lmflow.utils.conversation_template.ConversationTemplate.assistant_formatter", false]], "autoarguments (class in lmflow.args)": [[4, "lmflow.args.AutoArguments", false]], "autocast_smart_context_manager() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.autocast_smart_context_manager", false]], "automodel (class in lmflow.models.auto_model)": [[9, "lmflow.models.auto_model.AutoModel", false]], "autopipeline (class in lmflow.pipeline.auto_pipeline)": [[46, "lmflow.pipeline.auto_pipeline.AutoPipeline", false]], "autoregressive_sampling() (lmflow.pipeline.inferencer.speculativeinferencer method)": [[55, "lmflow.pipeline.inferencer.SpeculativeInferencer.autoregressive_sampling", false]], "backend (lmflow.datasets.dataset attribute)": [[6, "lmflow.datasets.Dataset.backend", false]], "backend (lmflow.datasets.dataset.dataset attribute)": [[5, "lmflow.datasets.dataset.Dataset.backend", false]], "backend_dataset (lmflow.datasets.dataset attribute)": [[6, "lmflow.datasets.Dataset.backend_dataset", false]], "backend_dataset (lmflow.datasets.dataset.dataset attribute)": [[5, "lmflow.datasets.dataset.Dataset.backend_dataset", false]], "backward() (lmflow.utils.flash_attention.triton_flash_attention.flashattnfunc static method)": [[94, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnFunc.backward", false]], "backward() (lmflow.utils.flash_attention.triton_flash_attention.flashattnkvpackedfunc static method)": [[94, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnKVPackedFunc.backward", false]], "backward() (lmflow.utils.flash_attention.triton_flash_attention.flashattnqkvpackedfunc static method)": [[94, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnQKVPackedFunc.backward", false]], "base_lrs (lmflow.optim.adabound.adabound attribute)": [[26, "lmflow.optim.adabound.AdaBound.base_lrs", false]], "basealigner (class in lmflow.pipeline.base_aligner)": [[47, "lmflow.pipeline.base_aligner.BaseAligner", false]], "basemodel (class in lmflow.models.base_model)": [[10, "lmflow.models.base_model.BaseModel", false]], "basepipeline (class in lmflow.pipeline.base_pipeline)": [[48, "lmflow.pipeline.base_pipeline.BasePipeline", false]], "basetuner (class in lmflow.pipeline.base_tuner)": [[49, "lmflow.pipeline.base_tuner.BaseTuner", false]], "batchlize() (in module lmflow.utils.data_utils)": [[88, "lmflow.utils.data_utils.batchlize", false]], "benchmarkingarguments (class in lmflow.args)": [[4, "lmflow.args.BenchmarkingArguments", false]], "beta (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.beta", false]], "beta (lmflow.args.dpov2alignerarguments attribute)": [[4, "lmflow.args.DPOv2AlignerArguments.beta", false]], "bits (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.bits", false]], "block_size (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.block_size", false]], "block_size (lmflow.pipeline.evaluator.evaluator attribute)": [[52, "lmflow.pipeline.evaluator.Evaluator.block_size", false]], "blocking() (in module lmflow.tokenization.hf_decoder_model)": [[70, "lmflow.tokenization.hf_decoder_model.blocking", false]], "blocking() (in module lmflow.tokenization.hf_text_regression_model)": [[71, "lmflow.tokenization.hf_text_regression_model.blocking", false]], "blocking_paired() (in module lmflow.tokenization.hf_text_regression_model)": [[71, "lmflow.tokenization.hf_text_regression_model.blocking_paired", false]], "blocking_text_to_textlist() (in module lmflow.tokenization.hf_text_regression_model)": [[71, "lmflow.tokenization.hf_text_regression_model.blocking_text_to_textlist", false]], "build_vision_tower() (in module lmflow.models.vision_encoder)": [[24, "lmflow.models.vision_encoder.build_vision_tower", false]], "build_vision_tower() (in module lmflow.models.vision_encoder.clip_encoder)": [[23, "lmflow.models.vision_encoder.clip_encoder.build_vision_tower", false]], "cache_dir (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.cache_dir", false]], "call_model_init() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.call_model_init", false]], "callback_handler (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.callback_handler", false]], "can_return_loss (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.can_return_loss", false]], "chatglm3_template (in module lmflow.utils.conversation_template)": [[81, "lmflow.utils.conversation_template.CHATGLM3_TEMPLATE", false]], "chatglm3_template (in module lmflow.utils.conversation_template.chatglm)": [[76, "lmflow.utils.conversation_template.chatglm.CHATGLM3_TEMPLATE", false]], "chatml_template (in module lmflow.utils.conversation_template)": [[81, "lmflow.utils.conversation_template.CHATML_TEMPLATE", false]], "chatml_template (in module lmflow.utils.conversation_template.chatml)": [[77, "lmflow.utils.conversation_template.chatml.CHATML_TEMPLATE", false]], "check_homogeneity() (in module lmflow.utils.model)": [[97, "lmflow.utils.model.check_homogeneity", false]], "clamp_value (lmflow.optim.lamb.lamb attribute)": [[36, "lmflow.optim.lamb.Lamb.clamp_value", false]], "clipvisiontower (class in lmflow.models.vision_encoder.clip_encoder)": [[23, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower", false]], "code_exec() (lmflow.pipeline.inferencer.toolinferencer method)": [[55, "lmflow.pipeline.inferencer.ToolInferencer.code_exec", false]], "collate() (lmflow.pipeline.utils.dpov2_dataprocessor.preferencedatacollatorwithpadding method)": [[60, "lmflow.pipeline.utils.dpov2_dataprocessor.PreferenceDataCollatorWithPadding.collate", false]], "collection_strategy (lmflow.args.raftalignerarguments attribute)": [[4, "lmflow.args.RaftAlignerArguments.collection_strategy", false]], "compress_list() (lmflow.pipeline.rm_inferencer.rewardmodelinferencer method)": [[58, "lmflow.pipeline.rm_inferencer.RewardModelInferencer.compress_list", false]], "compute_loss() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.compute_loss", false]], "compute_loss() (lmflow.pipeline.utils.rm_trainer.peftrewardtrainer method)": [[68, "lmflow.pipeline.utils.rm_trainer.PeftRewardTrainer.compute_loss", false]], "compute_loss() (lmflow.pipeline.utils.rm_trainer.rewardtrainer method)": [[68, "lmflow.pipeline.utils.rm_trainer.RewardTrainer.compute_loss", false]], "compute_loss_context_manager() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.compute_loss_context_manager", false]], "compute_metrics (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.compute_metrics", false]], "compute_metrics() (in module lmflow.pipeline.utils.rm_trainer)": [[68, "lmflow.pipeline.utils.rm_trainer.compute_metrics", false]], "condenserotaryembedding (class in lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch)": [[100, "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch.CondenseRotaryEmbedding", false]], "config (lmflow.models.vision_encoder.clip_encoder.clipvisiontower property)": [[23, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.config", false]], "config (lmflow.pipeline.evaluator.evaluator attribute)": [[52, "lmflow.pipeline.evaluator.Evaluator.config", false]], "config (lmflow.pipeline.inferencer.inferencer attribute)": [[55, "lmflow.pipeline.inferencer.Inferencer.config", false]], "config_name (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.config_name", false]], "config_overrides (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.config_overrides", false]], "content (lmflow.utils.conversation_template.base.templatecomponent attribute)": [[75, "lmflow.utils.conversation_template.base.TemplateComponent.content", false]], "control (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.control", false]], "controller_heart_beat_expiration (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.CONTROLLER_HEART_BEAT_EXPIRATION", false]], "conv_llama_2 (in module lmflow.utils.llava_conversation_lib)": [[96, "lmflow.utils.llava_conversation_lib.conv_llama_2", false]], "conv_llava_llama_2 (in module lmflow.utils.llava_conversation_lib)": [[96, "lmflow.utils.llava_conversation_lib.conv_llava_llama_2", false]], "conv_llava_plain (in module lmflow.utils.llava_conversation_lib)": [[96, "lmflow.utils.llava_conversation_lib.conv_llava_plain", false]], "conv_llava_v0 (in module lmflow.utils.llava_conversation_lib)": [[96, "lmflow.utils.llava_conversation_lib.conv_llava_v0", false]], "conv_llava_v0_mmtag (in module lmflow.utils.llava_conversation_lib)": [[96, "lmflow.utils.llava_conversation_lib.conv_llava_v0_mmtag", false]], "conv_llava_v1 (in module lmflow.utils.llava_conversation_lib)": [[96, "lmflow.utils.llava_conversation_lib.conv_llava_v1", false]], "conv_llava_v1_mmtag (in module lmflow.utils.llava_conversation_lib)": [[96, "lmflow.utils.llava_conversation_lib.conv_llava_v1_mmtag", false]], "conv_mpt (in module lmflow.utils.llava_conversation_lib)": [[96, "lmflow.utils.llava_conversation_lib.conv_mpt", false]], "conv_templates (in module lmflow.utils.llava_conversation_lib)": [[96, "lmflow.utils.llava_conversation_lib.conv_templates", false]], "conv_vicuna_v0 (in module lmflow.utils.llava_conversation_lib)": [[96, "lmflow.utils.llava_conversation_lib.conv_vicuna_v0", false]], "conv_vicuna_v1 (in module lmflow.utils.llava_conversation_lib)": [[96, "lmflow.utils.llava_conversation_lib.conv_vicuna_v1", false]], "conversation (class in lmflow.utils.llava_conversation_lib)": [[96, "lmflow.utils.llava_conversation_lib.Conversation", false]], "conversation_dataset_description (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.CONVERSATION_DATASET_DESCRIPTION", false]], "conversation_role_names (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.CONVERSATION_ROLE_NAMES", false]], "conversation_template (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.conversation_template", false]], "conversation_tokenize_function() (in module lmflow.tokenization.hf_decoder_model)": [[70, "lmflow.tokenization.hf_decoder_model.conversation_tokenize_function", false]], "conversation_tokenize_function() (in module lmflow.tokenization.hf_text_regression_model)": [[71, "lmflow.tokenization.hf_text_regression_model.conversation_tokenize_function", false]], "conversationtemplate (class in lmflow.utils.conversation_template)": [[81, "lmflow.utils.conversation_template.ConversationTemplate", false]], "conversationtemplate (class in lmflow.utils.conversation_template.base)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate", false]], "conversationtemplatefortool (class in lmflow.utils.conversation_template)": [[81, "lmflow.utils.conversation_template.ConversationTemplateForTool", false]], "conversationtemplatefortool (class in lmflow.utils.conversation_template.base)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplateForTool", false]], "convert_to_paired_dataset() (lmflow.pipeline.dpov2_aligner.dpov2aligner method)": [[51, "lmflow.pipeline.dpov2_aligner.DPOv2Aligner.convert_to_paired_dataset", false]], "copy() (lmflow.utils.llava_conversation_lib.conversation method)": [[96, "lmflow.utils.llava_conversation_lib.Conversation.copy", false]], "create_copied_dataclass() (in module lmflow.utils.common)": [[73, "lmflow.utils.common.create_copied_dataclass", false]], "create_customized_optimizer() (lmflow.pipeline.finetuner.finetuner method)": [[53, "lmflow.pipeline.finetuner.Finetuner.create_customized_optimizer", false]], "create_dataloader() (lmflow.pipeline.evaluator.evaluator method)": [[52, "lmflow.pipeline.evaluator.Evaluator.create_dataloader", false]], "create_dataloader() (lmflow.pipeline.inferencer.inferencer method)": [[55, "lmflow.pipeline.inferencer.Inferencer.create_dataloader", false]], "create_from_dict() (lmflow.datasets.dataset class method)": [[6, "lmflow.datasets.Dataset.create_from_dict", false]], "create_from_dict() (lmflow.datasets.dataset.dataset class method)": [[5, "lmflow.datasets.dataset.Dataset.create_from_dict", false]], "create_model_card() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_model_card", false]], "create_optimizer() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_optimizer", false]], "create_optimizer_and_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_optimizer_and_scheduler", false]], "create_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_scheduler", false]], "current_flos (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.current_flos", false]], "custom_model (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.custom_model", false]], "custom_vision_model (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.custom_vision_model", false]], "custom_vision_model (lmflow.models.vision2seq_model.customautovision2seqmodel attribute)": [[22, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.custom_vision_model", false]], "customautovision2seqmodel (class in lmflow.models.vision2seq_model)": [[22, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel", false]], "customized_cache_dir (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.customized_cache_dir", false]], "customized_optim (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.customized_optim", false]], "customized_optim_args (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.customized_optim_args", false]], "custommultimodaldataset (class in lmflow.datasets.multi_modal_dataset)": [[7, "lmflow.datasets.multi_modal_dataset.CustomMultiModalDataset", false]], "data_args (lmflow.datasets.dataset attribute)": [[6, "lmflow.datasets.Dataset.data_args", false]], "data_args (lmflow.datasets.dataset.dataset attribute)": [[5, "lmflow.datasets.dataset.Dataset.data_args", false]], "data_args (lmflow.datasets.multi_modal_dataset.custommultimodaldataset attribute)": [[7, "lmflow.datasets.multi_modal_dataset.CustomMultiModalDataset.data_args", false]], "data_args (lmflow.pipeline.dpo_aligner.dpoaligner attribute)": [[50, "lmflow.pipeline.dpo_aligner.DPOAligner.data_args", false]], "data_args (lmflow.pipeline.dpov2_aligner.dpov2aligner attribute)": [[51, "lmflow.pipeline.dpov2_aligner.DPOv2Aligner.data_args", false]], "data_args (lmflow.pipeline.dpov2_aligner.memorysafedpov2aligner attribute)": [[51, "lmflow.pipeline.dpov2_aligner.MemorySafeDPOv2Aligner.data_args", false]], "data_args (lmflow.pipeline.evaluator.evaluator attribute)": [[52, "lmflow.pipeline.evaluator.Evaluator.data_args", false]], "data_args (lmflow.pipeline.finetuner.finetuner attribute)": [[53, "lmflow.pipeline.finetuner.Finetuner.data_args", false]], "data_args (lmflow.pipeline.inferencer.inferencer attribute)": [[55, "lmflow.pipeline.inferencer.Inferencer.data_args", false]], "data_args (lmflow.pipeline.iterative_dpo_aligner.iterativedpoaligner attribute)": [[56, "lmflow.pipeline.iterative_dpo_aligner.IterativeDPOAligner.data_args", false]], "data_args (lmflow.pipeline.raft_aligner.raftaligner attribute)": [[57, "lmflow.pipeline.raft_aligner.RaftAligner.data_args", false]], "data_args (lmflow.pipeline.rm_inferencer.rewardmodelinferencer attribute)": [[58, "lmflow.pipeline.rm_inferencer.RewardModelInferencer.data_args", false]], "data_args (lmflow.pipeline.vllm_inferencer.inferencerwithoffloading attribute)": [[69, "lmflow.pipeline.vllm_inferencer.InferencerWithOffloading.data_args", false]], "data_collator (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.data_collator", false]], "data_dict (lmflow.datasets.multi_modal_dataset.custommultimodaldataset attribute)": [[7, "lmflow.datasets.multi_modal_dataset.CustomMultiModalDataset.data_dict", false]], "datacollatorforsuperviseddataset (class in lmflow.datasets.multi_modal_dataset)": [[7, "lmflow.datasets.multi_modal_dataset.DataCollatorForSupervisedDataset", false]], "dataset (class in lmflow.datasets)": [[6, "lmflow.datasets.Dataset", false]], "dataset (class in lmflow.datasets.dataset)": [[5, "lmflow.datasets.dataset.Dataset", false]], "dataset_config_name (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.dataset_config_name", false]], "dataset_description_map (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.DATASET_DESCRIPTION_MAP", false]], "dataset_name (lmflow.args.benchmarkingarguments attribute)": [[4, "lmflow.args.BenchmarkingArguments.dataset_name", false]], "dataset_name (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.dataset_name", false]], "dataset_path (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.dataset_path", false]], "dataset_path (lmflow.datasets.dataset attribute)": [[6, "lmflow.datasets.Dataset.dataset_path", false]], "dataset_path (lmflow.datasets.dataset.dataset attribute)": [[5, "lmflow.datasets.dataset.Dataset.dataset_path", false]], "dataset_path_list (lmflow.args.iterativealignerarguments attribute)": [[4, "lmflow.args.IterativeAlignerArguments.dataset_path_list", false]], "dataset_types (in module lmflow.datasets.dataset)": [[5, "lmflow.datasets.dataset.DATASET_TYPES", false]], "datasetarguments (class in lmflow.args)": [[4, "lmflow.args.DatasetArguments", false]], "deactivate_model_for_inference() (lmflow.models.hf_model_mixin.hfmodelmixin method)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.deactivate_model_for_inference", false]], "debias (lmflow.optim.lamb.lamb attribute)": [[36, "lmflow.optim.lamb.Lamb.debias", false]], "decode() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.decode", false]], "decode() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.decode", false]], "decodermodel (class in lmflow.models.decoder_model)": [[11, "lmflow.models.decoder_model.DecoderModel", false]], "deepseek_template (in module lmflow.utils.conversation_template)": [[81, "lmflow.utils.conversation_template.DEEPSEEK_TEMPLATE", false]], "deepseek_template (in module lmflow.utils.conversation_template.deepseek)": [[78, "lmflow.utils.conversation_template.deepseek.DEEPSEEK_TEMPLATE", false]], "deepspeed (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.deepspeed", false]], "deepspeed (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.deepspeed", false]], "deepspeed (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.deepspeed", false]], "default_callbacks (in module lmflow.pipeline.utils.raft_trainer)": [[66, "lmflow.pipeline.utils.raft_trainer.DEFAULT_CALLBACKS", false]], "default_conversation (in module lmflow.utils.llava_conversation_lib)": [[96, "lmflow.utils.llava_conversation_lib.default_conversation", false]], "default_im_end_token (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.DEFAULT_IM_END_TOKEN", false]], "default_im_start_token (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.DEFAULT_IM_START_TOKEN", false]], "default_image_patch_token (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.DEFAULT_IMAGE_PATCH_TOKEN", false]], "default_image_token (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.DEFAULT_IMAGE_TOKEN", false]], "default_progress_callback (in module lmflow.pipeline.utils.raft_trainer)": [[66, "id0", false], [66, "lmflow.pipeline.utils.raft_trainer.DEFAULT_PROGRESS_CALLBACK", false]], "degenerated_to_sgd (lmflow.optim.adabelief.adabelief attribute)": [[25, "lmflow.optim.adabelief.AdaBelief.degenerated_to_sgd", false]], "device (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.device", false]], "device (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel attribute)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.device", false]], "device (lmflow.models.hf_model_mixin.hfmodelmixin attribute)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.device", false]], "device (lmflow.models.vision_encoder.clip_encoder.clipvisiontower property)": [[23, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.device", false]], "dict() (lmflow.utils.llava_conversation_lib.conversation method)": [[96, "lmflow.utils.llava_conversation_lib.Conversation.dict", false]], "disable_group_texts (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.disable_group_texts", false]], "distributed_inference_num_instances (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.distributed_inference_num_instances", false]], "do_dpo_align (lmflow.args.iterativedpoalignerarguments attribute)": [[4, "lmflow.args.IterativeDPOAlignerArguments.do_dpo_align", false]], "do_grad_scaling (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.do_grad_scaling", false]], "do_response_generation (lmflow.args.iterativedpoalignerarguments attribute)": [[4, "lmflow.args.IterativeDPOAlignerArguments.do_response_generation", false]], "do_rope_scaling (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.do_rope_scaling", false]], "do_sample (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.do_sample", false]], "do_scoring (lmflow.args.iterativedpoalignerarguments attribute)": [[4, "lmflow.args.IterativeDPOAlignerArguments.do_scoring", false]], "do_train (lmflow.models.hf_model_mixin.hfmodelmixin attribute)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.do_train", false]], "double_quant (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.double_quant", false]], "dpo_loss() (lmflow.pipeline.utils.dpov2_trainer.dpov2trainer method)": [[61, "lmflow.pipeline.utils.dpov2_trainer.DPOv2Trainer.dpo_loss", false]], "dpoaligner (class in lmflow.pipeline.dpo_aligner)": [[50, "lmflow.pipeline.dpo_aligner.DPOAligner", false]], "dpoalignerarguments (class in lmflow.args)": [[4, "lmflow.args.DPOAlignerArguments", false]], "dpov2aligner (class in lmflow.pipeline.dpov2_aligner)": [[51, "lmflow.pipeline.dpov2_aligner.DPOv2Aligner", false]], "dpov2alignerarguments (class in lmflow.args)": [[4, "lmflow.args.DPOv2AlignerArguments", false]], "dpov2trainer (class in lmflow.pipeline.utils.dpov2_trainer)": [[61, "lmflow.pipeline.utils.dpov2_trainer.DPOv2Trainer", false]], "draft_config (lmflow.pipeline.inferencer.speculativeinferencer attribute)": [[55, "lmflow.pipeline.inferencer.SpeculativeInferencer.draft_config", false]], "draft_model_args (lmflow.pipeline.inferencer.speculativeinferencer attribute)": [[55, "lmflow.pipeline.inferencer.SpeculativeInferencer.draft_model_args", false]], "drop_instances() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.drop_instances", false]], "drop_instances() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.drop_instances", false]], "ds_config (lmflow.models.hf_model_mixin.hfmodelmixin attribute)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.ds_config", false]], "dtype (lmflow.models.vision_encoder.clip_encoder.clipvisiontower property)": [[23, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.dtype", false]], "dummy (class in lmflow.optim.dummy)": [[34, "lmflow.optim.dummy.Dummy", false]], "dummy (lmflow.args.optimizernames attribute)": [[4, "lmflow.args.OptimizerNames.DUMMY", false]], "dummy_feature (lmflow.models.vision_encoder.clip_encoder.clipvisiontower property)": [[23, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.dummy_feature", false]], "empty_no_special_tokens_template (in module lmflow.utils.conversation_template)": [[81, "lmflow.utils.conversation_template.EMPTY_NO_SPECIAL_TOKENS_TEMPLATE", false]], "empty_no_special_tokens_template (in module lmflow.utils.conversation_template.base)": [[75, "lmflow.utils.conversation_template.base.EMPTY_NO_SPECIAL_TOKENS_TEMPLATE", false]], "empty_template (in module lmflow.utils.conversation_template)": [[81, "lmflow.utils.conversation_template.EMPTY_TEMPLATE", false]], "empty_template (in module lmflow.utils.conversation_template.base)": [[75, "lmflow.utils.conversation_template.base.EMPTY_TEMPLATE", false]], "emptyformatter (class in lmflow.utils.conversation_template.base)": [[75, "lmflow.utils.conversation_template.base.EmptyFormatter", false]], "enable_decode_inference_result (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.enable_decode_inference_result", false]], "enable_distributed_inference (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.enable_distributed_inference", false]], "encode() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.encode", false]], "encode() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.encode", false]], "encode_conversation() (lmflow.utils.conversation_template.base.conversationtemplate method)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate.encode_conversation", false]], "encode_conversation() (lmflow.utils.conversation_template.base.conversationtemplatefortool method)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplateForTool.encode_conversation", false]], "encode_conversation() (lmflow.utils.conversation_template.conversationtemplate method)": [[81, "lmflow.utils.conversation_template.ConversationTemplate.encode_conversation", false]], "encode_conversation() (lmflow.utils.conversation_template.conversationtemplatefortool method)": [[81, "lmflow.utils.conversation_template.ConversationTemplateForTool.encode_conversation", false]], "encode_conversation() (lmflow.utils.conversation_template.gemma.gemmaconversationtemplate method)": [[79, "lmflow.utils.conversation_template.gemma.GemmaConversationTemplate.encode_conversation", false]], "encode_conversation() (lmflow.utils.conversation_template.hymba.hymbaconversationtemplate method)": [[80, "lmflow.utils.conversation_template.hymba.HymbaConversationTemplate.encode_conversation", false]], "encode_images() (lmflow.models.vision_encoder.clip_encoder.clipvisiontower method)": [[23, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.encode_images", false]], "encoderdecodermodel (class in lmflow.models.encoder_decoder_model)": [[12, "lmflow.models.encoder_decoder_model.EncoderDecoderModel", false]], "eos_padding (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.eos_padding", false]], "eos_token_id (lmflow.pipeline.vllm_inferencer.inferencerwithoffloading attribute)": [[69, "lmflow.pipeline.vllm_inferencer.InferencerWithOffloading.eos_token_id", false]], "eval() (lmflow.optim.adamw_schedule_free.adamwschedulefree method)": [[32, "lmflow.optim.adamw_schedule_free.AdamWScheduleFree.eval", false]], "eval() (lmflow.optim.sgd_schedule_free.sgdschedulefree method)": [[42, "lmflow.optim.sgd_schedule_free.SGDScheduleFree.eval", false]], "eval_dataset (lmflow.pipeline.dpo_aligner.dpoaligner attribute)": [[50, "lmflow.pipeline.dpo_aligner.DPOAligner.eval_dataset", false]], "eval_dataset (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.eval_dataset", false]], "eval_dataset_path (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.eval_dataset_path", false]], "eval_dataset_path (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.eval_dataset_path", false]], "eval_steps (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.eval_steps", false]], "evaluate() (lmflow.pipeline.evaluator.evaluator method)": [[52, "lmflow.pipeline.evaluator.Evaluator.evaluate", false]], "evaluate() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.evaluate", false]], "evaluate_block_size (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.evaluate_block_size", false]], "evaluation_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.evaluation_loop", false]], "evaluator (class in lmflow.pipeline.evaluator)": [[52, "lmflow.pipeline.evaluator.Evaluator", false]], "evaluator_args (lmflow.pipeline.evaluator.evaluator attribute)": [[52, "lmflow.pipeline.evaluator.Evaluator.evaluator_args", false]], "evaluatorarguments (class in lmflow.args)": [[4, "lmflow.args.EvaluatorArguments", false]], "feature_select() (lmflow.models.vision_encoder.clip_encoder.clipvisiontower method)": [[23, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.feature_select", false]], "finetune_part (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.finetune_part", false]], "finetuner (class in lmflow.pipeline.finetuner)": [[53, "lmflow.pipeline.finetuner.Finetuner", false]], "finetuner_args (lmflow.pipeline.finetuner.finetuner attribute)": [[53, "lmflow.pipeline.finetuner.Finetuner.finetuner_args", false]], "finetunerarguments (class in lmflow.args)": [[4, "lmflow.args.FinetunerArguments", false]], "fixed_decay (lmflow.optim.adabelief.adabelief attribute)": [[25, "lmflow.optim.adabelief.AdaBelief.fixed_decay", false]], "flash_attn_func (in module lmflow.utils.flash_attention.triton_flash_attention)": [[94, "lmflow.utils.flash_attention.triton_flash_attention.flash_attn_func", false]], "flash_attn_kvpacked_func (in module lmflow.utils.flash_attention.triton_flash_attention)": [[94, "lmflow.utils.flash_attention.triton_flash_attention.flash_attn_kvpacked_func", false]], "flash_attn_qkvpacked_func (in module lmflow.utils.flash_attention.triton_flash_attention)": [[94, "lmflow.utils.flash_attention.triton_flash_attention.flash_attn_qkvpacked_func", false]], "flashattnfunc (class in lmflow.utils.flash_attention.triton_flash_attention)": [[94, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnFunc", false]], "flashattnkvpackedfunc (class in lmflow.utils.flash_attention.triton_flash_attention)": [[94, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnKVPackedFunc", false]], "flashattnqkvpackedfunc (class in lmflow.utils.flash_attention.triton_flash_attention)": [[94, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnQKVPackedFunc", false]], "flatten_list() (lmflow.pipeline.rm_inferencer.rewardmodelinferencer method)": [[58, "lmflow.pipeline.rm_inferencer.RewardModelInferencer.flatten_list", false]], "float_only_dataset_description (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.FLOAT_ONLY_DATASET_DESCRIPTION", false]], "floating_point_ops() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.floating_point_ops", false]], "force_system (lmflow.utils.conversation_template.base.conversationtemplate attribute)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate.force_system", false]], "force_system (lmflow.utils.conversation_template.conversationtemplate attribute)": [[81, "lmflow.utils.conversation_template.ConversationTemplate.force_system", false]], "format() (lmflow.utils.conversation_template.base.emptyformatter method)": [[75, "lmflow.utils.conversation_template.base.EmptyFormatter.format", false]], "format() (lmflow.utils.conversation_template.base.formatter method)": [[75, "lmflow.utils.conversation_template.base.Formatter.format", false]], "format() (lmflow.utils.conversation_template.base.listformatter method)": [[75, "lmflow.utils.conversation_template.base.ListFormatter.format", false]], "format() (lmflow.utils.conversation_template.base.stringformatter method)": [[75, "lmflow.utils.conversation_template.base.StringFormatter.format", false]], "formatter (class in lmflow.utils.conversation_template.base)": [[75, "lmflow.utils.conversation_template.base.Formatter", false]], "forward() (in module lmflow.utils.flash_attention.bloom_flash_attention)": [[89, "lmflow.utils.flash_attention.bloom_flash_attention.forward", false]], "forward() (in module lmflow.utils.flash_attention.gpt2_flash_attention)": [[90, "lmflow.utils.flash_attention.gpt2_flash_attention.forward", false]], "forward() (in module lmflow.utils.flash_attention.gpt_neo_flash_attention)": [[91, "lmflow.utils.flash_attention.gpt_neo_flash_attention.forward", false]], "forward() (in module lmflow.utils.flash_attention.llama_flash_attention)": [[93, "lmflow.utils.flash_attention.llama_flash_attention.forward", false]], "forward() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[22, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.forward", false]], "forward() (lmflow.models.vision_encoder.clip_encoder.clipvisiontower method)": [[23, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.forward", false]], "forward() (lmflow.utils.flash_attention.triton_flash_attention.flashattnfunc static method)": [[94, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnFunc.forward", false]], "forward() (lmflow.utils.flash_attention.triton_flash_attention.flashattnkvpackedfunc static method)": [[94, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnKVPackedFunc.forward", false]], "forward() (lmflow.utils.flash_attention.triton_flash_attention.flashattnqkvpackedfunc static method)": [[94, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnQKVPackedFunc.forward", false]], "forward() (lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch.condenserotaryembedding method)": [[100, "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch.CondenseRotaryEmbedding.forward", false]], "from_dict() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.from_dict", false]], "from_dict() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.from_dict", false]], "fsdp (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.fsdp", false]], "function_formatter (lmflow.utils.conversation_template.base.conversationtemplate attribute)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate.function_formatter", false]], "function_formatter (lmflow.utils.conversation_template.conversationtemplate attribute)": [[81, "lmflow.utils.conversation_template.ConversationTemplate.function_formatter", false]], "gemma_template (in module lmflow.utils.conversation_template)": [[81, "lmflow.utils.conversation_template.GEMMA_TEMPLATE", false]], "gemma_template (in module lmflow.utils.conversation_template.gemma)": [[79, "lmflow.utils.conversation_template.gemma.GEMMA_TEMPLATE", false]], "gemmaconversationtemplate (class in lmflow.utils.conversation_template.gemma)": [[79, "lmflow.utils.conversation_template.gemma.GemmaConversationTemplate", false]], "generate() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[22, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.generate", false]], "get_backend() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.get_backend", false]], "get_backend() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.get_backend", false]], "get_backend_dataset() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.get_backend_dataset", false]], "get_backend_dataset() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.get_backend_dataset", false]], "get_backend_model() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.get_backend_model", false]], "get_backend_model() (lmflow.models.hf_model_mixin.hfmodelmixin method)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.get_backend_model", false]], "get_backend_model() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[22, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.get_backend_model", false]], "get_batch_loss_metrics() (lmflow.pipeline.utils.dpov2_trainer.dpov2trainer method)": [[61, "lmflow.pipeline.utils.dpov2_trainer.DPOv2Trainer.get_batch_loss_metrics", false]], "get_batch_metrics() (lmflow.pipeline.utils.dpov2_trainer.dpov2trainer method)": [[61, "lmflow.pipeline.utils.dpov2_trainer.DPOv2Trainer.get_batch_metrics", false]], "get_data_args() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.get_data_args", false]], "get_data_args() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.get_data_args", false]], "get_eval_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_eval_dataloader", false]], "get_fingerprint() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.get_fingerprint", false]], "get_fingerprint() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.get_fingerprint", false]], "get_images() (lmflow.utils.llava_conversation_lib.conversation method)": [[96, "lmflow.utils.llava_conversation_lib.Conversation.get_images", false]], "get_max_length() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.get_max_length", false]], "get_max_length() (lmflow.models.hf_model_mixin.hfmodelmixin method)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.get_max_length", false]], "get_model() (lmflow.models.auto_model.automodel class method)": [[9, "lmflow.models.auto_model.AutoModel.get_model", false]], "get_optimizer_cls_and_kwargs() (lmflow.pipeline.utils.raft_trainer.rafttrainer static method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_optimizer_cls_and_kwargs", false]], "get_paired_dataset() (in module lmflow.pipeline.dpo_aligner)": [[50, "lmflow.pipeline.dpo_aligner.get_paired_dataset", false]], "get_peft_without_qlora() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.get_peft_without_qlora", false]], "get_pipeline() (lmflow.pipeline.auto_pipeline.autopipeline class method)": [[46, "lmflow.pipeline.auto_pipeline.AutoPipeline.get_pipeline", false]], "get_pipeline_args_class() (lmflow.args.autoarguments method)": [[4, "lmflow.args.AutoArguments.get_pipeline_args_class", false]], "get_prompt() (lmflow.utils.llava_conversation_lib.conversation method)": [[96, "lmflow.utils.llava_conversation_lib.Conversation.get_prompt", false]], "get_python_version() (in module lmflow.utils.versioning)": [[101, "lmflow.utils.versioning.get_python_version", false]], "get_test_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_test_dataloader", false]], "get_tokenizer() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.get_tokenizer", false]], "get_tokenizer() (lmflow.models.hf_model_mixin.hfmodelmixin method)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.get_tokenizer", false]], "get_tokenizer() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[22, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.get_tokenizer", false]], "get_train_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_train_dataloader", false]], "get_type() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.get_type", false]], "get_type() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.get_type", false]], "gradient_accumulation_steps (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.gradient_accumulation_steps", false]], "gradient_checkpointing (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.gradient_checkpointing", false]], "gradient_checkpointing_use_reentrant (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.gradient_checkpointing_use_reentrant", false]], "group_text() (lmflow.pipeline.finetuner.finetuner method)": [[53, "lmflow.pipeline.finetuner.Finetuner.group_text", false]], "group_texts_batch_size (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.group_texts_batch_size", false]], "has_placeholder() (lmflow.utils.conversation_template.base.formatter method)": [[75, "lmflow.utils.conversation_template.base.Formatter.has_placeholder", false]], "hf_auto_model (lmflow.models.hf_model_mixin.hfmodelmixin attribute)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.hf_auto_model", false]], "hf_automodel_mapping (in module lmflow.models.hf_model_mixin)": [[15, "lmflow.models.hf_model_mixin.HF_AUTOMODEL_MAPPING", false]], "hf_automodel_type (in module lmflow.models.hf_model_mixin)": [[15, "lmflow.models.hf_model_mixin.HF_AUTOMODEL_TYPE", false]], "hf_dataset_sanity_check() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.hf_dataset_sanity_check", false]], "hf_dataset_sanity_check() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.hf_dataset_sanity_check", false]], "hf_model_config (lmflow.models.hf_model_mixin.hfmodelmixin attribute)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.hf_model_config", false]], "hfdecodermodel (class in lmflow.models.hf_decoder_model)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel", false]], "hfencoderdecodermodel (class in lmflow.models.hf_encoder_decoder_model)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel", false]], "hfmodelmixin (class in lmflow.models.hf_model_mixin)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin", false]], "hftextregressionmodel (class in lmflow.models.hf_text_regression_model)": [[16, "lmflow.models.hf_text_regression_model.HFTextRegressionModel", false]], "hidden_size (lmflow.models.vision2seq_model.customautovision2seqmodel attribute)": [[22, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.hidden_size", false]], "hidden_size (lmflow.models.vision_encoder.clip_encoder.clipvisiontower property)": [[23, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.hidden_size", false]], "hp_name (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.hp_name", false]], "hp_search_backend (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.hp_search_backend", false]], "hymba_template (in module lmflow.utils.conversation_template)": [[81, "lmflow.utils.conversation_template.HYMBA_TEMPLATE", false]], "hymba_template (in module lmflow.utils.conversation_template.hymba)": [[80, "lmflow.utils.conversation_template.hymba.HYMBA_TEMPLATE", false]], "hymbaconversationtemplate (class in lmflow.utils.conversation_template.hymba)": [[80, "lmflow.utils.conversation_template.hymba.HymbaConversationTemplate", false]], "hyperparameter_search() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.hyperparameter_search", false]], "ignore_bias_buffers (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.ignore_bias_buffers", false]], "ignore_index (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.IGNORE_INDEX", false]], "image_aspect_ratio (lmflow.args.multimodaldatasetarguments attribute)": [[4, "lmflow.args.MultiModalDatasetArguments.image_aspect_ratio", false]], "image_encoder_name_or_path (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.image_encoder_name_or_path", false]], "image_folder (lmflow.args.multimodaldatasetarguments attribute)": [[4, "lmflow.args.MultiModalDatasetArguments.image_folder", false]], "image_folder (lmflow.datasets.multi_modal_dataset.custommultimodaldataset attribute)": [[7, "lmflow.datasets.multi_modal_dataset.CustomMultiModalDataset.image_folder", false]], "image_token_index (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.IMAGE_TOKEN_INDEX", false]], "inf (lmflow.pipeline.raft_aligner.raftaligner attribute)": [[57, "lmflow.pipeline.raft_aligner.RaftAligner.INF", false]], "inference() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.inference", false]], "inference() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.inference", false]], "inference() (lmflow.models.hf_text_regression_model.hftextregressionmodel method)": [[16, "lmflow.models.hf_text_regression_model.HFTextRegressionModel.inference", false]], "inference() (lmflow.models.text_regression_model.textregressionmodel method)": [[21, "lmflow.models.text_regression_model.TextRegressionModel.inference", false]], "inference() (lmflow.pipeline.inferencer.inferencer method)": [[55, "lmflow.pipeline.inferencer.Inferencer.inference", false]], "inference() (lmflow.pipeline.inferencer.speculativeinferencer method)": [[55, "lmflow.pipeline.inferencer.SpeculativeInferencer.inference", false]], "inference() (lmflow.pipeline.inferencer.toolinferencer method)": [[55, "lmflow.pipeline.inferencer.ToolInferencer.inference", false]], "inference() (lmflow.pipeline.rm_inferencer.rewardmodelinferencer method)": [[58, "lmflow.pipeline.rm_inferencer.RewardModelInferencer.inference", false]], "inference() (lmflow.pipeline.vllm_inferencer.inferencerwithoffloading method)": [[69, "lmflow.pipeline.vllm_inferencer.InferencerWithOffloading.inference", false]], "inference() (lmflow.pipeline.vllm_inferencer.memorysafevllminferencer method)": [[69, "lmflow.pipeline.vllm_inferencer.MemorySafeVLLMInferencer.inference", false]], "inference() (lmflow.pipeline.vllm_inferencer.vllminferencer method)": [[69, "lmflow.pipeline.vllm_inferencer.VLLMInferencer.inference", false]], "inference_batch_size (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.inference_batch_size", false]], "inference_batch_size_per_device (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.inference_batch_size_per_device", false]], "inference_batch_size_per_device (lmflow.args.raftalignerarguments attribute)": [[4, "lmflow.args.RaftAlignerArguments.inference_batch_size_per_device", false]], "inference_func (lmflow.models.text_regression_model.textregressionmodel attribute)": [[21, "lmflow.models.text_regression_model.TextRegressionModel.inference_func", false]], "inferencer (class in lmflow.pipeline.inferencer)": [[55, "lmflow.pipeline.inferencer.Inferencer", false]], "inferencer_args (lmflow.pipeline.inferencer.inferencer attribute)": [[55, "lmflow.pipeline.inferencer.Inferencer.inferencer_args", false]], "inferencer_args (lmflow.pipeline.rm_inferencer.rewardmodelinferencer attribute)": [[58, "lmflow.pipeline.rm_inferencer.RewardModelInferencer.inferencer_args", false]], "inferencer_args (lmflow.pipeline.vllm_inferencer.inferencerwithoffloading attribute)": [[69, "lmflow.pipeline.vllm_inferencer.InferencerWithOffloading.inferencer_args", false]], "inferencer_file_path (lmflow.pipeline.vllm_inferencer.memorysafevllminferencer attribute)": [[69, "lmflow.pipeline.vllm_inferencer.MemorySafeVLLMInferencer.inferencer_file_path", false]], "inferencerarguments (class in lmflow.args)": [[4, "lmflow.args.InferencerArguments", false]], "inferencerwithoffloading (class in lmflow.pipeline.vllm_inferencer)": [[69, "lmflow.pipeline.vllm_inferencer.InferencerWithOffloading", false]], "init_git_repo() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.init_git_repo", false]], "init_to_zero() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[94, "lmflow.utils.flash_attention.triton_flash_attention.init_to_zero", false]], "initial_iter_idx (lmflow.args.iterativealignerarguments attribute)": [[4, "lmflow.args.IterativeAlignerArguments.initial_iter_idx", false]], "input (lmflow.utils.data_utils.rewardmodelinferenceresultwithinput attribute)": [[88, "lmflow.utils.data_utils.RewardModelInferenceResultWithInput.input", false]], "input (lmflow.utils.data_utils.vllminferenceresultwithinput attribute)": [[88, "lmflow.utils.data_utils.VLLMInferenceResultWithInput.input", false]], "instance_fields_map (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.INSTANCE_FIELDS_MAP", false]], "internal_version (in module lmflow)": [[8, "lmflow.internal_version", false]], "internlm2_template (in module lmflow.utils.conversation_template)": [[81, "lmflow.utils.conversation_template.INTERNLM2_TEMPLATE", false]], "internlm2_template (in module lmflow.utils.conversation_template.internlm)": [[82, "lmflow.utils.conversation_template.internlm.INTERNLM2_TEMPLATE", false]], "ipex_optimize_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.ipex_optimize_model", false]], "is_custom_dataset (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.is_custom_dataset", false]], "is_encoder_decoder (lmflow.pipeline.utils.dpov2_dataprocessor.preferencedatacollatorwithpadding attribute)": [[60, "lmflow.pipeline.utils.dpov2_dataprocessor.PreferenceDataCollatorWithPadding.is_encoder_decoder", false]], "is_flash_attn_available() (in module lmflow.utils.versioning)": [[101, "lmflow.utils.versioning.is_flash_attn_available", false]], "is_flask_available() (in module lmflow.utils.versioning)": [[101, "lmflow.utils.versioning.is_flask_available", false]], "is_gradio_available() (in module lmflow.utils.versioning)": [[101, "lmflow.utils.versioning.is_gradio_available", false]], "is_in_train (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.is_in_train", false]], "is_loaded (lmflow.models.vision_encoder.clip_encoder.clipvisiontower attribute)": [[23, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.is_loaded", false]], "is_local_process_zero() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.is_local_process_zero", false]], "is_multimodal (lmflow.args.multimodaldatasetarguments attribute)": [[4, "lmflow.args.MultiModalDatasetArguments.is_multimodal", false]], "is_multimodal_available() (in module lmflow.datasets)": [[6, "lmflow.datasets.is_multimodal_available", false]], "is_multimodal_available() (in module lmflow.utils.versioning)": [[101, "lmflow.utils.versioning.is_multimodal_available", false]], "is_package_version_at_least() (in module lmflow.utils.versioning)": [[101, "lmflow.utils.versioning.is_package_version_at_least", false]], "is_ray_available() (in module lmflow.utils.versioning)": [[101, "lmflow.utils.versioning.is_ray_available", false]], "is_sagemaker_mp_post_1_10 (in module lmflow.pipeline.utils.raft_trainer)": [[66, "lmflow.pipeline.utils.raft_trainer.IS_SAGEMAKER_MP_POST_1_10", false]], "is_torch_greater_or_equal_than_1_10 (in module lmflow.pipeline.utils.raft_trainer)": [[66, "lmflow.pipeline.utils.raft_trainer.is_torch_greater_or_equal_than_1_10", false]], "is_torch_less_than_1_11 (in module lmflow.pipeline.utils.raft_trainer)": [[66, "lmflow.pipeline.utils.raft_trainer.is_torch_less_than_1_11", false]], "is_trl_available() (in module lmflow.utils.versioning)": [[101, "lmflow.utils.versioning.is_trl_available", false]], "is_vllm_available() (in module lmflow.utils.versioning)": [[101, "lmflow.utils.versioning.is_vllm_available", false]], "is_world_process_zero() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.is_world_process_zero", false]], "iterativealignerarguments (class in lmflow.args)": [[4, "lmflow.args.IterativeAlignerArguments", false]], "iterativedpoaligner (class in lmflow.pipeline.iterative_dpo_aligner)": [[56, "lmflow.pipeline.iterative_dpo_aligner.IterativeDPOAligner", false]], "iterativedpoalignerarguments (class in lmflow.args)": [[4, "lmflow.args.IterativeDPOAlignerArguments", false]], "keep_linebreaks (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.keep_linebreaks", false]], "key_instances (in module lmflow.datasets.dataset)": [[5, "lmflow.datasets.dataset.KEY_INSTANCES", false]], "key_score (in module lmflow.datasets.dataset)": [[5, "lmflow.datasets.dataset.KEY_SCORE", false]], "key_type (in module lmflow.datasets.dataset)": [[5, "lmflow.datasets.dataset.KEY_TYPE", false]], "label_names (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.label_names", false]], "label_pad_token_id (lmflow.pipeline.utils.dpov2_dataprocessor.preferencedatacollatorwithpadding attribute)": [[60, "lmflow.pipeline.utils.dpov2_dataprocessor.PreferenceDataCollatorWithPadding.label_pad_token_id", false]], "lamb (class in lmflow.optim.lamb)": [[36, "lmflow.optim.lamb.Lamb", false]], "lamb (lmflow.args.optimizernames attribute)": [[4, "lmflow.args.OptimizerNames.LAMB", false]], "language_model (lmflow.models.vision2seq_model.customautovision2seqmodel attribute)": [[22, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.language_model", false]], "language_model_from_pretrained() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[22, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.language_model_from_pretrained", false]], "lars (class in lmflow.optim.lars)": [[37, "lmflow.optim.lars.LARS", false]], "lars (lmflow.args.optimizernames attribute)": [[4, "lmflow.args.OptimizerNames.LARS", false]], "last_checkpoint (lmflow.pipeline.finetuner.finetuner attribute)": [[53, "lmflow.pipeline.finetuner.Finetuner.last_checkpoint", false]], "learning_rate (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.learning_rate", false]], "len_penalty (lmflow.pipeline.utils.dpov2_trainer.dpov2trainer attribute)": [[61, "lmflow.pipeline.utils.dpov2_trainer.DPOv2Trainer.len_penalty", false]], "length_penalty (lmflow.args.dpov2alignerarguments attribute)": [[4, "lmflow.args.DPOv2AlignerArguments.length_penalty", false]], "lisa_activated_layers (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.lisa_activated_layers", false]], "lisa_interval_steps (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.lisa_interval_steps", false]], "lisa_layers_attribute (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.lisa_layers_attribute", false]], "listformatter (class in lmflow.utils.conversation_template.base)": [[75, "lmflow.utils.conversation_template.base.ListFormatter", false]], "llama2_template (in module lmflow.utils.conversation_template)": [[81, "lmflow.utils.conversation_template.LLAMA2_TEMPLATE", false]], "llama2_template (in module lmflow.utils.conversation_template.llama)": [[83, "lmflow.utils.conversation_template.llama.LLAMA2_TEMPLATE", false]], "llama2_template_for_tool (in module lmflow.utils.conversation_template.llama)": [[83, "lmflow.utils.conversation_template.llama.LLAMA2_TEMPLATE_FOR_TOOL", false]], "llama2conversationtemplate (class in lmflow.utils.conversation_template.llama)": [[83, "lmflow.utils.conversation_template.llama.Llama2ConversationTemplate", false]], "llama2conversationtemplatefortool (class in lmflow.utils.conversation_template.llama)": [[83, "lmflow.utils.conversation_template.llama.Llama2ConversationTemplateForTool", false]], "llama3_template (in module lmflow.utils.conversation_template)": [[81, "lmflow.utils.conversation_template.LLAMA3_TEMPLATE", false]], "llama3_template (in module lmflow.utils.conversation_template.llama)": [[83, "lmflow.utils.conversation_template.llama.LLAMA3_TEMPLATE", false]], "llama3_template_for_tool (in module lmflow.utils.conversation_template)": [[81, "lmflow.utils.conversation_template.LLAMA3_TEMPLATE_FOR_TOOL", false]], "llama3_template_for_tool (in module lmflow.utils.conversation_template.llama)": [[83, "lmflow.utils.conversation_template.llama.LLAMA3_TEMPLATE_FOR_TOOL", false]], "llama_2 (lmflow.utils.llava_conversation_lib.separatorstyle attribute)": [[96, "lmflow.utils.llava_conversation_lib.SeparatorStyle.LLAMA_2", false]], "llava_loading (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.llava_loading", false]], "llava_pretrain_model_path (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.llava_pretrain_model_path", false]], "llm_model_name_or_path (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.llm_model_name_or_path", false]], "lm_evaluation_metric (lmflow.args.benchmarkingarguments attribute)": [[4, "lmflow.args.BenchmarkingArguments.lm_evaluation_metric", false]], "lmflow": [[8, "module-lmflow", false]], "lmflow.args": [[4, "module-lmflow.args", false]], "lmflow.datasets": [[6, "module-lmflow.datasets", false]], "lmflow.datasets.dataset": [[5, "module-lmflow.datasets.dataset", false]], "lmflow.datasets.multi_modal_dataset": [[7, "module-lmflow.datasets.multi_modal_dataset", false]], "lmflow.models": [[17, "module-lmflow.models", false]], "lmflow.models.auto_model": [[9, "module-lmflow.models.auto_model", false]], "lmflow.models.base_model": [[10, "module-lmflow.models.base_model", false]], "lmflow.models.decoder_model": [[11, "module-lmflow.models.decoder_model", false]], "lmflow.models.encoder_decoder_model": [[12, "module-lmflow.models.encoder_decoder_model", false]], "lmflow.models.hf_decoder_model": [[13, "module-lmflow.models.hf_decoder_model", false]], "lmflow.models.hf_encoder_decoder_model": [[14, "module-lmflow.models.hf_encoder_decoder_model", false]], "lmflow.models.hf_model_mixin": [[15, "module-lmflow.models.hf_model_mixin", false]], "lmflow.models.hf_text_regression_model": [[16, "module-lmflow.models.hf_text_regression_model", false]], "lmflow.models.interfaces": [[18, "module-lmflow.models.interfaces", false]], "lmflow.models.interfaces.tunable": [[19, "module-lmflow.models.interfaces.tunable", false]], "lmflow.models.regression_model": [[20, "module-lmflow.models.regression_model", false]], "lmflow.models.text_regression_model": [[21, "module-lmflow.models.text_regression_model", false]], "lmflow.models.vision2seq_model": [[22, "module-lmflow.models.vision2seq_model", false]], "lmflow.models.vision_encoder": [[24, "module-lmflow.models.vision_encoder", false]], "lmflow.models.vision_encoder.clip_encoder": [[23, "module-lmflow.models.vision_encoder.clip_encoder", false]], "lmflow.optim": [[35, "module-lmflow.optim", false]], "lmflow.optim.adabelief": [[25, "module-lmflow.optim.adabelief", false]], "lmflow.optim.adabound": [[26, "module-lmflow.optim.adabound", false]], "lmflow.optim.adadelta": [[27, "module-lmflow.optim.adadelta", false]], "lmflow.optim.adagrad": [[28, "module-lmflow.optim.adagrad", false]], "lmflow.optim.adam": [[29, "module-lmflow.optim.adam", false]], "lmflow.optim.adamax": [[30, "module-lmflow.optim.adamax", false]], "lmflow.optim.adamp": [[31, "module-lmflow.optim.adamp", false]], "lmflow.optim.adamw_schedule_free": [[32, "module-lmflow.optim.adamw_schedule_free", false]], "lmflow.optim.adan": [[33, "module-lmflow.optim.adan", false]], "lmflow.optim.dummy": [[34, "module-lmflow.optim.dummy", false]], "lmflow.optim.lamb": [[36, "module-lmflow.optim.lamb", false]], "lmflow.optim.lars": [[37, "module-lmflow.optim.lars", false]], "lmflow.optim.nadam": [[38, "module-lmflow.optim.nadam", false]], "lmflow.optim.novograd": [[39, "module-lmflow.optim.novograd", false]], "lmflow.optim.optimizers": [[40, "module-lmflow.optim.optimizers", false]], "lmflow.optim.radam": [[41, "module-lmflow.optim.radam", false]], "lmflow.optim.sgd_schedule_free": [[42, "module-lmflow.optim.sgd_schedule_free", false]], "lmflow.optim.sgdp": [[43, "module-lmflow.optim.sgdp", false]], "lmflow.optim.sophia": [[44, "module-lmflow.optim.sophia", false]], "lmflow.optim.yogi": [[45, "module-lmflow.optim.yogi", false]], "lmflow.pipeline": [[54, "module-lmflow.pipeline", false]], "lmflow.pipeline.auto_pipeline": [[46, "module-lmflow.pipeline.auto_pipeline", false]], "lmflow.pipeline.base_aligner": [[47, "module-lmflow.pipeline.base_aligner", false]], "lmflow.pipeline.base_pipeline": [[48, "module-lmflow.pipeline.base_pipeline", false]], "lmflow.pipeline.base_tuner": [[49, "module-lmflow.pipeline.base_tuner", false]], "lmflow.pipeline.dpo_aligner": [[50, "module-lmflow.pipeline.dpo_aligner", false]], "lmflow.pipeline.dpov2_aligner": [[51, "module-lmflow.pipeline.dpov2_aligner", false]], "lmflow.pipeline.evaluator": [[52, "module-lmflow.pipeline.evaluator", false]], "lmflow.pipeline.finetuner": [[53, "module-lmflow.pipeline.finetuner", false]], "lmflow.pipeline.inferencer": [[55, "module-lmflow.pipeline.inferencer", false]], "lmflow.pipeline.iterative_dpo_aligner": [[56, "module-lmflow.pipeline.iterative_dpo_aligner", false]], "lmflow.pipeline.raft_aligner": [[57, "module-lmflow.pipeline.raft_aligner", false]], "lmflow.pipeline.rm_inferencer": [[58, "module-lmflow.pipeline.rm_inferencer", false]], "lmflow.pipeline.rm_tuner": [[59, "module-lmflow.pipeline.rm_tuner", false]], "lmflow.pipeline.utils": [[62, "module-lmflow.pipeline.utils", false]], "lmflow.pipeline.utils.dpov2_dataprocessor": [[60, "module-lmflow.pipeline.utils.dpov2_dataprocessor", false]], "lmflow.pipeline.utils.dpov2_trainer": [[61, "module-lmflow.pipeline.utils.dpov2_trainer", false]], "lmflow.pipeline.utils.memory_safe_dpov2_align": [[63, "module-lmflow.pipeline.utils.memory_safe_dpov2_align", false]], "lmflow.pipeline.utils.memory_safe_vllm_inference": [[64, "module-lmflow.pipeline.utils.memory_safe_vllm_inference", false]], "lmflow.pipeline.utils.peft_trainer": [[65, "module-lmflow.pipeline.utils.peft_trainer", false]], "lmflow.pipeline.utils.raft_trainer": [[66, "module-lmflow.pipeline.utils.raft_trainer", false]], "lmflow.pipeline.utils.rm_dataprocessor": [[67, "module-lmflow.pipeline.utils.rm_dataprocessor", false]], "lmflow.pipeline.utils.rm_trainer": [[68, "module-lmflow.pipeline.utils.rm_trainer", false]], "lmflow.pipeline.vllm_inferencer": [[69, "module-lmflow.pipeline.vllm_inferencer", false]], "lmflow.tokenization": [[72, "module-lmflow.tokenization", false]], "lmflow.tokenization.hf_decoder_model": [[70, "module-lmflow.tokenization.hf_decoder_model", false]], "lmflow.tokenization.hf_text_regression_model": [[71, "module-lmflow.tokenization.hf_text_regression_model", false]], "lmflow.utils": [[95, "module-lmflow.utils", false]], "lmflow.utils.common": [[73, "module-lmflow.utils.common", false]], "lmflow.utils.constants": [[74, "module-lmflow.utils.constants", false]], "lmflow.utils.conversation_template": [[81, "module-lmflow.utils.conversation_template", false]], "lmflow.utils.conversation_template.base": [[75, "module-lmflow.utils.conversation_template.base", false]], "lmflow.utils.conversation_template.chatglm": [[76, "module-lmflow.utils.conversation_template.chatglm", false]], "lmflow.utils.conversation_template.chatml": [[77, "module-lmflow.utils.conversation_template.chatml", false]], "lmflow.utils.conversation_template.deepseek": [[78, "module-lmflow.utils.conversation_template.deepseek", false]], "lmflow.utils.conversation_template.gemma": [[79, "module-lmflow.utils.conversation_template.gemma", false]], "lmflow.utils.conversation_template.hymba": [[80, "module-lmflow.utils.conversation_template.hymba", false]], "lmflow.utils.conversation_template.internlm": [[82, "module-lmflow.utils.conversation_template.internlm", false]], "lmflow.utils.conversation_template.llama": [[83, "module-lmflow.utils.conversation_template.llama", false]], "lmflow.utils.conversation_template.phi": [[84, "module-lmflow.utils.conversation_template.phi", false]], "lmflow.utils.conversation_template.qwen": [[85, "module-lmflow.utils.conversation_template.qwen", false]], "lmflow.utils.conversation_template.yi": [[86, "module-lmflow.utils.conversation_template.yi", false]], "lmflow.utils.conversation_template.zephyr": [[87, "module-lmflow.utils.conversation_template.zephyr", false]], "lmflow.utils.data_utils": [[88, "module-lmflow.utils.data_utils", false]], "lmflow.utils.flash_attention": [[92, "module-lmflow.utils.flash_attention", false]], "lmflow.utils.flash_attention.bloom_flash_attention": [[89, "module-lmflow.utils.flash_attention.bloom_flash_attention", false]], "lmflow.utils.flash_attention.gpt2_flash_attention": [[90, "module-lmflow.utils.flash_attention.gpt2_flash_attention", false]], "lmflow.utils.flash_attention.gpt_neo_flash_attention": [[91, "module-lmflow.utils.flash_attention.gpt_neo_flash_attention", false]], "lmflow.utils.flash_attention.llama_flash_attention": [[93, "module-lmflow.utils.flash_attention.llama_flash_attention", false]], "lmflow.utils.flash_attention.triton_flash_attention": [[94, "module-lmflow.utils.flash_attention.triton_flash_attention", false]], "lmflow.utils.llava_conversation_lib": [[96, "module-lmflow.utils.llava_conversation_lib", false]], "lmflow.utils.model": [[97, "module-lmflow.utils.model", false]], "lmflow.utils.multimodal": [[98, "module-lmflow.utils.multimodal", false]], "lmflow.utils.position_interpolation": [[99, "module-lmflow.utils.position_interpolation", false]], "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch": [[100, "module-lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch", false]], "lmflow.utils.versioning": [[101, "module-lmflow.utils.versioning", false]], "lmflow.version": [[102, "module-lmflow.version", false]], "lmflow_lora_target_modules_mapping (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.LMFLOW_LORA_TARGET_MODULES_MAPPING", false]], "load_data() (in module lmflow.utils.data_utils)": [[88, "lmflow.utils.data_utils.load_data", false]], "load_in_4bit (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.load_in_4bit", false]], "load_inference_results() (lmflow.pipeline.vllm_inferencer.inferencerwithoffloading method)": [[69, "lmflow.pipeline.vllm_inferencer.InferencerWithOffloading.load_inference_results", false]], "load_inference_results() (lmflow.pipeline.vllm_inferencer.vllminferencer method)": [[69, "lmflow.pipeline.vllm_inferencer.VLLMInferencer.load_inference_results", false]], "load_llava_pretrain_model() (in module lmflow.utils.multimodal)": [[98, "lmflow.utils.multimodal.load_llava_pretrain_model", false]], "load_model() (lmflow.models.vision_encoder.clip_encoder.clipvisiontower method)": [[23, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.load_model", false]], "load_prompt_cache() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[22, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.load_prompt_cache", false]], "local_rank (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.local_rank", false]], "local_rank (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.local_rank", false]], "local_rank (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.local_rank", false]], "local_rank (lmflow.pipeline.evaluator.evaluator attribute)": [[52, "lmflow.pipeline.evaluator.Evaluator.local_rank", false]], "local_rank (lmflow.pipeline.inferencer.inferencer attribute)": [[55, "lmflow.pipeline.inferencer.Inferencer.local_rank", false]], "local_rank (lmflow.pipeline.rm_inferencer.rewardmodelinferencer attribute)": [[58, "lmflow.pipeline.rm_inferencer.RewardModelInferencer.local_rank", false]], "log() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.log", false]], "log_freq (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.log_freq", false]], "logdir (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.LOGDIR", false]], "logger (in module lmflow.args)": [[4, "lmflow.args.logger", false]], "logger (in module lmflow.datasets.dataset)": [[5, "lmflow.datasets.dataset.logger", false]], "logger (in module lmflow.models.hf_decoder_model)": [[13, "lmflow.models.hf_decoder_model.logger", false]], "logger (in module lmflow.models.hf_encoder_decoder_model)": [[14, "lmflow.models.hf_encoder_decoder_model.logger", false]], "logger (in module lmflow.models.hf_model_mixin)": [[15, "lmflow.models.hf_model_mixin.logger", false]], "logger (in module lmflow.models.hf_text_regression_model)": [[16, "lmflow.models.hf_text_regression_model.logger", false]], "logger (in module lmflow.pipeline.dpov2_aligner)": [[51, "lmflow.pipeline.dpov2_aligner.logger", false]], "logger (in module lmflow.pipeline.finetuner)": [[53, "lmflow.pipeline.finetuner.logger", false]], "logger (in module lmflow.pipeline.inferencer)": [[55, "lmflow.pipeline.inferencer.logger", false]], "logger (in module lmflow.pipeline.iterative_dpo_aligner)": [[56, "lmflow.pipeline.iterative_dpo_aligner.logger", false]], "logger (in module lmflow.pipeline.raft_aligner)": [[57, "lmflow.pipeline.raft_aligner.logger", false]], "logger (in module lmflow.pipeline.rm_inferencer)": [[58, "lmflow.pipeline.rm_inferencer.logger", false]], "logger (in module lmflow.pipeline.rm_tuner)": [[59, "lmflow.pipeline.rm_tuner.logger", false]], "logger (in module lmflow.pipeline.utils.dpov2_dataprocessor)": [[60, "lmflow.pipeline.utils.dpov2_dataprocessor.logger", false]], "logger (in module lmflow.pipeline.utils.dpov2_trainer)": [[61, "lmflow.pipeline.utils.dpov2_trainer.logger", false]], "logger (in module lmflow.pipeline.utils.memory_safe_dpov2_align)": [[63, "lmflow.pipeline.utils.memory_safe_dpov2_align.logger", false]], "logger (in module lmflow.pipeline.utils.memory_safe_vllm_inference)": [[64, "lmflow.pipeline.utils.memory_safe_vllm_inference.logger", false]], "logger (in module lmflow.pipeline.utils.raft_trainer)": [[66, "lmflow.pipeline.utils.raft_trainer.logger", false]], "logger (in module lmflow.pipeline.utils.rm_dataprocessor)": [[67, "lmflow.pipeline.utils.rm_dataprocessor.logger", false]], "logger (in module lmflow.pipeline.vllm_inferencer)": [[69, "lmflow.pipeline.vllm_inferencer.logger", false]], "logger (in module lmflow.tokenization.hf_decoder_model)": [[70, "lmflow.tokenization.hf_decoder_model.logger", false]], "logger (in module lmflow.tokenization.hf_text_regression_model)": [[71, "lmflow.tokenization.hf_text_regression_model.logger", false]], "logger (in module lmflow.utils.common)": [[73, "lmflow.utils.common.logger", false]], "logger (in module lmflow.utils.conversation_template.base)": [[75, "lmflow.utils.conversation_template.base.logger", false]], "logger (in module lmflow.utils.conversation_template.gemma)": [[79, "lmflow.utils.conversation_template.gemma.logger", false]], "logger (in module lmflow.utils.conversation_template.llama)": [[83, "lmflow.utils.conversation_template.llama.logger", false]], "logger (in module lmflow.utils.conversation_template.zephyr)": [[87, "lmflow.utils.conversation_template.zephyr.logger", false]], "logger (in module lmflow.utils.model)": [[97, "lmflow.utils.model.logger", false]], "logger (in module lmflow.utils.versioning)": [[101, "lmflow.utils.versioning.logger", false]], "logging_steps (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.logging_steps", false]], "lora_alpha (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.lora_alpha", false]], "lora_dropout (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.lora_dropout", false]], "lora_model_path (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.lora_model_path", false]], "lora_r (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.lora_r", false]], "lora_target_modules (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.lora_target_modules", false]], "lora_target_modules_mapping (in module lmflow.models.hf_model_mixin)": [[15, "lmflow.models.hf_model_mixin.LORA_TARGET_MODULES_MAPPING", false]], "loss_type (lmflow.args.dpov2alignerarguments attribute)": [[4, "lmflow.args.DPOv2AlignerArguments.loss_type", false]], "low_resource (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.low_resource", false]], "lr_scheduler_type (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.lr_scheduler_type", false]], "main() (in module lmflow.pipeline.utils.memory_safe_dpov2_align)": [[63, "lmflow.pipeline.utils.memory_safe_dpov2_align.main", false]], "main() (in module lmflow.pipeline.utils.memory_safe_vllm_inference)": [[64, "lmflow.pipeline.utils.memory_safe_vllm_inference.main", false]], "make_shell_args_from_dataclass() (in module lmflow.utils.common)": [[73, "lmflow.utils.common.make_shell_args_from_dataclass", false]], "map() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.map", false]], "map() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.map", false]], "margin_scale (lmflow.args.dpov2alignerarguments attribute)": [[4, "lmflow.args.DPOv2AlignerArguments.margin_scale", false]], "mask (lmflow.utils.conversation_template.base.templatecomponent attribute)": [[75, "lmflow.utils.conversation_template.base.TemplateComponent.mask", false]], "mask_prompt (lmflow.args.dpov2alignerarguments attribute)": [[4, "lmflow.args.DPOv2AlignerArguments.mask_prompt", false]], "mask_prompt (lmflow.pipeline.utils.dpov2_dataprocessor.preferencedatacollatorwithpadding attribute)": [[60, "lmflow.pipeline.utils.dpov2_dataprocessor.PreferenceDataCollatorWithPadding.mask_prompt", false]], "max_eval_samples (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.max_eval_samples", false]], "max_length (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.max_length", false]], "max_length (lmflow.args.dpov2alignerarguments attribute)": [[4, "lmflow.args.DPOv2AlignerArguments.max_length", false]], "max_length (lmflow.pipeline.utils.dpov2_dataprocessor.preferencedatacollatorwithpadding attribute)": [[60, "lmflow.pipeline.utils.dpov2_dataprocessor.PreferenceDataCollatorWithPadding.max_length", false]], "max_length (lmflow.pipeline.utils.rm_dataprocessor.rewarddatacollatorwithpadding attribute)": [[67, "lmflow.pipeline.utils.rm_dataprocessor.RewardDataCollatorWithPadding.max_length", false]], "max_new_tokens (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.max_new_tokens", false]], "max_new_tokens (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.max_new_tokens", false]], "max_prompt_length (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.max_prompt_length", false]], "max_prompt_length (lmflow.args.dpov2alignerarguments attribute)": [[4, "lmflow.args.DPOv2AlignerArguments.max_prompt_length", false]], "max_prompt_length (lmflow.pipeline.utils.dpov2_dataprocessor.preferencedatacollatorwithpadding attribute)": [[60, "lmflow.pipeline.utils.dpov2_dataprocessor.PreferenceDataCollatorWithPadding.max_prompt_length", false]], "max_seq_len_cached (lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch.condenserotaryembedding attribute)": [[100, "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch.CondenseRotaryEmbedding.max_seq_len_cached", false]], "max_steps (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.max_steps", false]], "max_target_length (lmflow.pipeline.utils.dpov2_dataprocessor.preferencedatacollatorwithpadding attribute)": [[60, "lmflow.pipeline.utils.dpov2_dataprocessor.PreferenceDataCollatorWithPadding.max_target_length", false]], "max_train_samples (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.max_train_samples", false]], "memory_safe_dpov2_align_env_var_to_remove (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.MEMORY_SAFE_DPOV2_ALIGN_ENV_VAR_TO_REMOVE", false]], "memory_safe_vllm_inference_env_var_to_remove (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.MEMORY_SAFE_VLLM_INFERENCE_ENV_VAR_TO_REMOVE", false]], "memory_safe_vllm_inference_finish_flag (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.MEMORY_SAFE_VLLM_INFERENCE_FINISH_FLAG", false]], "memorysafedpov2aligner (class in lmflow.pipeline.dpov2_aligner)": [[51, "lmflow.pipeline.dpov2_aligner.MemorySafeDPOv2Aligner", false]], "memorysafevllminferencer (class in lmflow.pipeline.vllm_inferencer)": [[69, "lmflow.pipeline.vllm_inferencer.MemorySafeVLLMInferencer", false]], "merge_lora_weights() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.merge_lora_weights", false]], "merge_lora_weights() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.merge_lora_weights", false]], "messages (lmflow.utils.llava_conversation_lib.conversation attribute)": [[96, "lmflow.utils.llava_conversation_lib.Conversation.messages", false]], "metric (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.metric", false]], "mixed_precision (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.mixed_precision", false]], "mixed_precision (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.mixed_precision", false]], "model (lmflow.pipeline.inferencer.toolinferencer attribute)": [[55, "lmflow.pipeline.inferencer.ToolInferencer.model", false]], "model (lmflow.pipeline.utils.dpov2_dataprocessor.preferencedatacollatorwithpadding attribute)": [[60, "lmflow.pipeline.utils.dpov2_dataprocessor.PreferenceDataCollatorWithPadding.model", false]], "model (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.model", false]], "model_args (lmflow.models.hf_model_mixin.hfmodelmixin attribute)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.model_args", false]], "model_args (lmflow.pipeline.dpo_aligner.dpoaligner attribute)": [[50, "lmflow.pipeline.dpo_aligner.DPOAligner.model_args", false]], "model_args (lmflow.pipeline.dpov2_aligner.dpov2aligner attribute)": [[51, "lmflow.pipeline.dpov2_aligner.DPOv2Aligner.model_args", false]], "model_args (lmflow.pipeline.dpov2_aligner.memorysafedpov2aligner attribute)": [[51, "lmflow.pipeline.dpov2_aligner.MemorySafeDPOv2Aligner.model_args", false]], "model_args (lmflow.pipeline.evaluator.evaluator attribute)": [[52, "lmflow.pipeline.evaluator.Evaluator.model_args", false]], "model_args (lmflow.pipeline.finetuner.finetuner attribute)": [[53, "lmflow.pipeline.finetuner.Finetuner.model_args", false]], "model_args (lmflow.pipeline.inferencer.inferencer attribute)": [[55, "lmflow.pipeline.inferencer.Inferencer.model_args", false]], "model_args (lmflow.pipeline.iterative_dpo_aligner.iterativedpoaligner attribute)": [[56, "lmflow.pipeline.iterative_dpo_aligner.IterativeDPOAligner.model_args", false]], "model_args (lmflow.pipeline.raft_aligner.raftaligner attribute)": [[57, "lmflow.pipeline.raft_aligner.RaftAligner.model_args", false]], "model_args (lmflow.pipeline.rm_inferencer.rewardmodelinferencer attribute)": [[58, "lmflow.pipeline.rm_inferencer.RewardModelInferencer.model_args", false]], "model_args (lmflow.pipeline.vllm_inferencer.inferencerwithoffloading attribute)": [[69, "lmflow.pipeline.vllm_inferencer.InferencerWithOffloading.model_args", false]], "model_config_classes (in module lmflow.args)": [[4, "lmflow.args.MODEL_CONFIG_CLASSES", false]], "model_max_length (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.model_max_length", false]], "model_name_or_path (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.model_name_or_path", false]], "model_revision (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.model_revision", false]], "model_type (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.model_type", false]], "model_types (in module lmflow.args)": [[4, "lmflow.args.MODEL_TYPES", false]], "model_wrapped (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.model_wrapped", false]], "modelarguments (class in lmflow.args)": [[4, "lmflow.args.ModelArguments", false]], "module": [[4, "module-lmflow.args", false], [5, "module-lmflow.datasets.dataset", false], [6, "module-lmflow.datasets", false], [7, "module-lmflow.datasets.multi_modal_dataset", false], [8, "module-lmflow", false], [9, "module-lmflow.models.auto_model", false], [10, "module-lmflow.models.base_model", false], [11, "module-lmflow.models.decoder_model", false], [12, "module-lmflow.models.encoder_decoder_model", false], [13, "module-lmflow.models.hf_decoder_model", false], [14, "module-lmflow.models.hf_encoder_decoder_model", false], [15, "module-lmflow.models.hf_model_mixin", false], [16, "module-lmflow.models.hf_text_regression_model", false], [17, "module-lmflow.models", false], [18, "module-lmflow.models.interfaces", false], [19, "module-lmflow.models.interfaces.tunable", false], [20, "module-lmflow.models.regression_model", false], [21, "module-lmflow.models.text_regression_model", false], [22, "module-lmflow.models.vision2seq_model", false], [23, "module-lmflow.models.vision_encoder.clip_encoder", false], [24, "module-lmflow.models.vision_encoder", false], [25, "module-lmflow.optim.adabelief", false], [26, "module-lmflow.optim.adabound", false], [27, "module-lmflow.optim.adadelta", false], [28, "module-lmflow.optim.adagrad", false], [29, "module-lmflow.optim.adam", false], [30, "module-lmflow.optim.adamax", false], [31, "module-lmflow.optim.adamp", false], [32, "module-lmflow.optim.adamw_schedule_free", false], [33, "module-lmflow.optim.adan", false], [34, "module-lmflow.optim.dummy", false], [35, "module-lmflow.optim", false], [36, "module-lmflow.optim.lamb", false], [37, "module-lmflow.optim.lars", false], [38, "module-lmflow.optim.nadam", false], [39, "module-lmflow.optim.novograd", false], [40, "module-lmflow.optim.optimizers", false], [41, "module-lmflow.optim.radam", false], [42, "module-lmflow.optim.sgd_schedule_free", false], [43, "module-lmflow.optim.sgdp", false], [44, "module-lmflow.optim.sophia", false], [45, "module-lmflow.optim.yogi", false], [46, "module-lmflow.pipeline.auto_pipeline", false], [47, "module-lmflow.pipeline.base_aligner", false], [48, "module-lmflow.pipeline.base_pipeline", false], [49, "module-lmflow.pipeline.base_tuner", false], [50, "module-lmflow.pipeline.dpo_aligner", false], [51, "module-lmflow.pipeline.dpov2_aligner", false], [52, "module-lmflow.pipeline.evaluator", false], [53, "module-lmflow.pipeline.finetuner", false], [54, "module-lmflow.pipeline", false], [55, "module-lmflow.pipeline.inferencer", false], [56, "module-lmflow.pipeline.iterative_dpo_aligner", false], [57, "module-lmflow.pipeline.raft_aligner", false], [58, "module-lmflow.pipeline.rm_inferencer", false], [59, "module-lmflow.pipeline.rm_tuner", false], [60, "module-lmflow.pipeline.utils.dpov2_dataprocessor", false], [61, "module-lmflow.pipeline.utils.dpov2_trainer", false], [62, "module-lmflow.pipeline.utils", false], [63, "module-lmflow.pipeline.utils.memory_safe_dpov2_align", false], [64, "module-lmflow.pipeline.utils.memory_safe_vllm_inference", false], [65, "module-lmflow.pipeline.utils.peft_trainer", false], [66, "module-lmflow.pipeline.utils.raft_trainer", false], [67, "module-lmflow.pipeline.utils.rm_dataprocessor", false], [68, "module-lmflow.pipeline.utils.rm_trainer", false], [69, "module-lmflow.pipeline.vllm_inferencer", false], [70, "module-lmflow.tokenization.hf_decoder_model", false], [71, "module-lmflow.tokenization.hf_text_regression_model", false], [72, "module-lmflow.tokenization", false], [73, "module-lmflow.utils.common", false], [74, "module-lmflow.utils.constants", false], [75, "module-lmflow.utils.conversation_template.base", false], [76, "module-lmflow.utils.conversation_template.chatglm", false], [77, "module-lmflow.utils.conversation_template.chatml", false], [78, "module-lmflow.utils.conversation_template.deepseek", false], [79, "module-lmflow.utils.conversation_template.gemma", false], [80, "module-lmflow.utils.conversation_template.hymba", false], [81, "module-lmflow.utils.conversation_template", false], [82, "module-lmflow.utils.conversation_template.internlm", false], [83, "module-lmflow.utils.conversation_template.llama", false], [84, "module-lmflow.utils.conversation_template.phi", false], [85, "module-lmflow.utils.conversation_template.qwen", false], [86, "module-lmflow.utils.conversation_template.yi", false], [87, "module-lmflow.utils.conversation_template.zephyr", false], [88, "module-lmflow.utils.data_utils", false], [89, "module-lmflow.utils.flash_attention.bloom_flash_attention", false], [90, "module-lmflow.utils.flash_attention.gpt2_flash_attention", false], [91, "module-lmflow.utils.flash_attention.gpt_neo_flash_attention", false], [92, "module-lmflow.utils.flash_attention", false], [93, "module-lmflow.utils.flash_attention.llama_flash_attention", false], [94, "module-lmflow.utils.flash_attention.triton_flash_attention", false], [95, "module-lmflow.utils", false], [96, "module-lmflow.utils.llava_conversation_lib", false], [97, "module-lmflow.utils.model", false], [98, "module-lmflow.utils.multimodal", false], [99, "module-lmflow.utils.position_interpolation", false], [100, "module-lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch", false], [101, "module-lmflow.utils.versioning", false], [102, "module-lmflow.version", false]], "mpt (lmflow.utils.llava_conversation_lib.separatorstyle attribute)": [[96, "lmflow.utils.llava_conversation_lib.SeparatorStyle.MPT", false]], "multimodaldatasetarguments (class in lmflow.args)": [[4, "lmflow.args.MultiModalDatasetArguments", false]], "nadam (class in lmflow.optim.nadam)": [[38, "lmflow.optim.nadam.NAdam", false]], "nadam (lmflow.args.optimizernames attribute)": [[4, "lmflow.args.OptimizerNames.NADAM", false]], "novograd (class in lmflow.optim.novograd)": [[39, "lmflow.optim.novograd.NovoGrad", false]], "novograd (lmflow.args.optimizernames attribute)": [[4, "lmflow.args.OptimizerNames.NOVOGRAD", false]], "ntk_ratio (lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch.condenserotaryembedding attribute)": [[100, "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch.CondenseRotaryEmbedding.ntk_ratio", false]], "num_examples() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.num_examples", false]], "num_output_sequences (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.num_output_sequences", false]], "num_patches (lmflow.models.vision_encoder.clip_encoder.clipvisiontower property)": [[23, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.num_patches", false]], "num_raft_iteration (lmflow.args.raftalignerarguments attribute)": [[4, "lmflow.args.RaftAlignerArguments.num_raft_iteration", false]], "observation_formatter (lmflow.utils.conversation_template.base.conversationtemplate attribute)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate.observation_formatter", false]], "observation_formatter (lmflow.utils.conversation_template.conversationtemplate attribute)": [[81, "lmflow.utils.conversation_template.ConversationTemplate.observation_formatter", false]], "offset (lmflow.utils.llava_conversation_lib.conversation attribute)": [[96, "lmflow.utils.llava_conversation_lib.Conversation.offset", false]], "on_epoch_end() (lmflow.pipeline.utils.peft_trainer.peftsavingcallback method)": [[65, "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback.on_epoch_end", false]], "on_save() (lmflow.pipeline.utils.peft_trainer.peftsavingcallback method)": [[65, "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback.on_save", false]], "on_train_end() (lmflow.pipeline.utils.peft_trainer.peftsavingcallback method)": [[65, "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback.on_train_end", false]], "optim_adam_beta1 (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.optim_adam_beta1", false]], "optim_adam_beta2 (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.optim_adam_beta2", false]], "optim_beta1 (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.optim_beta1", false]], "optim_beta2 (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.optim_beta2", false]], "optim_beta3 (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.optim_beta3", false]], "optim_dummy_beta1 (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.optim_dummy_beta1", false]], "optim_dummy_beta2 (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.optim_dummy_beta2", false]], "optim_momentum (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.optim_momentum", false]], "optim_weight_decay (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.optim_weight_decay", false]], "optimizer_name (in module lmflow.pipeline.utils.raft_trainer)": [[66, "lmflow.pipeline.utils.raft_trainer.OPTIMIZER_NAME", false]], "optimizer_type (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.optimizer_type", false]], "optimizernames (class in lmflow.args)": [[4, "lmflow.args.OptimizerNames", false]], "output (lmflow.utils.data_utils.rewardmodelinferenceresultwithinput attribute)": [[88, "lmflow.utils.data_utils.RewardModelInferenceResultWithInput.output", false]], "output (lmflow.utils.data_utils.vllminferenceresultwithinput attribute)": [[88, "lmflow.utils.data_utils.VLLMInferenceResultWithInput.output", false]], "output_dir (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.output_dir", false]], "output_dir (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.output_dir", false]], "output_dir (lmflow.args.iterativedpoalignerarguments attribute)": [[4, "lmflow.args.IterativeDPOAlignerArguments.output_dir", false]], "output_max_length (lmflow.args.raftalignerarguments attribute)": [[4, "lmflow.args.RaftAlignerArguments.output_max_length", false]], "output_min_length (lmflow.args.raftalignerarguments attribute)": [[4, "lmflow.args.RaftAlignerArguments.output_min_length", false]], "output_reward_path (lmflow.args.raftalignerarguments attribute)": [[4, "lmflow.args.RaftAlignerArguments.output_reward_path", false]], "overwrite_cache (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.overwrite_cache", false]], "pad_to_multiple_of (lmflow.pipeline.utils.rm_dataprocessor.rewarddatacollatorwithpadding attribute)": [[67, "lmflow.pipeline.utils.rm_dataprocessor.RewardDataCollatorWithPadding.pad_to_multiple_of", false]], "padding (lmflow.pipeline.utils.dpov2_dataprocessor.preferencedatacollatorwithpadding attribute)": [[60, "lmflow.pipeline.utils.dpov2_dataprocessor.PreferenceDataCollatorWithPadding.padding", false]], "padding (lmflow.pipeline.utils.rm_dataprocessor.rewarddatacollatorwithpadding attribute)": [[67, "lmflow.pipeline.utils.rm_dataprocessor.RewardDataCollatorWithPadding.padding", false]], "padding_side (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.padding_side", false]], "padding_value (lmflow.pipeline.utils.dpov2_dataprocessor.preferencedatacollatorwithpadding attribute)": [[60, "lmflow.pipeline.utils.dpov2_dataprocessor.PreferenceDataCollatorWithPadding.padding_value", false]], "paired_conversation_dataset_description (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.PAIRED_CONVERSATION_DATASET_DESCRIPTION", false]], "paired_conversation_tokenize_function() (in module lmflow.tokenization.hf_text_regression_model)": [[71, "lmflow.tokenization.hf_text_regression_model.paired_conversation_tokenize_function", false]], "paired_text_to_text_dataset_description (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.PAIRED_TEXT_TO_TEXT_DATASET_DESCRIPTION", false]], "parse_to_sampling_params() (lmflow.pipeline.vllm_inferencer.vllminferencer method)": [[69, "lmflow.pipeline.vllm_inferencer.VLLMInferencer.parse_to_sampling_params", false]], "peft_config (lmflow.models.hf_model_mixin.hfmodelmixin attribute)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.peft_config", false]], "peftrewardtrainer (class in lmflow.pipeline.utils.rm_trainer)": [[68, "lmflow.pipeline.utils.rm_trainer.PeftRewardTrainer", false]], "peftsavingcallback (class in lmflow.pipeline.utils.peft_trainer)": [[65, "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback", false]], "pefttrainer (class in lmflow.pipeline.utils.peft_trainer)": [[65, "lmflow.pipeline.utils.peft_trainer.PeftTrainer", false]], "per_device_eval_batch_size (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.per_device_eval_batch_size", false]], "per_device_train_batch_size (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.per_device_train_batch_size", false]], "phi3_template (in module lmflow.utils.conversation_template)": [[81, "lmflow.utils.conversation_template.PHI3_TEMPLATE", false]], "phi3_template (in module lmflow.utils.conversation_template.phi)": [[84, "lmflow.utils.conversation_template.phi.PHI3_TEMPLATE", false]], "pi_ratio (lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch.condenserotaryembedding attribute)": [[100, "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch.CondenseRotaryEmbedding.pi_ratio", false]], "pipeline_argument_mapping (in module lmflow.args)": [[4, "lmflow.args.PIPELINE_ARGUMENT_MAPPING", false]], "pipeline_mapping (in module lmflow.pipeline.auto_pipeline)": [[46, "lmflow.pipeline.auto_pipeline.PIPELINE_MAPPING", false]], "pipeline_needs_extras (in module lmflow.pipeline.auto_pipeline)": [[46, "lmflow.pipeline.auto_pipeline.PIPELINE_NEEDS_EXTRAS", false]], "place_model_on_device (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.place_model_on_device", false]], "plain (lmflow.utils.llava_conversation_lib.separatorstyle attribute)": [[96, "lmflow.utils.llava_conversation_lib.SeparatorStyle.PLAIN", false]], "pop_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.pop_callback", false]], "post_process_pairs() (lmflow.utils.conversation_template.base.conversationtemplate method)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate.post_process_pairs", false]], "post_process_pairs() (lmflow.utils.conversation_template.conversationtemplate method)": [[81, "lmflow.utils.conversation_template.ConversationTemplate.post_process_pairs", false]], "postprocess_distributed_inference_outputs() (lmflow.models.hf_text_regression_model.hftextregressionmodel static method)": [[16, "lmflow.models.hf_text_regression_model.HFTextRegressionModel.postprocess_distributed_inference_outputs", false]], "postprocess_inference_outputs() (lmflow.models.hf_text_regression_model.hftextregressionmodel static method)": [[16, "lmflow.models.hf_text_regression_model.HFTextRegressionModel.postprocess_inference_outputs", false]], "predict() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.predict", false]], "predict_next_token() (lmflow.pipeline.inferencer.speculativeinferencer static method)": [[55, "lmflow.pipeline.inferencer.SpeculativeInferencer.predict_next_token", false]], "prediction_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.prediction_loop", false]], "prediction_step() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.prediction_step", false]], "preferencedatacollatorwithpadding (class in lmflow.pipeline.utils.dpov2_dataprocessor)": [[60, "lmflow.pipeline.utils.dpov2_dataprocessor.PreferenceDataCollatorWithPadding", false]], "prepare_inputs_for_inference() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.prepare_inputs_for_inference", false]], "prepare_inputs_for_inference() (lmflow.models.hf_text_regression_model.hftextregressionmodel method)": [[16, "lmflow.models.hf_text_regression_model.HFTextRegressionModel.prepare_inputs_for_inference", false]], "prepare_inputs_labels_for_multimodal() (lmflow.models.vision_encoder.clip_encoder.clipvisiontower method)": [[23, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.prepare_inputs_labels_for_multimodal", false]], "preprocess_llama_from_llava_plain() (in module lmflow.datasets.multi_modal_dataset)": [[7, "lmflow.datasets.multi_modal_dataset.preprocess_llama_from_llava_plain", false]], "preprocess_llama_from_llava_v1() (in module lmflow.datasets.multi_modal_dataset)": [[7, "lmflow.datasets.multi_modal_dataset.preprocess_llama_from_llava_v1", false]], "preprocess_logits_for_metrics (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.preprocess_logits_for_metrics", false]], "preprocess_multimodal_llava() (in module lmflow.datasets.multi_modal_dataset)": [[7, "lmflow.datasets.multi_modal_dataset.preprocess_multimodal_llava", false]], "preprocessing_num_workers (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.preprocessing_num_workers", false]], "preset_templates (in module lmflow.utils.conversation_template)": [[81, "lmflow.utils.conversation_template.PRESET_TEMPLATES", false]], "pretrained_language_projection_path (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.pretrained_language_projection_path", false]], "print_banner() (in module lmflow.utils.common)": [[73, "lmflow.utils.common.print_banner", false]], "process_image_flag() (in module lmflow.utils.data_utils)": [[88, "lmflow.utils.data_utils.process_image_flag", false]], "processor_image_token_in_minigpt4() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[22, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.processor_image_token_in_minigpt4", false]], "prompt_cache_path (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.prompt_cache_path", false]], "prompt_structure (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.prompt_structure", false]], "push_to_hub() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.push_to_hub", false]], "qformer_from_pretrained() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[22, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.qformer_from_pretrained", false]], "qformer_name_or_path (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.qformer_name_or_path", false]], "quant_config (lmflow.models.hf_model_mixin.hfmodelmixin attribute)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.quant_config", false]], "quant_type (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.quant_type", false]], "qwen2_template (in module lmflow.utils.conversation_template)": [[81, "lmflow.utils.conversation_template.QWEN2_TEMPLATE", false]], "qwen2_template (in module lmflow.utils.conversation_template.qwen)": [[85, "lmflow.utils.conversation_template.qwen.QWEN2_TEMPLATE", false]], "qwen2_template_for_tool (in module lmflow.utils.conversation_template)": [[81, "lmflow.utils.conversation_template.QWEN2_TEMPLATE_FOR_TOOL", false]], "qwen2_template_for_tool (in module lmflow.utils.conversation_template.qwen)": [[85, "lmflow.utils.conversation_template.qwen.QWEN2_TEMPLATE_FOR_TOOL", false]], "radam (class in lmflow.optim.radam)": [[41, "lmflow.optim.radam.RAdam", false]], "radam (lmflow.args.optimizernames attribute)": [[4, "lmflow.args.OptimizerNames.RADAM", false]], "raft_batch_size (lmflow.args.raftalignerarguments attribute)": [[4, "lmflow.args.RaftAlignerArguments.raft_batch_size", false]], "raftaligner (class in lmflow.pipeline.raft_aligner)": [[57, "lmflow.pipeline.raft_aligner.RaftAligner", false]], "raftalignerarguments (class in lmflow.args)": [[4, "lmflow.args.RaftAlignerArguments", false]], "rafttrainer (class in lmflow.pipeline.utils.raft_trainer)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer", false]], "random_seed (lmflow.args.dpov2alignerarguments attribute)": [[4, "lmflow.args.DPOv2AlignerArguments.random_seed", false]], "random_seed (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.random_seed", false]], "random_seed (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.random_seed", false]], "random_shuffle (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.random_shuffle", false]], "rectify (lmflow.optim.adabelief.adabelief attribute)": [[25, "lmflow.optim.adabelief.AdaBelief.rectify", false]], "ref_model_args (lmflow.pipeline.dpov2_aligner.dpov2aligner attribute)": [[51, "lmflow.pipeline.dpov2_aligner.DPOv2Aligner.ref_model_args", false]], "ref_model_args (lmflow.pipeline.dpov2_aligner.memorysafedpov2aligner attribute)": [[51, "lmflow.pipeline.dpov2_aligner.MemorySafeDPOv2Aligner.ref_model_args", false]], "ref_model_args (lmflow.pipeline.iterative_dpo_aligner.iterativedpoaligner attribute)": [[56, "lmflow.pipeline.iterative_dpo_aligner.IterativeDPOAligner.ref_model_args", false]], "referencemodelarguments (in module lmflow.pipeline.dpov2_aligner)": [[51, "lmflow.pipeline.dpov2_aligner.ReferenceModelArguments", false]], "referencemodelarguments (in module lmflow.pipeline.utils.memory_safe_dpov2_align)": [[63, "lmflow.pipeline.utils.memory_safe_dpov2_align.ReferenceModelArguments", false]], "register_inference_function() (lmflow.models.text_regression_model.textregressionmodel method)": [[21, "lmflow.models.text_regression_model.TextRegressionModel.register_inference_function", false]], "register_prompt_cache() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[22, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.register_prompt_cache", false]], "register_tokenizer() (lmflow.datasets.multi_modal_dataset.custommultimodaldataset method)": [[7, "lmflow.datasets.multi_modal_dataset.CustomMultiModalDataset.register_tokenizer", false]], "regressionmodel (class in lmflow.models.regression_model)": [[20, "lmflow.models.regression_model.RegressionModel", false]], "remove_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.remove_callback", false]], "remove_dataclass_attr_prefix() (in module lmflow.utils.common)": [[73, "lmflow.utils.common.remove_dataclass_attr_prefix", false]], "remove_last_sep (lmflow.utils.conversation_template.base.conversationtemplate attribute)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate.remove_last_sep", false]], "remove_last_sep (lmflow.utils.conversation_template.conversationtemplate attribute)": [[81, "lmflow.utils.conversation_template.ConversationTemplate.remove_last_sep", false]], "remove_last_separator() (lmflow.utils.conversation_template.base.conversationtemplate method)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate.remove_last_separator", false]], "remove_last_separator() (lmflow.utils.conversation_template.conversationtemplate method)": [[81, "lmflow.utils.conversation_template.ConversationTemplate.remove_last_separator", false]], "remove_unused_columns (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.remove_unused_columns", false]], "repetition_penalty (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.repetition_penalty", false]], "repetition_penalty (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.repetition_penalty", false]], "replace_bloom_attn_with_flash_attn() (in module lmflow.utils.flash_attention.bloom_flash_attention)": [[89, "lmflow.utils.flash_attention.bloom_flash_attention.replace_bloom_attn_with_flash_attn", false]], "replace_gpt2_attn_with_flash_attn() (in module lmflow.utils.flash_attention.gpt2_flash_attention)": [[90, "lmflow.utils.flash_attention.gpt2_flash_attention.replace_gpt2_attn_with_flash_attn", false]], "replace_gpt_neo_attn_with_flash_attn() (in module lmflow.utils.flash_attention.gpt_neo_flash_attention)": [[91, "lmflow.utils.flash_attention.gpt_neo_flash_attention.replace_gpt_neo_attn_with_flash_attn", false]], "replace_llama_attn_with_flash_attn() (in module lmflow.utils.flash_attention.llama_flash_attention)": [[93, "lmflow.utils.flash_attention.llama_flash_attention.replace_llama_attn_with_flash_attn", false]], "replace_llama_with_condense() (in module lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch)": [[100, "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch.replace_llama_with_condense", false]], "report_to (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.report_to", false]], "reset() (lmflow.optim.adabelief.adabelief method)": [[25, "lmflow.optim.adabelief.AdaBelief.reset", false]], "restart_opt() (lmflow.optim.adan.adan method)": [[33, "lmflow.optim.adan.Adan.restart_opt", false]], "results_path (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.results_path", false]], "return_code_error_buffer (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.RETURN_CODE_ERROR_BUFFER", false]], "return_tensors (lmflow.pipeline.utils.rm_dataprocessor.rewarddatacollatorwithpadding attribute)": [[67, "lmflow.pipeline.utils.rm_dataprocessor.RewardDataCollatorWithPadding.return_tensors", false]], "reward_model_args (lmflow.pipeline.iterative_dpo_aligner.iterativedpoaligner attribute)": [[56, "lmflow.pipeline.iterative_dpo_aligner.IterativeDPOAligner.reward_model_args", false]], "reward_model_inference_batch_size (lmflow.args.iterativedpoalignerarguments attribute)": [[4, "lmflow.args.IterativeDPOAlignerArguments.reward_model_inference_batch_size", false]], "reward_model_inference_block_size (lmflow.args.iterativedpoalignerarguments attribute)": [[4, "lmflow.args.IterativeDPOAlignerArguments.reward_model_inference_block_size", false]], "rewarddatacollatorwithpadding (class in lmflow.pipeline.utils.rm_dataprocessor)": [[67, "lmflow.pipeline.utils.rm_dataprocessor.RewardDataCollatorWithPadding", false]], "rewardmodelinferencer (class in lmflow.pipeline.rm_inferencer)": [[58, "lmflow.pipeline.rm_inferencer.RewardModelInferencer", false]], "rewardmodelinferenceresultwithinput (class in lmflow.utils.data_utils)": [[88, "lmflow.utils.data_utils.RewardModelInferenceResultWithInput", false]], "rewardmodeltuner (class in lmflow.pipeline.rm_tuner)": [[59, "lmflow.pipeline.rm_tuner.RewardModelTuner", false]], "rewardmodeltunerarguments (class in lmflow.args)": [[4, "lmflow.args.RewardModelTunerArguments", false]], "rewardtrainer (class in lmflow.pipeline.utils.rm_trainer)": [[68, "lmflow.pipeline.utils.rm_trainer.RewardTrainer", false]], "rm_loss() (in module lmflow.pipeline.utils.rm_trainer)": [[68, "lmflow.pipeline.utils.rm_trainer.rm_loss", false]], "roles (lmflow.utils.llava_conversation_lib.conversation attribute)": [[96, "lmflow.utils.llava_conversation_lib.Conversation.roles", false]], "rope_ntk_ratio (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.rope_ntk_ratio", false]], "rope_pi_ratio (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.rope_pi_ratio", false]], "rstrip_partial_utf8() (in module lmflow.pipeline.inferencer)": [[55, "lmflow.pipeline.inferencer.rstrip_partial_utf8", false]], "run_name (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.run_name", false]], "sample() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.sample", false]], "sample() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.sample", false]], "sample() (lmflow.pipeline.inferencer.speculativeinferencer static method)": [[55, "lmflow.pipeline.inferencer.SpeculativeInferencer.sample", false]], "sampling_paired_idx_from_rewards() (lmflow.pipeline.dpov2_aligner.dpov2aligner method)": [[51, "lmflow.pipeline.dpov2_aligner.DPOv2Aligner.sampling_paired_idx_from_rewards", false]], "sampling_paired_method (lmflow.args.dpov2alignerarguments attribute)": [[4, "lmflow.args.DPOv2AlignerArguments.sampling_paired_method", false]], "sampling_params (lmflow.pipeline.vllm_inferencer.vllminferencer attribute)": [[69, "lmflow.pipeline.vllm_inferencer.VLLMInferencer.sampling_params", false]], "sanity_check (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.sanity_check", false]], "sanity_check() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.sanity_check", false]], "sanity_check() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.sanity_check", false]], "save() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.save", false]], "save() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.save", false]], "save() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.save", false]], "save() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.save", false]], "save() (lmflow.models.hf_text_regression_model.hftextregressionmodel method)": [[16, "lmflow.models.hf_text_regression_model.HFTextRegressionModel.save", false]], "save_aggregated_lora (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.save_aggregated_lora", false]], "save_counter (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.save_counter", false]], "save_inference_results() (lmflow.pipeline.vllm_inferencer.inferencerwithoffloading method)": [[69, "lmflow.pipeline.vllm_inferencer.InferencerWithOffloading.save_inference_results", false]], "save_inference_results() (lmflow.pipeline.vllm_inferencer.vllminferencer method)": [[69, "lmflow.pipeline.vllm_inferencer.VLLMInferencer.save_inference_results", false]], "save_language_projection (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.save_language_projection", false]], "save_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.save_model", false]], "save_pretrain_model_path (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.save_pretrain_model_path", false]], "save_prompt_cache() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[22, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.save_prompt_cache", false]], "save_results (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.save_results", false]], "save_steps (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.save_steps", false]], "scaler_name (in module lmflow.pipeline.utils.raft_trainer)": [[66, "lmflow.pipeline.utils.raft_trainer.SCALER_NAME", false]], "scheduler_name (in module lmflow.pipeline.utils.raft_trainer)": [[66, "lmflow.pipeline.utils.raft_trainer.SCHEDULER_NAME", false]], "score_to_prob() (lmflow.pipeline.inferencer.speculativeinferencer static method)": [[55, "lmflow.pipeline.inferencer.SpeculativeInferencer.score_to_prob", false]], "seed (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.seed", false]], "select_feature (lmflow.models.vision_encoder.clip_encoder.clipvisiontower attribute)": [[23, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.select_feature", false]], "select_layer (lmflow.models.vision_encoder.clip_encoder.clipvisiontower attribute)": [[23, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.select_layer", false]], "sep (lmflow.utils.llava_conversation_lib.conversation attribute)": [[96, "lmflow.utils.llava_conversation_lib.Conversation.sep", false]], "sep2 (lmflow.utils.llava_conversation_lib.conversation attribute)": [[96, "lmflow.utils.llava_conversation_lib.Conversation.sep2", false]], "sep_style (lmflow.args.multimodaldatasetarguments attribute)": [[4, "lmflow.args.MultiModalDatasetArguments.sep_style", false]], "sep_style (lmflow.utils.llava_conversation_lib.conversation attribute)": [[96, "lmflow.utils.llava_conversation_lib.Conversation.sep_style", false]], "separator (lmflow.utils.conversation_template.base.conversationtemplate attribute)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate.separator", false]], "separator (lmflow.utils.conversation_template.conversationtemplate attribute)": [[81, "lmflow.utils.conversation_template.ConversationTemplate.separator", false]], "separatorstyle (class in lmflow.utils.llava_conversation_lib)": [[96, "lmflow.utils.llava_conversation_lib.SeparatorStyle", false]], "set_random_seed() (in module lmflow.utils.data_utils)": [[88, "lmflow.utils.data_utils.set_random_seed", false]], "sgd_schedule_free (lmflow.args.optimizernames attribute)": [[4, "lmflow.args.OptimizerNames.SGD_SCHEDULE_FREE", false]], "sgdp (class in lmflow.optim.sgdp)": [[43, "lmflow.optim.sgdp.SGDP", false]], "sgdp (lmflow.args.optimizernames attribute)": [[4, "lmflow.args.OptimizerNames.SGDP", false]], "sgdschedulefree (class in lmflow.optim.sgd_schedule_free)": [[42, "lmflow.optim.sgd_schedule_free.SGDScheduleFree", false]], "sharded_ddp (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.sharded_ddp", false]], "single (lmflow.utils.llava_conversation_lib.separatorstyle attribute)": [[96, "lmflow.utils.llava_conversation_lib.SeparatorStyle.SINGLE", false]], "skip_first_batches (in module lmflow.pipeline.utils.raft_trainer)": [[66, "lmflow.pipeline.utils.raft_trainer.skip_first_batches", false]], "skip_next (lmflow.utils.llava_conversation_lib.conversation attribute)": [[96, "lmflow.utils.llava_conversation_lib.Conversation.skip_next", false]], "sophia (lmflow.args.optimizernames attribute)": [[4, "lmflow.args.OptimizerNames.SOPHIA", false]], "sophiag (class in lmflow.optim.sophia)": [[44, "lmflow.optim.sophia.SophiaG", false]], "special_starter (lmflow.utils.conversation_template.base.conversationtemplate attribute)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate.special_starter", false]], "special_starter (lmflow.utils.conversation_template.conversationtemplate attribute)": [[81, "lmflow.utils.conversation_template.ConversationTemplate.special_starter", false]], "special_stopper (lmflow.utils.conversation_template.base.conversationtemplate attribute)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate.special_stopper", false]], "special_stopper (lmflow.utils.conversation_template.conversationtemplate attribute)": [[81, "lmflow.utils.conversation_template.ConversationTemplate.special_stopper", false]], "speculativeinferencer (class in lmflow.pipeline.inferencer)": [[55, "lmflow.pipeline.inferencer.SpeculativeInferencer", false]], "split_args() (in module lmflow.args)": [[4, "lmflow.args.split_args", false]], "state (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.state", false]], "step() (lmflow.optim.adabelief.adabelief method)": [[25, "lmflow.optim.adabelief.AdaBelief.step", false]], "step() (lmflow.optim.adabound.adabound method)": [[26, "lmflow.optim.adabound.AdaBound.step", false]], "step() (lmflow.optim.adadelta.adadelta method)": [[27, "lmflow.optim.adadelta.Adadelta.step", false]], "step() (lmflow.optim.adagrad.adagrad method)": [[28, "lmflow.optim.adagrad.AdaGrad.step", false]], "step() (lmflow.optim.adam.adam method)": [[29, "lmflow.optim.adam.Adam.step", false]], "step() (lmflow.optim.adamax.adamax method)": [[30, "lmflow.optim.adamax.Adamax.step", false]], "step() (lmflow.optim.adamp.adamp method)": [[31, "lmflow.optim.adamp.AdamP.step", false]], "step() (lmflow.optim.adamw_schedule_free.adamwschedulefree method)": [[32, "lmflow.optim.adamw_schedule_free.AdamWScheduleFree.step", false]], "step() (lmflow.optim.adan.adan method)": [[33, "lmflow.optim.adan.Adan.step", false]], "step() (lmflow.optim.dummy.dummy method)": [[34, "lmflow.optim.dummy.Dummy.step", false]], "step() (lmflow.optim.lamb.lamb method)": [[36, "lmflow.optim.lamb.Lamb.step", false]], "step() (lmflow.optim.lars.lars method)": [[37, "lmflow.optim.lars.LARS.step", false]], "step() (lmflow.optim.nadam.nadam method)": [[38, "lmflow.optim.nadam.NAdam.step", false]], "step() (lmflow.optim.novograd.novograd method)": [[39, "lmflow.optim.novograd.NovoGrad.step", false]], "step() (lmflow.optim.radam.radam method)": [[41, "lmflow.optim.radam.RAdam.step", false]], "step() (lmflow.optim.sgd_schedule_free.sgdschedulefree method)": [[42, "lmflow.optim.sgd_schedule_free.SGDScheduleFree.step", false]], "step() (lmflow.optim.sgdp.sgdp method)": [[43, "lmflow.optim.sgdp.SGDP.step", false]], "step() (lmflow.optim.sophia.sophiag method)": [[44, "lmflow.optim.sophia.SophiaG.step", false]], "step() (lmflow.optim.yogi.yogi method)": [[45, "lmflow.optim.yogi.Yogi.step", false]], "store_flos() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.store_flos", false]], "stream_inference() (lmflow.pipeline.inferencer.inferencer method)": [[55, "lmflow.pipeline.inferencer.Inferencer.stream_inference", false]], "stream_inference() (lmflow.pipeline.inferencer.speculativeinferencer method)": [[55, "lmflow.pipeline.inferencer.SpeculativeInferencer.stream_inference", false]], "streaming (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.streaming", false]], "stringformatter (class in lmflow.utils.conversation_template.base)": [[75, "lmflow.utils.conversation_template.base.StringFormatter", false]], "supported_dataset_type (in module lmflow.pipeline.inferencer)": [[55, "lmflow.pipeline.inferencer.supported_dataset_type", false]], "system (lmflow.utils.llava_conversation_lib.conversation attribute)": [[96, "lmflow.utils.llava_conversation_lib.Conversation.system", false]], "system_formatter (lmflow.utils.conversation_template.base.conversationtemplate attribute)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate.system_formatter", false]], "system_formatter (lmflow.utils.conversation_template.conversationtemplate attribute)": [[81, "lmflow.utils.conversation_template.ConversationTemplate.system_formatter", false]], "temperature (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.temperature", false]], "temperature (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.temperature", false]], "template (lmflow.utils.conversation_template.base.formatter attribute)": [[75, "lmflow.utils.conversation_template.base.Formatter.template", false]], "template_name (lmflow.utils.conversation_template.base.conversationtemplate attribute)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate.template_name", false]], "template_name (lmflow.utils.conversation_template.conversationtemplate attribute)": [[81, "lmflow.utils.conversation_template.ConversationTemplate.template_name", false]], "templatecomponent (class in lmflow.utils.conversation_template.base)": [[75, "lmflow.utils.conversation_template.base.TemplateComponent", false]], "tensor_parallel_size (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.tensor_parallel_size", false]], "test_file (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.test_file", false]], "text2text_dataset_description (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.TEXT2TEXT_DATASET_DESCRIPTION", false]], "text2text_dataset_details (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.TEXT2TEXT_DATASET_DETAILS", false]], "text2text_dataset_long_descrition (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.TEXT2TEXT_DATASET_LONG_DESCRITION", false]], "text_only_dataset_description (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.TEXT_ONLY_DATASET_DESCRIPTION", false]], "text_only_dataset_details (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.TEXT_ONLY_DATASET_DETAILS", false]], "text_only_dataset_long_descrition (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.TEXT_ONLY_DATASET_LONG_DESCRITION", false]], "text_to_scored_textlist_dataset_description (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.TEXT_TO_SCORED_TEXTLIST_DATASET_DESCRIPTION", false]], "text_to_textlist_dataset_description (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.TEXT_TO_TEXTLIST_DATASET_DESCRIPTION", false]], "text_to_textlist_tokenize_function() (in module lmflow.tokenization.hf_text_regression_model)": [[71, "lmflow.tokenization.hf_text_regression_model.text_to_textlist_tokenize_function", false]], "textregressionmodel (class in lmflow.models.text_regression_model)": [[21, "lmflow.models.text_regression_model.TextRegressionModel", false]], "to_dict() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.to_dict", false]], "to_dict() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.to_dict", false]], "to_gradio_chatbot() (lmflow.utils.llava_conversation_lib.conversation method)": [[96, "lmflow.utils.llava_conversation_lib.Conversation.to_gradio_chatbot", false]], "to_list() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.to_list", false]], "to_list() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.to_list", false]], "tok_logger (in module lmflow.tokenization.hf_decoder_model)": [[70, "lmflow.tokenization.hf_decoder_model.tok_logger", false]], "tok_logger (in module lmflow.tokenization.hf_text_regression_model)": [[71, "lmflow.tokenization.hf_text_regression_model.tok_logger", false]], "token (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.token", false]], "tokenize() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.tokenize", false]], "tokenize() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.tokenize", false]], "tokenize() (lmflow.models.hf_text_regression_model.hftextregressionmodel method)": [[16, "lmflow.models.hf_text_regression_model.HFTextRegressionModel.tokenize", false]], "tokenize_batch_element() (lmflow.pipeline.utils.dpov2_dataprocessor.preferencedatacollatorwithpadding method)": [[60, "lmflow.pipeline.utils.dpov2_dataprocessor.PreferenceDataCollatorWithPadding.tokenize_batch_element", false]], "tokenize_function() (in module lmflow.tokenization.hf_decoder_model)": [[70, "lmflow.tokenization.hf_decoder_model.tokenize_function", false]], "tokenize_function() (in module lmflow.tokenization.hf_text_regression_model)": [[71, "lmflow.tokenization.hf_text_regression_model.tokenize_function", false]], "tokenizer (lmflow.datasets.multi_modal_dataset.datacollatorforsuperviseddataset attribute)": [[7, "lmflow.datasets.multi_modal_dataset.DataCollatorForSupervisedDataset.tokenizer", false]], "tokenizer (lmflow.models.hf_model_mixin.hfmodelmixin attribute)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.tokenizer", false]], "tokenizer (lmflow.pipeline.utils.dpov2_dataprocessor.preferencedatacollatorwithpadding attribute)": [[60, "lmflow.pipeline.utils.dpov2_dataprocessor.PreferenceDataCollatorWithPadding.tokenizer", false]], "tokenizer (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.tokenizer", false]], "tokenizer (lmflow.pipeline.utils.rm_dataprocessor.rewarddatacollatorwithpadding attribute)": [[67, "lmflow.pipeline.utils.rm_dataprocessor.RewardDataCollatorWithPadding.tokenizer", false]], "tokenizer_image_token() (in module lmflow.datasets.multi_modal_dataset)": [[7, "lmflow.datasets.multi_modal_dataset.tokenizer_image_token", false]], "tokenizer_name (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.tokenizer_name", false]], "toolinferencer (class in lmflow.pipeline.inferencer)": [[55, "lmflow.pipeline.inferencer.ToolInferencer", false]], "tools_formatter (lmflow.utils.conversation_template.base.conversationtemplate attribute)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate.tools_formatter", false]], "tools_formatter (lmflow.utils.conversation_template.conversationtemplate attribute)": [[81, "lmflow.utils.conversation_template.ConversationTemplate.tools_formatter", false]], "top_k (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.top_k", false]], "top_p (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.top_p", false]], "top_reward_percentage (lmflow.args.raftalignerarguments attribute)": [[4, "lmflow.args.RaftAlignerArguments.top_reward_percentage", false]], "torch_dtype (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.torch_dtype", false]], "torch_dtype (lmflow.models.hf_model_mixin.hfmodelmixin attribute)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.torch_dtype", false]], "torch_jit_model_eval() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.torch_jit_model_eval", false]], "train() (lmflow.optim.adamw_schedule_free.adamwschedulefree method)": [[32, "lmflow.optim.adamw_schedule_free.AdamWScheduleFree.train", false]], "train() (lmflow.optim.sgd_schedule_free.sgdschedulefree method)": [[42, "lmflow.optim.sgd_schedule_free.SGDScheduleFree.train", false]], "train() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.train", false]], "train_dataset (lmflow.pipeline.dpo_aligner.dpoaligner attribute)": [[50, "lmflow.pipeline.dpo_aligner.DPOAligner.train_dataset", false]], "train_dataset (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.train_dataset", false]], "train_file (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.train_file", false]], "train_on_prompt (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.train_on_prompt", false]], "train_test_split() (lmflow.datasets.dataset method)": [[6, "lmflow.datasets.Dataset.train_test_split", false]], "train_test_split() (lmflow.datasets.dataset.dataset method)": [[5, "lmflow.datasets.dataset.Dataset.train_test_split", false]], "trainer_state_name (in module lmflow.pipeline.utils.raft_trainer)": [[66, "lmflow.pipeline.utils.raft_trainer.TRAINER_STATE_NAME", false]], "training_args_name (in module lmflow.pipeline.utils.raft_trainer)": [[66, "lmflow.pipeline.utils.raft_trainer.TRAINING_ARGS_NAME", false]], "training_step() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.training_step", false]], "truncate_to_model_max_length (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.truncate_to_model_max_length", false]], "truncation_mode (lmflow.pipeline.utils.dpov2_dataprocessor.preferencedatacollatorwithpadding attribute)": [[60, "lmflow.pipeline.utils.dpov2_dataprocessor.PreferenceDataCollatorWithPadding.truncation_mode", false]], "truncation_side (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.truncation_side", false]], "trust_remote_code (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.trust_remote_code", false]], "tunable (class in lmflow.models.interfaces.tunable)": [[19, "lmflow.models.interfaces.tunable.Tunable", false]], "tune() (lmflow.pipeline.base_tuner.basetuner method)": [[49, "lmflow.pipeline.base_tuner.BaseTuner.tune", false]], "tune() (lmflow.pipeline.finetuner.finetuner method)": [[53, "lmflow.pipeline.finetuner.Finetuner.tune", false]], "tune() (lmflow.pipeline.rm_tuner.rewardmodeltuner method)": [[59, "lmflow.pipeline.rm_tuner.RewardModelTuner.tune", false]], "two (lmflow.utils.llava_conversation_lib.separatorstyle attribute)": [[96, "lmflow.utils.llava_conversation_lib.SeparatorStyle.TWO", false]], "type (lmflow.datasets.dataset attribute)": [[6, "lmflow.datasets.Dataset.type", false]], "type (lmflow.datasets.dataset.dataset attribute)": [[5, "lmflow.datasets.dataset.Dataset.type", false]], "type (lmflow.utils.conversation_template.base.templatecomponent attribute)": [[75, "lmflow.utils.conversation_template.base.TemplateComponent.type", false]], "update_custom_config() (in module lmflow.utils.multimodal)": [[98, "lmflow.utils.multimodal.update_custom_config", false]], "update_hessian() (lmflow.optim.sophia.sophiag method)": [[44, "lmflow.optim.sophia.SophiaG.update_hessian", false]], "use_accelerator (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.use_accelerator", false]], "use_accelerator (lmflow.models.hf_model_mixin.hfmodelmixin attribute)": [[15, "lmflow.models.hf_model_mixin.HFModelMixin.use_accelerator", false]], "use_accelerator_for_evaluator (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.use_accelerator_for_evaluator", false]], "use_apex (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.use_apex", false]], "use_beam_search (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.use_beam_search", false]], "use_cpu_amp (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.use_cpu_amp", false]], "use_cuda_amp (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.use_cuda_amp", false]], "use_customized_optim (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.use_customized_optim", false]], "use_dora (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.use_dora", false]], "use_dpo_data_collator (lmflow.pipeline.utils.dpov2_trainer.dpov2trainer attribute)": [[61, "lmflow.pipeline.utils.dpov2_trainer.DPOv2Trainer.use_dpo_data_collator", false]], "use_fast_tokenizer (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.use_fast_tokenizer", false]], "use_flash_attention (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.use_flash_attention", false]], "use_image_start_end (lmflow.args.multimodaldatasetarguments attribute)": [[4, "lmflow.args.MultiModalDatasetArguments.use_image_start_end", false]], "use_int8 (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.use_int8", false]], "use_lisa (lmflow.args.finetunerarguments attribute)": [[4, "lmflow.args.FinetunerArguments.use_lisa", false]], "use_lora (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.use_lora", false]], "use_prompt_cache (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.use_prompt_cache", false]], "use_qlora (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.use_qlora", false]], "use_ram_optimized_load (lmflow.args.modelarguments attribute)": [[4, "lmflow.args.ModelArguments.use_ram_optimized_load", false]], "use_tune_checkpoints (lmflow.pipeline.utils.raft_trainer.rafttrainer attribute)": [[66, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.use_tune_checkpoints", false]], "use_vllm (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.use_vllm", false]], "use_wandb (lmflow.args.evaluatorarguments attribute)": [[4, "lmflow.args.EvaluatorArguments.use_wandb", false]], "user_formatter (lmflow.utils.conversation_template.base.conversationtemplate attribute)": [[75, "lmflow.utils.conversation_template.base.ConversationTemplate.user_formatter", false]], "user_formatter (lmflow.utils.conversation_template.conversationtemplate attribute)": [[81, "lmflow.utils.conversation_template.ConversationTemplate.user_formatter", false]], "validation_file (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.validation_file", false]], "validation_split_percentage (lmflow.args.datasetarguments attribute)": [[4, "lmflow.args.DatasetArguments.validation_split_percentage", false]], "version (lmflow.utils.llava_conversation_lib.conversation attribute)": [[96, "lmflow.utils.llava_conversation_lib.Conversation.version", false]], "vision_feature_select() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[22, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.vision_feature_select", false]], "vision_model_from_pretrained() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[22, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.vision_model_from_pretrained", false]], "vision_select_layer (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.vision_select_layer", false]], "vision_tower_name (lmflow.models.vision_encoder.clip_encoder.clipvisiontower attribute)": [[23, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.vision_tower_name", false]], "vismodelarguments (class in lmflow.args)": [[4, "lmflow.args.VisModelArguments", false]], "vllm_gpu_memory_utilization (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.vllm_gpu_memory_utilization", false]], "vllm_inference_batch_size (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.vllm_inference_batch_size", false]], "vllm_tensor_parallel_size (lmflow.args.inferencerarguments attribute)": [[4, "lmflow.args.InferencerArguments.vllm_tensor_parallel_size", false]], "vllminferencer (class in lmflow.pipeline.vllm_inferencer)": [[69, "lmflow.pipeline.vllm_inferencer.VLLMInferencer", false]], "vllminferenceresultwithinput (class in lmflow.utils.data_utils)": [[88, "lmflow.utils.data_utils.VLLMInferenceResultWithInput", false]], "warmup_steps (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.warmup_steps", false]], "weight_decay (lmflow.args.dpoalignerarguments attribute)": [[4, "lmflow.args.DPOAlignerArguments.weight_decay", false]], "weight_decouple (lmflow.optim.adabelief.adabelief attribute)": [[25, "lmflow.optim.adabelief.AdaBelief.weight_decouple", false]], "with_qformer (lmflow.args.vismodelarguments attribute)": [[4, "lmflow.args.VisModelArguments.with_qformer", false]], "with_qformer (lmflow.models.vision2seq_model.customautovision2seqmodel attribute)": [[22, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.with_qformer", false]], "worker_heart_beat_interval (in module lmflow.utils.constants)": [[74, "lmflow.utils.constants.WORKER_HEART_BEAT_INTERVAL", false]], "workspace_path (lmflow.pipeline.iterative_dpo_aligner.iterativedpoaligner attribute)": [[56, "lmflow.pipeline.iterative_dpo_aligner.IterativeDPOAligner.workspace_path", false]], "world_size (lmflow.pipeline.evaluator.evaluator attribute)": [[52, "lmflow.pipeline.evaluator.Evaluator.world_size", false]], "world_size (lmflow.pipeline.inferencer.inferencer attribute)": [[55, "lmflow.pipeline.inferencer.Inferencer.world_size", false]], "world_size (lmflow.pipeline.rm_inferencer.rewardmodelinferencer attribute)": [[58, "lmflow.pipeline.rm_inferencer.RewardModelInferencer.world_size", false]], "yi1_5_template (in module lmflow.utils.conversation_template)": [[81, "lmflow.utils.conversation_template.YI1_5_TEMPLATE", false]], "yi1_5_template (in module lmflow.utils.conversation_template.yi)": [[86, "lmflow.utils.conversation_template.yi.YI1_5_TEMPLATE", false]], "yogi (class in lmflow.optim.yogi)": [[45, "lmflow.optim.yogi.Yogi", false]], "yogi (lmflow.args.optimizernames attribute)": [[4, "lmflow.args.OptimizerNames.YOGI", false]], "zephyr_template (in module lmflow.utils.conversation_template)": [[81, "lmflow.utils.conversation_template.ZEPHYR_TEMPLATE", false]], "zephyr_template (in module lmflow.utils.conversation_template.zephyr)": [[87, "lmflow.utils.conversation_template.zephyr.ZEPHYR_TEMPLATE", false]], "zephyrconversationtemplate (class in lmflow.utils.conversation_template.zephyr)": [[87, "lmflow.utils.conversation_template.zephyr.ZephyrConversationTemplate", false]]}, "objects": {"": [[8, 0, 0, "-", "lmflow"]], "lmflow": [[8, 1, 1, "", "__version__"], [4, 0, 0, "-", "args"], [6, 0, 0, "-", "datasets"], [8, 1, 1, "", "internal_version"], [17, 0, 0, "-", "models"], [35, 0, 0, "-", "optim"], [54, 0, 0, "-", "pipeline"], [72, 0, 0, "-", "tokenization"], [95, 0, 0, "-", "utils"], [102, 0, 0, "-", "version"]], "lmflow.args": [[4, 2, 1, "", "AutoArguments"], [4, 2, 1, "", "BenchmarkingArguments"], [4, 2, 1, "", "DPOAlignerArguments"], [4, 2, 1, "", "DPOv2AlignerArguments"], [4, 2, 1, "", "DatasetArguments"], [4, 2, 1, "", "EvaluatorArguments"], [4, 2, 1, "", "FinetunerArguments"], [4, 2, 1, "", "InferencerArguments"], [4, 2, 1, "", "IterativeAlignerArguments"], [4, 2, 1, "", "IterativeDPOAlignerArguments"], [4, 1, 1, "", "MODEL_CONFIG_CLASSES"], [4, 1, 1, "", "MODEL_TYPES"], [4, 2, 1, "", "ModelArguments"], [4, 2, 1, "", "MultiModalDatasetArguments"], [4, 2, 1, "", "OptimizerNames"], [4, 1, 1, "", "PIPELINE_ARGUMENT_MAPPING"], [4, 2, 1, "", "RaftAlignerArguments"], [4, 2, 1, "", "RewardModelTunerArguments"], [4, 2, 1, "", "VisModelArguments"], [4, 1, 1, "", "logger"], [4, 5, 1, "", "split_args"]], "lmflow.args.AutoArguments": [[4, 3, 1, "", "get_pipeline_args_class"]], "lmflow.args.BenchmarkingArguments": [[4, 4, 1, "", "dataset_name"], [4, 4, 1, "", "lm_evaluation_metric"]], "lmflow.args.DPOAlignerArguments": [[4, 4, 1, "", "beta"], [4, 4, 1, "", "eval_dataset_path"], [4, 4, 1, "", "eval_steps"], [4, 4, 1, "", "gradient_accumulation_steps"], [4, 4, 1, "", "gradient_checkpointing"], [4, 4, 1, "", "gradient_checkpointing_use_reentrant"], [4, 4, 1, "", "learning_rate"], [4, 4, 1, "", "local_rank"], [4, 4, 1, "", "log_freq"], [4, 4, 1, "", "logging_steps"], [4, 4, 1, "", "lr_scheduler_type"], [4, 4, 1, "", "max_length"], [4, 4, 1, "", "max_prompt_length"], [4, 4, 1, "", "max_steps"], [4, 4, 1, "", "optimizer_type"], [4, 4, 1, "", "output_dir"], [4, 4, 1, "", "per_device_eval_batch_size"], [4, 4, 1, "", "per_device_train_batch_size"], [4, 4, 1, "", "report_to"], [4, 4, 1, "", "run_name"], [4, 4, 1, "", "sanity_check"], [4, 4, 1, "", "save_steps"], [4, 4, 1, "", "seed"], [4, 4, 1, "", "warmup_steps"], [4, 4, 1, "", "weight_decay"]], "lmflow.args.DPOv2AlignerArguments": [[4, 4, 1, "", "accelerate_config_file"], [4, 4, 1, "", "beta"], [4, 4, 1, "", "length_penalty"], [4, 4, 1, "", "loss_type"], [4, 4, 1, "", "margin_scale"], [4, 4, 1, "", "mask_prompt"], [4, 4, 1, "", "max_length"], [4, 4, 1, "", "max_prompt_length"], [4, 4, 1, "", "random_seed"], [4, 4, 1, "", "sampling_paired_method"]], "lmflow.args.DatasetArguments": [[4, 3, 1, "", "__post_init__"], [4, 4, 1, "", "block_size"], [4, 4, 1, "", "conversation_template"], [4, 4, 1, "", "customized_cache_dir"], [4, 4, 1, "", "dataset_config_name"], [4, 4, 1, "", "dataset_name"], [4, 4, 1, "", "dataset_path"], [4, 4, 1, "", "disable_group_texts"], [4, 4, 1, "", "group_texts_batch_size"], [4, 4, 1, "", "is_custom_dataset"], [4, 4, 1, "", "keep_linebreaks"], [4, 4, 1, "", "max_eval_samples"], [4, 4, 1, "", "max_train_samples"], [4, 4, 1, "", "overwrite_cache"], [4, 4, 1, "", "preprocessing_num_workers"], [4, 4, 1, "", "streaming"], [4, 4, 1, "", "test_file"], [4, 4, 1, "", "train_file"], [4, 4, 1, "", "train_on_prompt"], [4, 4, 1, "", "validation_file"], [4, 4, 1, "", "validation_split_percentage"]], "lmflow.args.EvaluatorArguments": [[4, 4, 1, "", "answer_type"], [4, 4, 1, "", "deepspeed"], [4, 4, 1, "", "evaluate_block_size"], [4, 4, 1, "", "inference_batch_size_per_device"], [4, 4, 1, "", "local_rank"], [4, 4, 1, "", "max_new_tokens"], [4, 4, 1, "", "metric"], [4, 4, 1, "", "mixed_precision"], [4, 4, 1, "", "output_dir"], [4, 4, 1, "", "prompt_structure"], [4, 4, 1, "", "random_seed"], [4, 4, 1, "", "random_shuffle"], [4, 4, 1, "", "repetition_penalty"], [4, 4, 1, "", "temperature"], [4, 4, 1, "", "use_accelerator_for_evaluator"], [4, 4, 1, "", "use_wandb"]], "lmflow.args.FinetunerArguments": [[4, 4, 1, "", "customized_optim"], [4, 4, 1, "", "customized_optim_args"], [4, 4, 1, "", "eval_dataset_path"], [4, 4, 1, "", "finetune_part"], [4, 4, 1, "", "lisa_activated_layers"], [4, 4, 1, "", "lisa_interval_steps"], [4, 4, 1, "", "lisa_layers_attribute"], [4, 4, 1, "", "optim_adam_beta1"], [4, 4, 1, "", "optim_adam_beta2"], [4, 4, 1, "", "optim_beta1"], [4, 4, 1, "", "optim_beta2"], [4, 4, 1, "", "optim_beta3"], [4, 4, 1, "", "optim_dummy_beta1"], [4, 4, 1, "", "optim_dummy_beta2"], [4, 4, 1, "", "optim_momentum"], [4, 4, 1, "", "optim_weight_decay"], [4, 4, 1, "", "remove_unused_columns"], [4, 4, 1, "", "save_language_projection"], [4, 4, 1, "", "use_customized_optim"], [4, 4, 1, "", "use_lisa"]], "lmflow.args.InferencerArguments": [[4, 3, 1, "", "__post_init__"], [4, 4, 1, "", "additional_stop_token_ids"], [4, 4, 1, "", "apply_chat_template"], [4, 4, 1, "", "deepspeed"], [4, 4, 1, "", "device"], [4, 4, 1, "", "distributed_inference_num_instances"], [4, 4, 1, "", "do_sample"], [4, 4, 1, "", "enable_decode_inference_result"], [4, 4, 1, "", "enable_distributed_inference"], [4, 4, 1, "", "inference_batch_size"], [4, 4, 1, "", "local_rank"], [4, 4, 1, "", "max_new_tokens"], [4, 4, 1, "", "mixed_precision"], [4, 4, 1, "", "num_output_sequences"], [4, 4, 1, "", "random_seed"], [4, 4, 1, "", "repetition_penalty"], [4, 4, 1, "", "results_path"], [4, 4, 1, "", "save_results"], [4, 4, 1, "", "temperature"], [4, 4, 1, "", "tensor_parallel_size"], [4, 4, 1, "", "top_k"], [4, 4, 1, "", "top_p"], [4, 4, 1, "", "use_accelerator"], [4, 4, 1, "", "use_beam_search"], [4, 4, 1, "", "use_vllm"], [4, 4, 1, "", "vllm_gpu_memory_utilization"], [4, 4, 1, "", "vllm_inference_batch_size"], [4, 4, 1, "", "vllm_tensor_parallel_size"]], "lmflow.args.IterativeAlignerArguments": [[4, 4, 1, "", "dataset_path_list"], [4, 4, 1, "", "initial_iter_idx"]], "lmflow.args.IterativeDPOAlignerArguments": [[4, 4, 1, "", "do_dpo_align"], [4, 4, 1, "", "do_response_generation"], [4, 4, 1, "", "do_scoring"], [4, 4, 1, "", "output_dir"], [4, 4, 1, "", "reward_model_inference_batch_size"], [4, 4, 1, "", "reward_model_inference_block_size"]], "lmflow.args.ModelArguments": [[4, 3, 1, "", "__post_init__"], [4, 4, 1, "", "arch_type"], [4, 4, 1, "", "bits"], [4, 4, 1, "", "cache_dir"], [4, 4, 1, "", "config_name"], [4, 4, 1, "", "config_overrides"], [4, 4, 1, "", "do_rope_scaling"], [4, 4, 1, "", "double_quant"], [4, 4, 1, "", "eos_padding"], [4, 4, 1, "", "ignore_bias_buffers"], [4, 4, 1, "", "load_in_4bit"], [4, 4, 1, "", "lora_alpha"], [4, 4, 1, "", "lora_dropout"], [4, 4, 1, "", "lora_model_path"], [4, 4, 1, "", "lora_r"], [4, 4, 1, "", "lora_target_modules"], [4, 4, 1, "", "model_max_length"], [4, 4, 1, "", "model_name_or_path"], [4, 4, 1, "", "model_revision"], [4, 4, 1, "", "model_type"], [4, 4, 1, "", "padding_side"], [4, 4, 1, "", "quant_type"], [4, 4, 1, "", "rope_ntk_ratio"], [4, 4, 1, "", "rope_pi_ratio"], [4, 4, 1, "", "save_aggregated_lora"], [4, 4, 1, "", "token"], [4, 4, 1, "", "tokenizer_name"], [4, 4, 1, "", "torch_dtype"], [4, 4, 1, "", "truncate_to_model_max_length"], [4, 4, 1, "", "truncation_side"], [4, 4, 1, "", "trust_remote_code"], [4, 4, 1, "", "use_dora"], [4, 4, 1, "", "use_fast_tokenizer"], [4, 4, 1, "", "use_flash_attention"], [4, 4, 1, "", "use_int8"], [4, 4, 1, "", "use_lora"], [4, 4, 1, "", "use_qlora"], [4, 4, 1, "", "use_ram_optimized_load"]], "lmflow.args.MultiModalDatasetArguments": [[4, 4, 1, "", "image_aspect_ratio"], [4, 4, 1, "", "image_folder"], [4, 4, 1, "", "is_multimodal"], [4, 4, 1, "", "sep_style"], [4, 4, 1, "", "use_image_start_end"]], "lmflow.args.OptimizerNames": [[4, 4, 1, "", "ADABELIEF"], [4, 4, 1, "", "ADABOUND"], [4, 4, 1, "", "ADADELTA"], [4, 4, 1, "", "ADAGRAD"], [4, 4, 1, "", "ADAM"], [4, 4, 1, "", "ADAMAX"], [4, 4, 1, "", "ADAMP"], [4, 4, 1, "", "ADAMW_SCHEDULE_FREE"], [4, 4, 1, "", "ADAN"], [4, 4, 1, "", "DUMMY"], [4, 4, 1, "", "LAMB"], [4, 4, 1, "", "LARS"], [4, 4, 1, "", "NADAM"], [4, 4, 1, "", "NOVOGRAD"], [4, 4, 1, "", "RADAM"], [4, 4, 1, "", "SGDP"], [4, 4, 1, "", "SGD_SCHEDULE_FREE"], [4, 4, 1, "", "SOPHIA"], [4, 4, 1, "", "YOGI"]], "lmflow.args.RaftAlignerArguments": [[4, 4, 1, "", "collection_strategy"], [4, 4, 1, "", "inference_batch_size_per_device"], [4, 4, 1, "", "num_raft_iteration"], [4, 4, 1, "", "output_max_length"], [4, 4, 1, "", "output_min_length"], [4, 4, 1, "", "output_reward_path"], [4, 4, 1, "", "raft_batch_size"], [4, 4, 1, "", "top_reward_percentage"]], "lmflow.args.VisModelArguments": [[4, 4, 1, "", "custom_model"], [4, 4, 1, "", "custom_vision_model"], [4, 4, 1, "", "image_encoder_name_or_path"], [4, 4, 1, "", "llava_loading"], [4, 4, 1, "", "llava_pretrain_model_path"], [4, 4, 1, "", "llm_model_name_or_path"], [4, 4, 1, "", "low_resource"], [4, 4, 1, "", "pretrained_language_projection_path"], [4, 4, 1, "", "prompt_cache_path"], [4, 4, 1, "", "qformer_name_or_path"], [4, 4, 1, "", "save_pretrain_model_path"], [4, 4, 1, "", "use_prompt_cache"], [4, 4, 1, "", "vision_select_layer"], [4, 4, 1, "", "with_qformer"]], "lmflow.datasets": [[6, 2, 1, "", "Dataset"], [5, 0, 0, "-", "dataset"], [6, 5, 1, "", "is_multimodal_available"], [7, 0, 0, "-", "multi_modal_dataset"]], "lmflow.datasets.Dataset": [[6, 3, 1, "", "__len__"], [6, 3, 1, "", "_check_data_format"], [6, 4, 1, "", "backend"], [6, 4, 1, "", "backend_dataset"], [6, 3, 1, "", "create_from_dict"], [6, 4, 1, "", "data_args"], [6, 4, 1, "", "dataset_path"], [6, 3, 1, "", "drop_instances"], [6, 3, 1, "", "from_dict"], [6, 3, 1, "", "get_backend"], [6, 3, 1, "", "get_backend_dataset"], [6, 3, 1, "", "get_data_args"], [6, 3, 1, "", "get_fingerprint"], [6, 3, 1, "", "get_type"], [6, 3, 1, "", "hf_dataset_sanity_check"], [6, 3, 1, "", "map"], [6, 3, 1, "", "sample"], [6, 3, 1, "", "sanity_check"], [6, 3, 1, "", "save"], [6, 3, 1, "", "to_dict"], [6, 3, 1, "", "to_list"], [6, 3, 1, "", "train_test_split"], [6, 4, 1, "", "type"]], "lmflow.datasets.dataset": [[5, 1, 1, "", "DATASET_TYPES"], [5, 2, 1, "", "Dataset"], [5, 1, 1, "", "KEY_INSTANCES"], [5, 1, 1, "", "KEY_SCORE"], [5, 1, 1, "", "KEY_TYPE"], [5, 1, 1, "", "logger"]], "lmflow.datasets.dataset.Dataset": [[5, 3, 1, "", "__len__"], [5, 3, 1, "", "_check_data_format"], [5, 4, 1, "", "backend"], [5, 4, 1, "", "backend_dataset"], [5, 3, 1, "", "create_from_dict"], [5, 4, 1, "", "data_args"], [5, 4, 1, "", "dataset_path"], [5, 3, 1, "", "drop_instances"], [5, 3, 1, "", "from_dict"], [5, 3, 1, "", "get_backend"], [5, 3, 1, "", "get_backend_dataset"], [5, 3, 1, "", "get_data_args"], [5, 3, 1, "", "get_fingerprint"], [5, 3, 1, "", "get_type"], [5, 3, 1, "", "hf_dataset_sanity_check"], [5, 3, 1, "", "map"], [5, 3, 1, "", "sample"], [5, 3, 1, "", "sanity_check"], [5, 3, 1, "", "save"], [5, 3, 1, "", "to_dict"], [5, 3, 1, "", "to_list"], [5, 3, 1, "", "train_test_split"], [5, 4, 1, "", "type"]], "lmflow.datasets.multi_modal_dataset": [[7, 2, 1, "", "CustomMultiModalDataset"], [7, 2, 1, "", "DataCollatorForSupervisedDataset"], [7, 5, 1, "", "preprocess_llama_from_llava_plain"], [7, 5, 1, "", "preprocess_llama_from_llava_v1"], [7, 5, 1, "", "preprocess_multimodal_llava"], [7, 5, 1, "", "tokenizer_image_token"]], "lmflow.datasets.multi_modal_dataset.CustomMultiModalDataset": [[7, 3, 1, "", "__getitem__"], [7, 3, 1, "", "__len__"], [7, 4, 1, "", "data_args"], [7, 4, 1, "", "data_dict"], [7, 4, 1, "", "image_folder"], [7, 3, 1, "", "register_tokenizer"]], "lmflow.datasets.multi_modal_dataset.DataCollatorForSupervisedDataset": [[7, 3, 1, "", "__call__"], [7, 4, 1, "", "tokenizer"]], "lmflow.models": [[9, 0, 0, "-", "auto_model"], [10, 0, 0, "-", "base_model"], [11, 0, 0, "-", "decoder_model"], [12, 0, 0, "-", "encoder_decoder_model"], [13, 0, 0, "-", "hf_decoder_model"], [14, 0, 0, "-", "hf_encoder_decoder_model"], [15, 0, 0, "-", "hf_model_mixin"], [16, 0, 0, "-", "hf_text_regression_model"], [18, 0, 0, "-", "interfaces"], [20, 0, 0, "-", "regression_model"], [21, 0, 0, "-", "text_regression_model"], [22, 0, 0, "-", "vision2seq_model"], [24, 0, 0, "-", "vision_encoder"]], "lmflow.models.auto_model": [[9, 2, 1, "", "AutoModel"]], "lmflow.models.auto_model.AutoModel": [[9, 3, 1, "", "get_model"]], "lmflow.models.base_model": [[10, 2, 1, "", "BaseModel"]], "lmflow.models.decoder_model": [[11, 2, 1, "", "DecoderModel"]], "lmflow.models.encoder_decoder_model": [[12, 2, 1, "", "EncoderDecoderModel"]], "lmflow.models.hf_decoder_model": [[13, 2, 1, "", "HFDecoderModel"], [13, 1, 1, "", "logger"]], "lmflow.models.hf_decoder_model.HFDecoderModel": [[13, 3, 1, "", "__inference"], [13, 3, 1, "", "__prepare_inputs_for_inference"], [13, 3, 1, "", "__prepare_inputs_for_vllm_inference"], [13, 3, 1, "", "__vllm_inference"], [13, 3, 1, "", "decode"], [13, 3, 1, "", "encode"], [13, 3, 1, "", "get_peft_without_qlora"], [13, 3, 1, "", "inference"], [13, 3, 1, "", "merge_lora_weights"], [13, 3, 1, "", "prepare_inputs_for_inference"], [13, 3, 1, "", "save"], [13, 3, 1, "", "tokenize"]], "lmflow.models.hf_encoder_decoder_model": [[14, 2, 1, "", "HFEncoderDecoderModel"], [14, 1, 1, "", "logger"]], "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel": [[14, 3, 1, "", "decode"], [14, 4, 1, "", "device"], [14, 3, 1, "", "encode"], [14, 3, 1, "", "get_backend_model"], [14, 3, 1, "", "get_max_length"], [14, 3, 1, "", "get_tokenizer"], [14, 3, 1, "", "inference"], [14, 3, 1, "", "merge_lora_weights"], [14, 3, 1, "", "save"], [14, 3, 1, "", "tokenize"]], "lmflow.models.hf_model_mixin": [[15, 2, 1, "", "HFModelMixin"], [15, 1, 1, "", "HF_AUTOMODEL_MAPPING"], [15, 1, 1, "", "HF_AUTOMODEL_TYPE"], [15, 1, 1, "", "LORA_TARGET_MODULES_MAPPING"], [15, 1, 1, "", "logger"]], "lmflow.models.hf_model_mixin.HFModelMixin": [[15, 3, 1, "", "__model_module_inject"], [15, 3, 1, "", "__prepare_dtype"], [15, 3, 1, "", "__prepare_model_config"], [15, 3, 1, "", "__prepare_model_for_inference"], [15, 3, 1, "", "__prepare_model_for_training"], [15, 3, 1, "", "__prepare_model_for_vllm_inference"], [15, 3, 1, "", "__prepare_model_post_process"], [15, 3, 1, "", "__prepare_peft_config"], [15, 3, 1, "", "__prepare_quant_config"], [15, 3, 1, "", "__prepare_tokenizer"], [15, 4, 1, "", "_activated"], [15, 3, 1, "", "activate_model_for_inference"], [15, 3, 1, "", "deactivate_model_for_inference"], [15, 4, 1, "", "device"], [15, 4, 1, "", "do_train"], [15, 4, 1, "", "ds_config"], [15, 3, 1, "", "get_backend_model"], [15, 3, 1, "", "get_max_length"], [15, 3, 1, "", "get_tokenizer"], [15, 4, 1, "", "hf_auto_model"], [15, 4, 1, "", "hf_model_config"], [15, 4, 1, "", "model_args"], [15, 4, 1, "", "peft_config"], [15, 4, 1, "", "quant_config"], [15, 4, 1, "", "tokenizer"], [15, 4, 1, "", "torch_dtype"], [15, 4, 1, "", "use_accelerator"]], "lmflow.models.hf_text_regression_model": [[16, 2, 1, "", "HFTextRegressionModel"], [16, 1, 1, "", "logger"]], "lmflow.models.hf_text_regression_model.HFTextRegressionModel": [[16, 3, 1, "", "__inference"], [16, 3, 1, "", "__vllm_inference"], [16, 3, 1, "", "inference"], [16, 3, 1, "", "postprocess_distributed_inference_outputs"], [16, 3, 1, "", "postprocess_inference_outputs"], [16, 3, 1, "", "prepare_inputs_for_inference"], [16, 3, 1, "", "save"], [16, 3, 1, "", "tokenize"]], "lmflow.models.interfaces": [[19, 0, 0, "-", "tunable"]], "lmflow.models.interfaces.tunable": [[19, 2, 1, "", "Tunable"]], "lmflow.models.regression_model": [[20, 2, 1, "", "RegressionModel"]], "lmflow.models.text_regression_model": [[21, 2, 1, "", "TextRegressionModel"]], "lmflow.models.text_regression_model.TextRegressionModel": [[21, 3, 1, "", "inference"], [21, 4, 1, "", "inference_func"], [21, 3, 1, "", "register_inference_function"]], "lmflow.models.vision2seq_model": [[22, 2, 1, "", "CustomAutoVision2SeqModel"]], "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel": [[22, 4, 1, "", "custom_vision_model"], [22, 3, 1, "", "forward"], [22, 3, 1, "", "generate"], [22, 3, 1, "", "get_backend_model"], [22, 3, 1, "", "get_tokenizer"], [22, 4, 1, "", "hidden_size"], [22, 4, 1, "", "language_model"], [22, 3, 1, "", "language_model_from_pretrained"], [22, 3, 1, "", "load_prompt_cache"], [22, 3, 1, "", "processor_image_token_in_minigpt4"], [22, 3, 1, "", "qformer_from_pretrained"], [22, 3, 1, "", "register_prompt_cache"], [22, 3, 1, "", "save_prompt_cache"], [22, 3, 1, "", "vision_feature_select"], [22, 3, 1, "", "vision_model_from_pretrained"], [22, 4, 1, "", "with_qformer"]], "lmflow.models.vision_encoder": [[24, 5, 1, "", "build_vision_tower"], [23, 0, 0, "-", "clip_encoder"]], "lmflow.models.vision_encoder.clip_encoder": [[23, 2, 1, "", "CLIPVisionTower"], [23, 5, 1, "", "build_vision_tower"]], "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower": [[23, 6, 1, "", "config"], [23, 6, 1, "", "device"], [23, 6, 1, "", "dtype"], [23, 6, 1, "", "dummy_feature"], [23, 3, 1, "", "encode_images"], [23, 3, 1, "", "feature_select"], [23, 3, 1, "", "forward"], [23, 6, 1, "", "hidden_size"], [23, 4, 1, "", "is_loaded"], [23, 3, 1, "", "load_model"], [23, 6, 1, "", "num_patches"], [23, 3, 1, "", "prepare_inputs_labels_for_multimodal"], [23, 4, 1, "", "select_feature"], [23, 4, 1, "", "select_layer"], [23, 4, 1, "", "vision_tower_name"]], "lmflow.optim": [[25, 0, 0, "-", "adabelief"], [26, 0, 0, "-", "adabound"], [27, 0, 0, "-", "adadelta"], [28, 0, 0, "-", "adagrad"], [29, 0, 0, "-", "adam"], [30, 0, 0, "-", "adamax"], [31, 0, 0, "-", "adamp"], [32, 0, 0, "-", "adamw_schedule_free"], [33, 0, 0, "-", "adan"], [34, 0, 0, "-", "dummy"], [36, 0, 0, "-", "lamb"], [37, 0, 0, "-", "lars"], [38, 0, 0, "-", "nadam"], [39, 0, 0, "-", "novograd"], [40, 0, 0, "-", "optimizers"], [41, 0, 0, "-", "radam"], [42, 0, 0, "-", "sgd_schedule_free"], [43, 0, 0, "-", "sgdp"], [44, 0, 0, "-", "sophia"], [45, 0, 0, "-", "yogi"]], "lmflow.optim.adabelief": [[25, 2, 1, "", "AdaBelief"]], "lmflow.optim.adabelief.AdaBelief": [[25, 3, 1, "", "__setstate__"], [25, 4, 1, "", "degenerated_to_sgd"], [25, 4, 1, "", "fixed_decay"], [25, 4, 1, "", "rectify"], [25, 3, 1, "", "reset"], [25, 3, 1, "", "step"], [25, 4, 1, "", "weight_decouple"]], "lmflow.optim.adabound": [[26, 2, 1, "", "AdaBound"]], "lmflow.optim.adabound.AdaBound": [[26, 3, 1, "", "__setstate__"], [26, 4, 1, "", "base_lrs"], [26, 3, 1, "", "step"]], "lmflow.optim.adadelta": [[27, 2, 1, "", "Adadelta"]], "lmflow.optim.adadelta.Adadelta": [[27, 3, 1, "", "step"]], "lmflow.optim.adagrad": [[28, 2, 1, "", "AdaGrad"]], "lmflow.optim.adagrad.AdaGrad": [[28, 3, 1, "", "step"]], "lmflow.optim.adam": [[29, 2, 1, "", "Adam"]], "lmflow.optim.adam.Adam": [[29, 3, 1, "", "step"]], "lmflow.optim.adamax": [[30, 2, 1, "", "Adamax"]], "lmflow.optim.adamax.Adamax": [[30, 3, 1, "", "__setstate__"], [30, 3, 1, "", "step"]], "lmflow.optim.adamp": [[31, 2, 1, "", "AdamP"]], "lmflow.optim.adamp.AdamP": [[31, 3, 1, "", "_channel_view"], [31, 3, 1, "", "_cosine_similarity"], [31, 3, 1, "", "_layer_view"], [31, 3, 1, "", "_projection"], [31, 3, 1, "", "step"]], "lmflow.optim.adamw_schedule_free": [[32, 2, 1, "", "AdamWScheduleFree"]], "lmflow.optim.adamw_schedule_free.AdamWScheduleFree": [[32, 3, 1, "", "eval"], [32, 3, 1, "", "step"], [32, 3, 1, "", "train"]], "lmflow.optim.adan": [[33, 2, 1, "", "Adan"], [33, 5, 1, "", "_multi_tensor_adan"], [33, 5, 1, "", "_single_tensor_adan"]], "lmflow.optim.adan.Adan": [[33, 3, 1, "", "__setstate__"], [33, 3, 1, "", "restart_opt"], [33, 3, 1, "", "step"]], "lmflow.optim.dummy": [[34, 2, 1, "", "Dummy"]], "lmflow.optim.dummy.Dummy": [[34, 3, 1, "", "step"]], "lmflow.optim.lamb": [[36, 2, 1, "", "Lamb"]], "lmflow.optim.lamb.Lamb": [[36, 4, 1, "", "adam"], [36, 4, 1, "", "clamp_value"], [36, 4, 1, "", "debias"], [36, 3, 1, "", "step"]], "lmflow.optim.lars": [[37, 2, 1, "", "LARS"]], "lmflow.optim.lars.LARS": [[37, 3, 1, "", "__setstate__"], [37, 3, 1, "", "step"]], "lmflow.optim.nadam": [[38, 2, 1, "", "NAdam"]], "lmflow.optim.nadam.NAdam": [[38, 3, 1, "", "__setstate__"], [38, 3, 1, "", "step"]], "lmflow.optim.novograd": [[39, 2, 1, "", "NovoGrad"]], "lmflow.optim.novograd.NovoGrad": [[39, 3, 1, "", "__setstate__"], [39, 3, 1, "", "step"]], "lmflow.optim.radam": [[41, 2, 1, "", "RAdam"]], "lmflow.optim.radam.RAdam": [[41, 3, 1, "", "__setstate__"], [41, 3, 1, "", "step"]], "lmflow.optim.sgd_schedule_free": [[42, 2, 1, "", "SGDScheduleFree"]], "lmflow.optim.sgd_schedule_free.SGDScheduleFree": [[42, 3, 1, "", "eval"], [42, 3, 1, "", "step"], [42, 3, 1, "", "train"]], "lmflow.optim.sgdp": [[43, 2, 1, "", "SGDP"]], "lmflow.optim.sgdp.SGDP": [[43, 3, 1, "", "_channel_view"], [43, 3, 1, "", "_cosine_similarity"], [43, 3, 1, "", "_layer_view"], [43, 3, 1, "", "_projection"], [43, 3, 1, "", "step"]], "lmflow.optim.sophia": [[44, 2, 1, "", "SophiaG"]], "lmflow.optim.sophia.SophiaG": [[44, 3, 1, "", "__setstate__"], [44, 3, 1, "", "step"], [44, 3, 1, "", "update_hessian"]], "lmflow.optim.yogi": [[45, 2, 1, "", "Yogi"]], "lmflow.optim.yogi.Yogi": [[45, 3, 1, "", "step"]], "lmflow.pipeline": [[46, 0, 0, "-", "auto_pipeline"], [47, 0, 0, "-", "base_aligner"], [48, 0, 0, "-", "base_pipeline"], [49, 0, 0, "-", "base_tuner"], [50, 0, 0, "-", "dpo_aligner"], [51, 0, 0, "-", "dpov2_aligner"], [52, 0, 0, "-", "evaluator"], [53, 0, 0, "-", "finetuner"], [55, 0, 0, "-", "inferencer"], [56, 0, 0, "-", "iterative_dpo_aligner"], [57, 0, 0, "-", "raft_aligner"], [58, 0, 0, "-", "rm_inferencer"], [59, 0, 0, "-", "rm_tuner"], [62, 0, 0, "-", "utils"], [69, 0, 0, "-", "vllm_inferencer"]], "lmflow.pipeline.auto_pipeline": [[46, 2, 1, "", "AutoPipeline"], [46, 1, 1, "", "PIPELINE_MAPPING"], [46, 1, 1, "", "PIPELINE_NEEDS_EXTRAS"]], "lmflow.pipeline.auto_pipeline.AutoPipeline": [[46, 3, 1, "", "get_pipeline"]], "lmflow.pipeline.base_aligner": [[47, 2, 1, "", "BaseAligner"]], "lmflow.pipeline.base_aligner.BaseAligner": [[47, 3, 1, "", "_check_if_alignable"], [47, 3, 1, "", "align"]], "lmflow.pipeline.base_pipeline": [[48, 2, 1, "", "BasePipeline"]], "lmflow.pipeline.base_tuner": [[49, 2, 1, "", "BaseTuner"]], "lmflow.pipeline.base_tuner.BaseTuner": [[49, 3, 1, "", "_check_if_tunable"], [49, 3, 1, "", "tune"]], "lmflow.pipeline.dpo_aligner": [[50, 2, 1, "", "DPOAligner"], [50, 5, 1, "", "get_paired_dataset"]], "lmflow.pipeline.dpo_aligner.DPOAligner": [[50, 3, 1, "", "_initialize_trainer"], [50, 3, 1, "", "_load_dataset"], [50, 3, 1, "", "align"], [50, 4, 1, "", "aligner_args"], [50, 4, 1, "", "data_args"], [50, 4, 1, "", "eval_dataset"], [50, 4, 1, "", "model_args"], [50, 4, 1, "", "train_dataset"]], "lmflow.pipeline.dpov2_aligner": [[51, 2, 1, "", "DPOv2Aligner"], [51, 2, 1, "", "MemorySafeDPOv2Aligner"], [51, 1, 1, "", "ReferenceModelArguments"], [51, 1, 1, "", "logger"]], "lmflow.pipeline.dpov2_aligner.DPOv2Aligner": [[51, 3, 1, "", "__prepare_training_args"], [51, 3, 1, "", "_calc_response_lengths"], [51, 3, 1, "", "_calc_reward_with_length_penalty"], [51, 3, 1, "", "_sampling_paired_idx_from_rewards"], [51, 3, 1, "", "_sampling_paired_idx_from_rewards_fast"], [51, 3, 1, "", "align"], [51, 4, 1, "", "aligner_args"], [51, 3, 1, "", "convert_to_paired_dataset"], [51, 4, 1, "", "data_args"], [51, 4, 1, "", "model_args"], [51, 4, 1, "", "ref_model_args"], [51, 3, 1, "", "sampling_paired_idx_from_rewards"]], "lmflow.pipeline.dpov2_aligner.MemorySafeDPOv2Aligner": [[51, 3, 1, "", "align"], [51, 4, 1, "", "aligner_args"], [51, 4, 1, "", "aligner_file_path"], [51, 4, 1, "", "data_args"], [51, 4, 1, "", "model_args"], [51, 4, 1, "", "ref_model_args"]], "lmflow.pipeline.evaluator": [[52, 2, 1, "", "Evaluator"]], "lmflow.pipeline.evaluator.Evaluator": [[52, 3, 1, "", "_evaluate_acc_with_accelerator"], [52, 3, 1, "", "_evaluate_acc_with_deepspeed"], [52, 3, 1, "", "_evaluate_nll"], [52, 3, 1, "", "_evaluate_ppl"], [52, 3, 1, "", "_match"], [52, 4, 1, "", "block_size"], [52, 4, 1, "", "config"], [52, 3, 1, "", "create_dataloader"], [52, 4, 1, "", "data_args"], [52, 3, 1, "", "evaluate"], [52, 4, 1, "", "evaluator_args"], [52, 4, 1, "", "local_rank"], [52, 4, 1, "", "model_args"], [52, 4, 1, "", "world_size"]], "lmflow.pipeline.finetuner": [[53, 2, 1, "", "Finetuner"], [53, 1, 1, "", "logger"]], "lmflow.pipeline.finetuner.Finetuner": [[53, 3, 1, "", "create_customized_optimizer"], [53, 4, 1, "", "data_args"], [53, 4, 1, "", "finetuner_args"], [53, 3, 1, "", "group_text"], [53, 4, 1, "", "last_checkpoint"], [53, 4, 1, "", "model_args"], [53, 3, 1, "", "tune"]], "lmflow.pipeline.inferencer": [[55, 2, 1, "", "Inferencer"], [55, 2, 1, "", "SpeculativeInferencer"], [55, 2, 1, "", "ToolInferencer"], [55, 1, 1, "", "logger"], [55, 5, 1, "", "rstrip_partial_utf8"], [55, 1, 1, "", "supported_dataset_type"]], "lmflow.pipeline.inferencer.Inferencer": [[55, 4, 1, "", "config"], [55, 3, 1, "", "create_dataloader"], [55, 4, 1, "", "data_args"], [55, 3, 1, "", "inference"], [55, 4, 1, "", "inferencer_args"], [55, 4, 1, "", "local_rank"], [55, 4, 1, "", "model_args"], [55, 3, 1, "", "stream_inference"], [55, 4, 1, "", "world_size"]], "lmflow.pipeline.inferencer.SpeculativeInferencer": [[55, 3, 1, "", "autoregressive_sampling"], [55, 4, 1, "", "draft_config"], [55, 4, 1, "", "draft_model_args"], [55, 3, 1, "", "inference"], [55, 3, 1, "", "predict_next_token"], [55, 3, 1, "", "sample"], [55, 3, 1, "", "score_to_prob"], [55, 3, 1, "", "stream_inference"]], "lmflow.pipeline.inferencer.ToolInferencer": [[55, 3, 1, "", "code_exec"], [55, 3, 1, "", "inference"], [55, 4, 1, "", "model"]], "lmflow.pipeline.iterative_dpo_aligner": [[56, 2, 1, "", "IterativeDPOAligner"], [56, 1, 1, "", "logger"]], "lmflow.pipeline.iterative_dpo_aligner.IterativeDPOAligner": [[56, 3, 1, "", "__filter_args"], [56, 3, 1, "", "_align_single_iteration"], [56, 3, 1, "", "_do_reward_model_inference"], [56, 3, 1, "", "_do_single_dpo_align"], [56, 3, 1, "", "_do_target_model_inference"], [56, 3, 1, "", "_parse_dpo_aligner_args"], [56, 3, 1, "", "_parse_reward_model_inference_args"], [56, 3, 1, "", "_parse_target_model_inference_args"], [56, 3, 1, "", "align"], [56, 4, 1, "", "aligner_args"], [56, 4, 1, "", "data_args"], [56, 4, 1, "", "model_args"], [56, 4, 1, "", "ref_model_args"], [56, 4, 1, "", "reward_model_args"], [56, 4, 1, "", "workspace_path"]], "lmflow.pipeline.raft_aligner": [[57, 2, 1, "", "RaftAligner"], [57, 1, 1, "", "logger"]], "lmflow.pipeline.raft_aligner.RaftAligner": [[57, 4, 1, "", "INF"], [57, 3, 1, "", "_clean_text"], [57, 3, 1, "", "_discard_sample"], [57, 3, 1, "", "_get_batch_dataset_local"], [57, 3, 1, "", "_get_batch_dataset_top"], [57, 3, 1, "", "_initialize_trainer"], [57, 3, 1, "", "_load_dataset"], [57, 3, 1, "", "_load_input_dataset"], [57, 3, 1, "", "align"], [57, 4, 1, "", "aligner_args"], [57, 4, 1, "", "data_args"], [57, 4, 1, "", "model_args"]], "lmflow.pipeline.rm_inferencer": [[58, 2, 1, "", "RewardModelInferencer"], [58, 1, 1, "", "logger"]], "lmflow.pipeline.rm_inferencer.RewardModelInferencer": [[58, 3, 1, "", "__distributed_inference"], [58, 3, 1, "", "__inference"], [58, 3, 1, "", "__post_process_model_output"], [58, 3, 1, "", "__vllm_inference"], [58, 3, 1, "", "_inference"], [58, 3, 1, "", "compress_list"], [58, 4, 1, "", "data_args"], [58, 3, 1, "", "flatten_list"], [58, 3, 1, "", "inference"], [58, 4, 1, "", "inferencer_args"], [58, 4, 1, "", "local_rank"], [58, 4, 1, "", "model_args"], [58, 4, 1, "", "world_size"]], "lmflow.pipeline.rm_tuner": [[59, 2, 1, "", "RewardModelTuner"], [59, 1, 1, "", "logger"]], "lmflow.pipeline.rm_tuner.RewardModelTuner": [[59, 3, 1, "", "tune"]], "lmflow.pipeline.utils": [[60, 0, 0, "-", "dpov2_dataprocessor"], [61, 0, 0, "-", "dpov2_trainer"], [63, 0, 0, "-", "memory_safe_dpov2_align"], [64, 0, 0, "-", "memory_safe_vllm_inference"], [65, 0, 0, "-", "peft_trainer"], [66, 0, 0, "-", "raft_trainer"], [67, 0, 0, "-", "rm_dataprocessor"], [68, 0, 0, "-", "rm_trainer"]], "lmflow.pipeline.utils.dpov2_dataprocessor": [[60, 2, 1, "", "PreferenceDataCollatorWithPadding"], [60, 1, 1, "", "logger"]], "lmflow.pipeline.utils.dpov2_dataprocessor.PreferenceDataCollatorWithPadding": [[60, 3, 1, "", "__call__"], [60, 3, 1, "", "collate"], [60, 4, 1, "", "is_encoder_decoder"], [60, 4, 1, "", "label_pad_token_id"], [60, 4, 1, "", "mask_prompt"], [60, 4, 1, "", "max_length"], [60, 4, 1, "", "max_prompt_length"], [60, 4, 1, "", "max_target_length"], [60, 4, 1, "", "model"], [60, 4, 1, "", "padding"], [60, 4, 1, "", "padding_value"], [60, 3, 1, "", "tokenize_batch_element"], [60, 4, 1, "", "tokenizer"], [60, 4, 1, "", "truncation_mode"]], "lmflow.pipeline.utils.dpov2_trainer": [[61, 2, 1, "", "DPOv2Trainer"], [61, 1, 1, "", "logger"]], "lmflow.pipeline.utils.dpov2_trainer.DPOv2Trainer": [[61, 3, 1, "", "dpo_loss"], [61, 3, 1, "", "get_batch_loss_metrics"], [61, 3, 1, "", "get_batch_metrics"], [61, 4, 1, "", "len_penalty"], [61, 4, 1, "", "use_dpo_data_collator"]], "lmflow.pipeline.utils.memory_safe_dpov2_align": [[63, 1, 1, "", "ReferenceModelArguments"], [63, 1, 1, "", "logger"], [63, 5, 1, "", "main"]], "lmflow.pipeline.utils.memory_safe_vllm_inference": [[64, 1, 1, "", "logger"], [64, 5, 1, "", "main"]], "lmflow.pipeline.utils.peft_trainer": [[65, 2, 1, "", "PeftSavingCallback"], [65, 2, 1, "", "PeftTrainer"]], "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback": [[65, 3, 1, "", "_save"], [65, 3, 1, "", "on_epoch_end"], [65, 3, 1, "", "on_save"], [65, 3, 1, "", "on_train_end"]], "lmflow.pipeline.utils.peft_trainer.PeftTrainer": [[65, 3, 1, "", "_save_checkpoint"]], "lmflow.pipeline.utils.raft_trainer": [[66, 1, 1, "", "DEFAULT_CALLBACKS"], [66, 1, 1, "id0", "DEFAULT_PROGRESS_CALLBACK"], [66, 1, 1, "", "IS_SAGEMAKER_MP_POST_1_10"], [66, 1, 1, "", "OPTIMIZER_NAME"], [66, 2, 1, "", "RaftTrainer"], [66, 1, 1, "", "SCALER_NAME"], [66, 1, 1, "", "SCHEDULER_NAME"], [66, 1, 1, "", "TRAINER_STATE_NAME"], [66, 1, 1, "", "TRAINING_ARGS_NAME"], [66, 1, 1, "", "_is_native_cpu_amp_available"], [66, 1, 1, "", "is_torch_greater_or_equal_than_1_10"], [66, 1, 1, "", "is_torch_less_than_1_11"], [66, 1, 1, "", "logger"], [66, 1, 1, "", "skip_first_batches"]], "lmflow.pipeline.utils.raft_trainer.RaftTrainer": [[66, 3, 1, "", "_add_sm_patterns_to_gitignore"], [66, 3, 1, "", "_gather_and_numpify"], [66, 3, 1, "", "_get_collator_with_removed_columns"], [66, 3, 1, "", "_get_eval_sampler"], [66, 3, 1, "", "_get_output_dir"], [66, 3, 1, "", "_get_train_sampler"], [66, 3, 1, "", "_hp_search_setup"], [66, 3, 1, "", "_inner_training_loop"], [66, 3, 1, "", "_issue_warnings_after_load"], [66, 3, 1, "", "_load_best_model"], [66, 3, 1, "", "_load_from_checkpoint"], [66, 3, 1, "", "_load_optimizer_and_scheduler"], [66, 3, 1, "", "_load_rng_state"], [66, 4, 1, "", "_loggers_initialized"], [66, 3, 1, "", "_maybe_log_save_evaluate"], [66, 4, 1, "", "_memory_tracker"], [66, 3, 1, "", "_move_model_to_device"], [66, 3, 1, "", "_nested_gather"], [66, 3, 1, "", "_one_train"], [66, 3, 1, "", "_pad_across_processes"], [66, 3, 1, "", "_prepare_input"], [66, 3, 1, "", "_prepare_inputs"], [66, 3, 1, "", "_push_from_checkpoint"], [66, 3, 1, "", "_remove_unused_columns"], [66, 3, 1, "", "_report_to_hp_search"], [66, 3, 1, "", "_rotate_checkpoints"], [66, 3, 1, "", "_save"], [66, 3, 1, "", "_save_checkpoint"], [66, 3, 1, "", "_save_tpu"], [66, 3, 1, "", "_set_signature_columns_if_needed"], [66, 4, 1, "", "_signature_columns"], [66, 3, 1, "", "_sorted_checkpoints"], [66, 4, 1, "", "_train_batch_size"], [66, 3, 1, "", "_tune_save_checkpoint"], [66, 3, 1, "", "_wrap_model"], [66, 3, 1, "", "add_callback"], [66, 4, 1, "", "args"], [66, 3, 1, "", "autocast_smart_context_manager"], [66, 3, 1, "", "call_model_init"], [66, 4, 1, "", "callback_handler"], [66, 4, 1, "", "can_return_loss"], [66, 3, 1, "", "compute_loss"], [66, 3, 1, "", "compute_loss_context_manager"], [66, 4, 1, "", "compute_metrics"], [66, 4, 1, "", "control"], [66, 3, 1, "", "create_model_card"], [66, 3, 1, "", "create_optimizer"], [66, 3, 1, "", "create_optimizer_and_scheduler"], [66, 3, 1, "", "create_scheduler"], [66, 4, 1, "", "current_flos"], [66, 4, 1, "", "data_collator"], [66, 4, 1, "", "deepspeed"], [66, 4, 1, "", "do_grad_scaling"], [66, 4, 1, "", "eval_dataset"], [66, 3, 1, "", "evaluate"], [66, 3, 1, "", "evaluation_loop"], [66, 3, 1, "", "floating_point_ops"], [66, 4, 1, "", "fsdp"], [66, 3, 1, "", "get_eval_dataloader"], [66, 3, 1, "", "get_optimizer_cls_and_kwargs"], [66, 3, 1, "", "get_test_dataloader"], [66, 3, 1, "", "get_train_dataloader"], [66, 4, 1, "", "hp_name"], [66, 4, 1, "", "hp_search_backend"], [66, 3, 1, "", "hyperparameter_search"], [66, 3, 1, "", "init_git_repo"], [66, 3, 1, "", "ipex_optimize_model"], [66, 4, 1, "", "is_in_train"], [66, 3, 1, "", "is_local_process_zero"], [66, 3, 1, "", "is_world_process_zero"], [66, 4, 1, "", "label_names"], [66, 3, 1, "", "log"], [66, 4, 1, "", "model"], [66, 4, 1, "", "model_wrapped"], [66, 3, 1, "", "num_examples"], [66, 4, 1, "", "place_model_on_device"], [66, 3, 1, "", "pop_callback"], [66, 3, 1, "", "predict"], [66, 3, 1, "", "prediction_loop"], [66, 3, 1, "", "prediction_step"], [66, 4, 1, "", "preprocess_logits_for_metrics"], [66, 3, 1, "", "push_to_hub"], [66, 3, 1, "", "remove_callback"], [66, 4, 1, "", "save_counter"], [66, 3, 1, "", "save_model"], [66, 4, 1, "", "sharded_ddp"], [66, 4, 1, "", "state"], [66, 3, 1, "", "store_flos"], [66, 4, 1, "", "tokenizer"], [66, 3, 1, "", "torch_jit_model_eval"], [66, 3, 1, "", "train"], [66, 4, 1, "", "train_dataset"], [66, 3, 1, "", "training_step"], [66, 4, 1, "", "use_apex"], [66, 4, 1, "", "use_cpu_amp"], [66, 4, 1, "", "use_cuda_amp"], [66, 4, 1, "", "use_tune_checkpoints"]], "lmflow.pipeline.utils.rm_dataprocessor": [[67, 2, 1, "", "RewardDataCollatorWithPadding"], [67, 1, 1, "", "logger"]], "lmflow.pipeline.utils.rm_dataprocessor.RewardDataCollatorWithPadding": [[67, 3, 1, "", "__call__"], [67, 4, 1, "", "max_length"], [67, 4, 1, "", "pad_to_multiple_of"], [67, 4, 1, "", "padding"], [67, 4, 1, "", "return_tensors"], [67, 4, 1, "", "tokenizer"]], "lmflow.pipeline.utils.rm_trainer": [[68, 2, 1, "", "PeftRewardTrainer"], [68, 2, 1, "", "RewardTrainer"], [68, 5, 1, "", "compute_metrics"], [68, 5, 1, "", "rm_loss"]], "lmflow.pipeline.utils.rm_trainer.PeftRewardTrainer": [[68, 3, 1, "", "compute_loss"]], "lmflow.pipeline.utils.rm_trainer.RewardTrainer": [[68, 3, 1, "", "compute_loss"]], "lmflow.pipeline.vllm_inferencer": [[69, 2, 1, "", "InferencerWithOffloading"], [69, 2, 1, "", "MemorySafeVLLMInferencer"], [69, 2, 1, "", "VLLMInferencer"], [69, 1, 1, "", "logger"]], "lmflow.pipeline.vllm_inferencer.InferencerWithOffloading": [[69, 4, 1, "", "data_args"], [69, 4, 1, "", "eos_token_id"], [69, 3, 1, "", "inference"], [69, 4, 1, "", "inferencer_args"], [69, 3, 1, "", "load_inference_results"], [69, 4, 1, "", "model_args"], [69, 3, 1, "", "save_inference_results"]], "lmflow.pipeline.vllm_inferencer.MemorySafeVLLMInferencer": [[69, 3, 1, "", "inference"], [69, 4, 1, "", "inferencer_file_path"]], "lmflow.pipeline.vllm_inferencer.VLLMInferencer": [[69, 3, 1, "", "_distributed_inference"], [69, 3, 1, "", "_inference"], [69, 3, 1, "", "inference"], [69, 3, 1, "", "load_inference_results"], [69, 3, 1, "", "parse_to_sampling_params"], [69, 4, 1, "", "sampling_params"], [69, 3, 1, "", "save_inference_results"]], "lmflow.tokenization": [[70, 0, 0, "-", "hf_decoder_model"], [71, 0, 0, "-", "hf_text_regression_model"]], "lmflow.tokenization.hf_decoder_model": [[70, 5, 1, "", "blocking"], [70, 5, 1, "", "conversation_tokenize_function"], [70, 1, 1, "", "logger"], [70, 1, 1, "", "tok_logger"], [70, 5, 1, "", "tokenize_function"]], "lmflow.tokenization.hf_text_regression_model": [[71, 5, 1, "", "blocking"], [71, 5, 1, "", "blocking_paired"], [71, 5, 1, "", "blocking_text_to_textlist"], [71, 5, 1, "", "conversation_tokenize_function"], [71, 1, 1, "", "logger"], [71, 5, 1, "", "paired_conversation_tokenize_function"], [71, 5, 1, "", "text_to_textlist_tokenize_function"], [71, 1, 1, "", "tok_logger"], [71, 5, 1, "", "tokenize_function"]], "lmflow.utils": [[73, 0, 0, "-", "common"], [74, 0, 0, "-", "constants"], [81, 0, 0, "-", "conversation_template"], [88, 0, 0, "-", "data_utils"], [92, 0, 0, "-", "flash_attention"], [96, 0, 0, "-", "llava_conversation_lib"], [97, 0, 0, "-", "model"], [98, 0, 0, "-", "multimodal"], [99, 0, 0, "-", "position_interpolation"], [101, 0, 0, "-", "versioning"]], "lmflow.utils.common": [[73, 5, 1, "", "add_dataclass_attr_prefix"], [73, 5, 1, "", "create_copied_dataclass"], [73, 1, 1, "", "logger"], [73, 5, 1, "", "make_shell_args_from_dataclass"], [73, 5, 1, "", "print_banner"], [73, 5, 1, "", "remove_dataclass_attr_prefix"]], "lmflow.utils.constants": [[74, 1, 1, "", "CONTROLLER_HEART_BEAT_EXPIRATION"], [74, 1, 1, "", "CONVERSATION_DATASET_DESCRIPTION"], [74, 1, 1, "", "CONVERSATION_ROLE_NAMES"], [74, 1, 1, "", "DATASET_DESCRIPTION_MAP"], [74, 1, 1, "", "DEFAULT_IMAGE_PATCH_TOKEN"], [74, 1, 1, "", "DEFAULT_IMAGE_TOKEN"], [74, 1, 1, "", "DEFAULT_IM_END_TOKEN"], [74, 1, 1, "", "DEFAULT_IM_START_TOKEN"], [74, 1, 1, "", "FLOAT_ONLY_DATASET_DESCRIPTION"], [74, 1, 1, "", "IGNORE_INDEX"], [74, 1, 1, "", "IMAGE_TOKEN_INDEX"], [74, 1, 1, "", "INSTANCE_FIELDS_MAP"], [74, 1, 1, "", "LMFLOW_LORA_TARGET_MODULES_MAPPING"], [74, 1, 1, "", "LOGDIR"], [74, 1, 1, "", "MEMORY_SAFE_DPOV2_ALIGN_ENV_VAR_TO_REMOVE"], [74, 1, 1, "", "MEMORY_SAFE_VLLM_INFERENCE_ENV_VAR_TO_REMOVE"], [74, 1, 1, "", "MEMORY_SAFE_VLLM_INFERENCE_FINISH_FLAG"], [74, 1, 1, "", "PAIRED_CONVERSATION_DATASET_DESCRIPTION"], [74, 1, 1, "", "PAIRED_TEXT_TO_TEXT_DATASET_DESCRIPTION"], [74, 1, 1, "", "RETURN_CODE_ERROR_BUFFER"], [74, 1, 1, "", "TEXT2TEXT_DATASET_DESCRIPTION"], [74, 1, 1, "", "TEXT2TEXT_DATASET_DETAILS"], [74, 1, 1, "", "TEXT2TEXT_DATASET_LONG_DESCRITION"], [74, 1, 1, "", "TEXT_ONLY_DATASET_DESCRIPTION"], [74, 1, 1, "", "TEXT_ONLY_DATASET_DETAILS"], [74, 1, 1, "", "TEXT_ONLY_DATASET_LONG_DESCRITION"], [74, 1, 1, "", "TEXT_TO_SCORED_TEXTLIST_DATASET_DESCRIPTION"], [74, 1, 1, "", "TEXT_TO_TEXTLIST_DATASET_DESCRIPTION"], [74, 1, 1, "", "WORKER_HEART_BEAT_INTERVAL"]], "lmflow.utils.conversation_template": [[81, 1, 1, "", "CHATGLM3_TEMPLATE"], [81, 1, 1, "", "CHATML_TEMPLATE"], [81, 2, 1, "", "ConversationTemplate"], [81, 2, 1, "", "ConversationTemplateForTool"], [81, 1, 1, "", "DEEPSEEK_TEMPLATE"], [81, 1, 1, "", "EMPTY_NO_SPECIAL_TOKENS_TEMPLATE"], [81, 1, 1, "", "EMPTY_TEMPLATE"], [81, 1, 1, "", "GEMMA_TEMPLATE"], [81, 1, 1, "", "HYMBA_TEMPLATE"], [81, 1, 1, "", "INTERNLM2_TEMPLATE"], [81, 1, 1, "", "LLAMA2_TEMPLATE"], [81, 1, 1, "", "LLAMA3_TEMPLATE"], [81, 1, 1, "", "LLAMA3_TEMPLATE_FOR_TOOL"], [81, 1, 1, "", "PHI3_TEMPLATE"], [81, 1, 1, "", "PRESET_TEMPLATES"], [81, 1, 1, "", "QWEN2_TEMPLATE"], [81, 1, 1, "", "QWEN2_TEMPLATE_FOR_TOOL"], [81, 1, 1, "", "YI1_5_TEMPLATE"], [81, 1, 1, "", "ZEPHYR_TEMPLATE"], [75, 0, 0, "-", "base"], [76, 0, 0, "-", "chatglm"], [77, 0, 0, "-", "chatml"], [78, 0, 0, "-", "deepseek"], [79, 0, 0, "-", "gemma"], [80, 0, 0, "-", "hymba"], [82, 0, 0, "-", "internlm"], [83, 0, 0, "-", "llama"], [84, 0, 0, "-", "phi"], [85, 0, 0, "-", "qwen"], [86, 0, 0, "-", "yi"], [87, 0, 0, "-", "zephyr"]], "lmflow.utils.conversation_template.ConversationTemplate": [[81, 3, 1, "", "__post_init__"], [81, 3, 1, "", "_encode"], [81, 3, 1, "", "_encode_template"], [81, 3, 1, "", "_ensure_id_list"], [81, 3, 1, "", "add_special_starter"], [81, 3, 1, "", "add_special_stopper"], [81, 4, 1, "", "assistant_formatter"], [81, 3, 1, "", "encode_conversation"], [81, 4, 1, "", "force_system"], [81, 4, 1, "", "function_formatter"], [81, 4, 1, "", "observation_formatter"], [81, 3, 1, "", "post_process_pairs"], [81, 4, 1, "", "remove_last_sep"], [81, 3, 1, "", "remove_last_separator"], [81, 4, 1, "", "separator"], [81, 4, 1, "", "special_starter"], [81, 4, 1, "", "special_stopper"], [81, 4, 1, "", "system_formatter"], [81, 4, 1, "", "template_name"], [81, 4, 1, "", "tools_formatter"], [81, 4, 1, "", "user_formatter"]], "lmflow.utils.conversation_template.ConversationTemplateForTool": [[81, 3, 1, "", "_encode"], [81, 3, 1, "", "_encode_template"], [81, 3, 1, "", "encode_conversation"]], "lmflow.utils.conversation_template.base": [[75, 2, 1, "", "ConversationTemplate"], [75, 2, 1, "", "ConversationTemplateForTool"], [75, 1, 1, "", "EMPTY_NO_SPECIAL_TOKENS_TEMPLATE"], [75, 1, 1, "", "EMPTY_TEMPLATE"], [75, 2, 1, "", "EmptyFormatter"], [75, 2, 1, "", "Formatter"], [75, 2, 1, "", "ListFormatter"], [75, 2, 1, "", "StringFormatter"], [75, 2, 1, "", "TemplateComponent"], [75, 1, 1, "", "logger"]], "lmflow.utils.conversation_template.base.ConversationTemplate": [[75, 3, 1, "", "__post_init__"], [75, 3, 1, "", "_encode"], [75, 3, 1, "", "_encode_template"], [75, 3, 1, "", "_ensure_id_list"], [75, 3, 1, "", "add_special_starter"], [75, 3, 1, "", "add_special_stopper"], [75, 4, 1, "", "assistant_formatter"], [75, 3, 1, "", "encode_conversation"], [75, 4, 1, "", "force_system"], [75, 4, 1, "", "function_formatter"], [75, 4, 1, "", "observation_formatter"], [75, 3, 1, "", "post_process_pairs"], [75, 4, 1, "", "remove_last_sep"], [75, 3, 1, "", "remove_last_separator"], [75, 4, 1, "", "separator"], [75, 4, 1, "", "special_starter"], [75, 4, 1, "", "special_stopper"], [75, 4, 1, "", "system_formatter"], [75, 4, 1, "", "template_name"], [75, 4, 1, "", "tools_formatter"], [75, 4, 1, "", "user_formatter"]], "lmflow.utils.conversation_template.base.ConversationTemplateForTool": [[75, 3, 1, "", "_encode"], [75, 3, 1, "", "_encode_template"], [75, 3, 1, "", "encode_conversation"]], "lmflow.utils.conversation_template.base.EmptyFormatter": [[75, 3, 1, "", "__post_init__"], [75, 3, 1, "", "format"]], "lmflow.utils.conversation_template.base.Formatter": [[75, 3, 1, "", "format"], [75, 3, 1, "", "has_placeholder"], [75, 4, 1, "", "template"]], "lmflow.utils.conversation_template.base.ListFormatter": [[75, 3, 1, "", "format"]], "lmflow.utils.conversation_template.base.StringFormatter": [[75, 3, 1, "", "__post_init__"], [75, 3, 1, "", "format"]], "lmflow.utils.conversation_template.base.TemplateComponent": [[75, 3, 1, "", "__post_init__"], [75, 3, 1, "", "__repr__"], [75, 3, 1, "", "__str__"], [75, 4, 1, "", "content"], [75, 4, 1, "", "mask"], [75, 4, 1, "", "type"]], "lmflow.utils.conversation_template.chatglm": [[76, 1, 1, "", "CHATGLM3_TEMPLATE"]], "lmflow.utils.conversation_template.chatml": [[77, 1, 1, "", "CHATML_TEMPLATE"]], "lmflow.utils.conversation_template.deepseek": [[78, 1, 1, "", "DEEPSEEK_TEMPLATE"]], "lmflow.utils.conversation_template.gemma": [[79, 1, 1, "", "GEMMA_TEMPLATE"], [79, 2, 1, "", "GemmaConversationTemplate"], [79, 1, 1, "", "logger"]], "lmflow.utils.conversation_template.gemma.GemmaConversationTemplate": [[79, 3, 1, "", "encode_conversation"]], "lmflow.utils.conversation_template.hymba": [[80, 1, 1, "", "HYMBA_TEMPLATE"], [80, 2, 1, "", "HymbaConversationTemplate"]], "lmflow.utils.conversation_template.hymba.HymbaConversationTemplate": [[80, 3, 1, "", "encode_conversation"]], "lmflow.utils.conversation_template.internlm": [[82, 1, 1, "", "INTERNLM2_TEMPLATE"]], "lmflow.utils.conversation_template.llama": [[83, 1, 1, "", "LLAMA2_TEMPLATE"], [83, 1, 1, "", "LLAMA2_TEMPLATE_FOR_TOOL"], [83, 1, 1, "", "LLAMA3_TEMPLATE"], [83, 1, 1, "", "LLAMA3_TEMPLATE_FOR_TOOL"], [83, 2, 1, "", "Llama2ConversationTemplate"], [83, 2, 1, "", "Llama2ConversationTemplateForTool"], [83, 1, 1, "", "logger"]], "lmflow.utils.conversation_template.llama.Llama2ConversationTemplate": [[83, 3, 1, "", "_encode"]], "lmflow.utils.conversation_template.llama.Llama2ConversationTemplateForTool": [[83, 3, 1, "", "_encode"]], "lmflow.utils.conversation_template.phi": [[84, 1, 1, "", "PHI3_TEMPLATE"]], "lmflow.utils.conversation_template.qwen": [[85, 1, 1, "", "QWEN2_TEMPLATE"], [85, 1, 1, "", "QWEN2_TEMPLATE_FOR_TOOL"]], "lmflow.utils.conversation_template.yi": [[86, 1, 1, "", "YI1_5_TEMPLATE"]], "lmflow.utils.conversation_template.zephyr": [[87, 1, 1, "", "ZEPHYR_TEMPLATE"], [87, 2, 1, "", "ZephyrConversationTemplate"], [87, 1, 1, "", "logger"]], "lmflow.utils.conversation_template.zephyr.ZephyrConversationTemplate": [[87, 3, 1, "", "_encode"]], "lmflow.utils.data_utils": [[88, 2, 1, "", "RewardModelInferenceResultWithInput"], [88, 2, 1, "", "VLLMInferenceResultWithInput"], [88, 5, 1, "", "answer_extraction"], [88, 5, 1, "", "batchlize"], [88, 5, 1, "", "load_data"], [88, 5, 1, "", "process_image_flag"], [88, 5, 1, "", "set_random_seed"]], "lmflow.utils.data_utils.RewardModelInferenceResultWithInput": [[88, 4, 1, "", "input"], [88, 4, 1, "", "output"]], "lmflow.utils.data_utils.VLLMInferenceResultWithInput": [[88, 4, 1, "", "input"], [88, 4, 1, "", "output"]], "lmflow.utils.flash_attention": [[89, 0, 0, "-", "bloom_flash_attention"], [90, 0, 0, "-", "gpt2_flash_attention"], [91, 0, 0, "-", "gpt_neo_flash_attention"], [93, 0, 0, "-", "llama_flash_attention"], [94, 0, 0, "-", "triton_flash_attention"]], "lmflow.utils.flash_attention.bloom_flash_attention": [[89, 5, 1, "", "_prepare_attn_mask"], [89, 5, 1, "", "forward"], [89, 5, 1, "", "replace_bloom_attn_with_flash_attn"]], "lmflow.utils.flash_attention.gpt2_flash_attention": [[90, 5, 1, "", "_prepare_decoder_attention_mask"], [90, 5, 1, "", "forward"], [90, 5, 1, "", "replace_gpt2_attn_with_flash_attn"]], "lmflow.utils.flash_attention.gpt_neo_flash_attention": [[91, 5, 1, "", "_attn"], [91, 5, 1, "", "forward"], [91, 5, 1, "", "replace_gpt_neo_attn_with_flash_attn"]], "lmflow.utils.flash_attention.llama_flash_attention": [[93, 5, 1, "", "_prepare_decoder_attention_mask"], [93, 5, 1, "", "forward"], [93, 5, 1, "", "replace_llama_attn_with_flash_attn"]], "lmflow.utils.flash_attention.triton_flash_attention": [[94, 2, 1, "", "FlashAttnFunc"], [94, 2, 1, "", "FlashAttnKVPackedFunc"], [94, 2, 1, "", "FlashAttnQKVPackedFunc"], [94, 5, 1, "", "_bwd_kernel"], [94, 5, 1, "", "_bwd_kernel_one_col_block"], [94, 5, 1, "", "_bwd_preprocess_do_o_dot"], [94, 5, 1, "", "_bwd_store_dk_dv"], [94, 5, 1, "", "_flash_attn_backward"], [94, 5, 1, "", "_flash_attn_forward"], [94, 5, 1, "", "_fwd_kernel"], [94, 1, 1, "", "flash_attn_func"], [94, 1, 1, "", "flash_attn_kvpacked_func"], [94, 1, 1, "", "flash_attn_qkvpacked_func"], [94, 5, 1, "", "init_to_zero"]], "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnFunc": [[94, 3, 1, "", "backward"], [94, 3, 1, "", "forward"]], "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnKVPackedFunc": [[94, 3, 1, "", "backward"], [94, 3, 1, "", "forward"]], "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnQKVPackedFunc": [[94, 3, 1, "", "backward"], [94, 3, 1, "", "forward"]], "lmflow.utils.llava_conversation_lib": [[96, 2, 1, "", "Conversation"], [96, 2, 1, "", "SeparatorStyle"], [96, 1, 1, "", "conv_llama_2"], [96, 1, 1, "", "conv_llava_llama_2"], [96, 1, 1, "", "conv_llava_plain"], [96, 1, 1, "", "conv_llava_v0"], [96, 1, 1, "", "conv_llava_v0_mmtag"], [96, 1, 1, "", "conv_llava_v1"], [96, 1, 1, "", "conv_llava_v1_mmtag"], [96, 1, 1, "", "conv_mpt"], [96, 1, 1, "", "conv_templates"], [96, 1, 1, "", "conv_vicuna_v0"], [96, 1, 1, "", "conv_vicuna_v1"], [96, 1, 1, "", "default_conversation"]], "lmflow.utils.llava_conversation_lib.Conversation": [[96, 3, 1, "", "append_message"], [96, 3, 1, "", "copy"], [96, 3, 1, "", "dict"], [96, 3, 1, "", "get_images"], [96, 3, 1, "", "get_prompt"], [96, 4, 1, "", "messages"], [96, 4, 1, "", "offset"], [96, 4, 1, "", "roles"], [96, 4, 1, "", "sep"], [96, 4, 1, "", "sep2"], [96, 4, 1, "", "sep_style"], [96, 4, 1, "", "skip_next"], [96, 4, 1, "", "system"], [96, 3, 1, "", "to_gradio_chatbot"], [96, 4, 1, "", "version"]], "lmflow.utils.llava_conversation_lib.SeparatorStyle": [[96, 4, 1, "", "LLAMA_2"], [96, 4, 1, "", "MPT"], [96, 4, 1, "", "PLAIN"], [96, 4, 1, "", "SINGLE"], [96, 4, 1, "", "TWO"]], "lmflow.utils.model": [[97, 5, 1, "", "check_homogeneity"], [97, 1, 1, "", "logger"]], "lmflow.utils.multimodal": [[98, 5, 1, "", "adapt_llava_model_to_lmflow_type"], [98, 5, 1, "", "load_llava_pretrain_model"], [98, 5, 1, "", "update_custom_config"]], "lmflow.utils.position_interpolation": [[100, 0, 0, "-", "llama_rope_scaled_monkey_patch"]], "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch": [[100, 2, 1, "", "CondenseRotaryEmbedding"], [100, 5, 1, "", "replace_llama_with_condense"]], "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch.CondenseRotaryEmbedding": [[100, 3, 1, "", "forward"], [100, 4, 1, "", "max_seq_len_cached"], [100, 4, 1, "", "ntk_ratio"], [100, 4, 1, "", "pi_ratio"]], "lmflow.utils.versioning": [[101, 5, 1, "", "_is_package_available"], [101, 5, 1, "", "_is_packages_available"], [101, 5, 1, "", "get_python_version"], [101, 5, 1, "", "is_flash_attn_available"], [101, 5, 1, "", "is_flask_available"], [101, 5, 1, "", "is_gradio_available"], [101, 5, 1, "", "is_multimodal_available"], [101, 5, 1, "", "is_package_version_at_least"], [101, 5, 1, "", "is_ray_available"], [101, 5, 1, "", "is_trl_available"], [101, 5, 1, "", "is_vllm_available"], [101, 1, 1, "", "logger"]], "lmflow.version": [[102, 1, 1, "", "__version__"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "data", "Python data"], "2": ["py", "class", "Python class"], "3": ["py", "method", "Python method"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"], "6": ["py", "property", "Python property"]}, "objtypes": {"0": "py:module", "1": "py:data", "2": "py:class", "3": "py:method", "4": "py:attribute", "5": "py:function", "6": "py:property"}, "terms": {"": [4, 13, 16, 51, 66, 103, 105, 106, 108, 111, 112, 113, 114, 115], "0": [2, 4, 5, 6, 8, 13, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 51, 52, 55, 57, 60, 61, 66, 94, 102, 103, 107, 112, 113, 114, 115], "000": 103, "0001": 44, "0005": 4, "001": [25, 26, 28, 29, 31, 33, 36, 41, 43, 45], "002": [30, 38], "0025": 32, "004": 38, "00962": 36, "01": [37, 39, 45], "02155": [112, 113], "03265": 41, "04": 44, "05": 4, "0501": 103, "06": [27, 36, 45], "06677": 33, "08": [26, 28, 29, 30, 31, 32, 33, 37, 38, 39, 41, 43], "08217": [31, 43], "09843": 26, "1": [2, 3, 4, 5, 6, 13, 22, 26, 27, 31, 37, 42, 43, 44, 51, 52, 55, 61, 66, 94, 103, 105, 109, 110, 111, 115], "10": [4, 36, 103, 112, 113], "100": [4, 55, 60, 61, 66, 74, 94, 113], "1000": 4, "10000": [100, 112, 113], "10000000000": 4, "101": [13, 103], "1010": 13, "102": 13, "1024": [4, 55, 112], "105": 103, "106": 103, "109": 103, "10k": 113, "112k": [112, 113], "113": 103, "119": 103, "12": [112, 113], "120b": 115, "121": 103, "123": 103, "124": 103, "125": [103, 112], "128": [4, 94, 113], "129": 103, "12k": 113, "130": 103, "134": [74, 103], "135": 103, "139": 103, "13b": [103, 113], "140": 103, "141": 103, "146": 103, "147": 103, "149": 103, "15": 74, "150": 103, "151": 103, "153": 103, "155": 103, "16": [25, 57, 94, 113], "160": 103, "163": 103, "164": 103, "165": 103, "1659": 112, "167": 103, "1692": 112, "170": 103, "17192": 55, "17192v2": 55, "172": 103, "173": 103, "175": 103, "175b": 115, "176b": 115, "18": 115, "180": 103, "181": 103, "183": 103, "184": 103, "188": 103, "1902": 26, "1904": 36, "1908": [15, 41], "1935": 112, "1938": 112, "198": 103, "1b": 103, "1e": [25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 41, 43, 45, 55], "2": [4, 5, 6, 32, 42, 55, 57, 75, 80, 81, 94, 103, 105, 109, 110, 111, 115], "20": [4, 66, 103, 109, 112], "200": [74, 103], "2005": 112, "2006": [31, 43], "2020": [25, 112], "2023": [2, 103, 115], "2048": [4, 100], "206": 103, "207": 103, "2088": 13, "21": 115, "211": 103, "213": 103, "214": 103, "215": 103, "219": 103, "22": 112, "220": 103, "2203": [112, 113], "2208": 33, "2211": 55, "222": 103, "224": 103, "228": 103, "23": 115, "237": 103, "24": [50, 112, 113, 115], "240": 103, "245": 103, "25": 115, "254": 103, "256": 112, "258": 103, "25mb": 115, "26": 115, "262": 103, "266": 103, "27": 115, "28": [2, 115], "280b": 115, "29": 115, "2e": 112, "2k": 112, "3": [94, 103, 105, 106, 109, 110, 115], "30": [74, 103, 112, 115], "30b": 115, "32": [4, 94, 113, 115], "33": 103, "33b": 115, "34": 103, "35": [103, 115], "36": 115, "37": [103, 115], "38": 103, "39": [103, 112, 115], "3b": [103, 109, 112, 113], "3e": 112, "4": [4, 69, 103, 105, 112, 115], "40": [94, 103, 115], "400": 112, "41": 103, "42": [4, 5, 6, 103], "43": 115, "44": [103, 115], "447": 103, "46": 115, "48": [57, 94], "49": 115, "4bit": 4, "4rtemi5": 45, "5": [4, 55, 61, 103, 109, 112, 113, 115], "50": 115, "51": 115, "512": [4, 113], "5120": 44, "52": [103, 112, 113], "53": 103, "54": 115, "55": [103, 113, 115], "56": [103, 115], "57": [103, 115], "58": [103, 112, 113, 115], "59": [103, 115], "5k": [112, 113], "6": [37, 55, 103, 112, 115], "60": [103, 115], "600mb": 103, "61": [103, 115], "62": 103, "63": [103, 115], "64": [4, 94, 103, 112, 113, 115], "65": [103, 112, 113, 115], "66": [103, 115], "67": [103, 115], "68": [103, 115], "69": [103, 112, 113, 115], "7": [103, 112, 115], "70": [103, 115], "71": [103, 112, 113], "72": [103, 115], "73": [103, 115], "74": [103, 115], "75": [103, 115], "7592": 13, "76": [36, 103], "767": 103, "77": 103, "78": [103, 115], "79": [103, 112, 113], "7b": [103, 105, 107, 109, 112, 113, 115], "7oemwynu": 113, "8": [4, 57, 103, 112, 115], "80": [94, 113], "800": 112, "81": [103, 113], "8186": 45, "82": 103, "82147": 112, "83": 103, "84": 113, "85": [103, 115], "86": 103, "87": 115, "88": [94, 103], "888888888": 57, "89": 103, "8b": 109, "8fc1rcf8": 113, "9": [4, 8, 25, 26, 29, 30, 31, 32, 34, 36, 38, 39, 41, 42, 45, 102, 103, 106, 115], "90": 115, "900mb": 103, "92": 33, "95": [4, 27, 103], "96": [94, 103], "965": 44, "97": 103, "98": 33, "99": [33, 44], "999": [4, 25, 26, 29, 30, 31, 32, 34, 36, 38, 39, 41, 45], "9b": 103, "A": [1, 5, 6, 11, 12, 13, 14, 16, 21, 22, 25, 26, 31, 32, 34, 36, 37, 41, 42, 43, 44, 45, 47, 49, 52, 57, 61, 66, 73, 88, 96, 103, 105, 112, 114], "And": 7, "As": [32, 42, 103, 105, 112, 113, 114], "At": 60, "But": 112, "By": [4, 66, 107, 112, 115], "For": [4, 66, 71, 75, 94, 103, 105, 108, 109, 110, 112, 113, 114, 115], "If": [4, 61, 66, 88, 94, 103, 105, 106, 111, 112, 113, 115], "In": [66, 103, 105, 106, 107, 112, 113], "It": [4, 13, 14, 26, 31, 36, 41, 43, 45, 52, 66, 103, 105, 108, 112, 115], "Its": [103, 105, 115], "NOT": 55, "No": 103, "ONE": 108, "Of": [13, 16], "On": [41, 103], "One": [66, 103], "Or": [112, 113], "That": 112, "The": [1, 4, 5, 6, 7, 11, 12, 13, 14, 16, 22, 32, 34, 37, 42, 46, 50, 52, 53, 55, 57, 61, 66, 73, 75, 88, 94, 103, 105, 112, 113, 114, 115], "Then": [52, 107, 112], "There": [103, 112, 113], "These": [103, 108], "To": [32, 42, 66, 105, 108, 112, 113, 115], "Will": [66, 69], "With": [107, 114], "_": 65, "__call__": [7, 60, 67], "__distributed_infer": 58, "__filter_arg": 56, "__getitem__": 7, "__infer": [13, 16, 58], "__init__": [13, 14, 108], "__len__": [5, 6, 7, 66], "__model_module_inject": 15, "__post_init__": [4, 75, 81], "__post_process_model_output": 58, "__prepare_dtyp": 15, "__prepare_inputs_for_infer": 13, "__prepare_inputs_for_vllm_infer": 13, "__prepare_model_config": 15, "__prepare_model_for_infer": 15, "__prepare_model_for_train": 15, "__prepare_model_for_vllm_infer": 15, "__prepare_model_post_process": 15, "__prepare_peft_config": 15, "__prepare_quant_config": 15, "__prepare_token": 15, "__prepare_training_arg": 51, "__repr__": 75, "__setstate__": [25, 26, 30, 33, 37, 38, 39, 41, 44], "__str__": 75, "__version__": [8, 102], "__vllm_infer": [13, 16, 58], "_activ": 15, "_add_sm_patterns_to_gitignor": 66, "_align_single_iter": 56, "_attn": 91, "_bwd_kernel": 94, "_bwd_kernel_one_col_block": 94, "_bwd_preprocess_do_o_dot": 94, "_bwd_store_dk_dv": 94, "_calc_response_length": 51, "_calc_reward_with_length_penalti": 51, "_channel_view": [31, 43], "_check_data_format": [5, 6], "_check_if_align": 47, "_check_if_tun": 49, "_clean_text": [57, 112], "_cosine_similar": [31, 43], "_discard_sampl": [57, 112], "_distributed_infer": 69, "_do_reward_model_infer": 56, "_do_single_dpo_align": 56, "_do_target_model_infer": 56, "_encod": [75, 81, 83, 87], "_encode_templ": [75, 81], "_ensure_id_list": [75, 81], "_evaluate_acc_with_acceler": 52, "_evaluate_acc_with_deepspe": 52, "_evaluate_nl": 52, "_evaluate_ppl": 52, "_flash_attn_backward": 94, "_flash_attn_forward": 94, "_foreach_mul_": [32, 42], "_fwd_kernel": 94, "_gather_and_numpifi": 66, "_get_batch_dataset_loc": 57, "_get_batch_dataset_top": 57, "_get_collator_with_removed_column": 66, "_get_eval_sampl": 66, "_get_output_dir": 66, "_get_train_sampl": 66, "_hp_search_setup": 66, "_infer": [58, 69], "_initialize_train": [50, 57], "_inner_training_loop": 66, "_internal_cal": 66, "_is_native_cpu_amp_avail": 66, "_is_package_avail": 101, "_is_packages_avail": 101, "_issue_warnings_after_load": 66, "_layer_view": [31, 43], "_load_best_model": 66, "_load_dataset": [50, 57], "_load_from_checkpoint": 66, "_load_input_dataset": 57, "_load_optimizer_and_schedul": 66, "_load_rng_stat": 66, "_loggers_initi": 66, "_match": 52, "_maybe_log_save_evalu": 66, "_memory_track": 66, "_move_model_to_devic": 66, "_multi_tensor_adan": 33, "_nested_gath": 66, "_one_train": 66, "_pad_across_process": 66, "_parse_dpo_aligner_arg": 56, "_parse_reward_model_inference_arg": 56, "_parse_target_model_inference_arg": 56, "_prepare_attn_mask": 89, "_prepare_decoder_attention_mask": [90, 93], "_prepare_input": 66, "_project": [31, 43], "_provided_": 61, "_push_from_checkpoint": 66, "_remove_unused_column": 66, "_report_to_hp_search": 66, "_rotate_checkpoint": 66, "_sampling_paired_idx_from_reward": 51, "_sampling_paired_idx_from_rewards_fast": 51, "_save": [65, 66], "_save_checkpoint": [65, 66], "_save_tpu": 66, "_set_signature_columns_if_need": 66, "_signature_column": 66, "_single_tensor_adan": 33, "_sorted_checkpoint": 66, "_train_batch_s": 66, "_tune_save_checkpoint": 66, "_wrap_model": 66, "a1": 103, "a100": 94, "a2": 103, "a3": 103, "ab": [26, 31, 33, 36, 41, 43, 55, 112, 113], "abc": [10, 11, 12, 15, 19, 20, 22, 48, 69, 75], "abil": [103, 115], "abl": [22, 66, 103, 112], "about": [4, 66, 103, 112, 113, 115], "abov": [103, 105, 108], "abspath": 111, "abstract": [13, 14, 16, 47, 49, 55, 58, 69, 75, 108], "accelerate_config_fil": 4, "accept": [14, 15, 21, 52, 66, 105, 112], "access": [4, 66, 103, 105, 107, 115], "accid": 112, "accomplish": 112, "accord": [37, 66, 103, 112], "account": 115, "accuraci": [4, 52, 103, 112, 113, 115], "achiev": [103, 112, 115], "acquir": [103, 115], "across": [75, 94], "activ": [106, 112, 115], "activate_model_for_infer": 15, "actual": [75, 103, 112], "ad": [109, 112, 113], "adabelief": [3, 4, 35], "adabound": [3, 4, 35], "adadelta": [3, 4, 35], "adagrad": [3, 4, 35], "adam": [3, 4, 25, 35, 36, 103], "adamax": [3, 4, 35], "adamp": [3, 4, 35, 43], "adamw": [32, 66, 110], "adamw_schedule_fre": [3, 4, 35], "adamwschedulefre": 32, "adan": [3, 4, 35], "adapt": [4, 13, 14, 25, 26, 33, 41, 45, 65, 66, 110, 112, 115], "adapt_llava_model_to_lmflow_typ": 98, "add": [7, 32, 42, 66, 73, 105, 106, 108, 112, 114], "add_callback": 66, "add_dataclass_attr_prefix": 73, "add_generation_prompt": 114, "add_special_start": [75, 81], "add_special_stopp": [75, 81], "add_special_token": [13, 16, 70, 71], "addit": [4, 7, 66], "addition": [103, 112, 113], "additional_stop_token_id": 4, "adjust": [55, 112, 113], "administ": 103, "administr": 112, "adobada": 103, "adopt": 112, "advanc": 112, "advantag": 103, "advers": 103, "advic": 115, "affect": 113, "afflict": 103, "afford": [103, 112], "after": [4, 7, 13, 16, 55, 69, 75, 103, 106, 108, 112, 114], "ag": [105, 108, 114], "again": 66, "ago": 113, "ai": [103, 105, 112, 113, 115], "aim": 115, "al": 103, "algorithm": [25, 26, 31, 33, 36, 41, 43, 45, 103, 109, 110], "alibi": [89, 94], "align": [4, 37, 47, 50, 51, 56, 57, 105, 110], "aligner_arg": [50, 51, 56, 57], "aligner_file_path": 51, "all": [15, 40, 61, 66, 94, 96, 103, 105, 107, 108, 109, 112, 113, 115], "allevi": 112, "allow": [13, 14, 66, 103, 109, 115], "almost": 108, "along": 66, "alpaca": [103, 105, 107, 109], "alpha": 57, "alreadi": [4, 66, 75, 103, 105, 112, 113], "alright": 113, "also": [4, 11, 12, 32, 42, 52, 60, 66, 103, 106, 108, 112, 113, 114, 115], "altern": [112, 114], "although": [103, 112, 113], "alwai": [66, 103, 112, 114], "am": [103, 105, 108, 112, 114], "america": [112, 113], "american": 103, "among": 115, "amount": [112, 113], "amsbound": 26, "amsgrad": [25, 39], "an": [4, 10, 11, 12, 15, 19, 20, 22, 34, 48, 66, 69, 75, 94, 104, 105, 108, 109, 112, 113, 115], "analog": 37, "anatomi": 115, "ani": [7, 13, 16, 60, 66, 67, 103, 105, 112, 113, 114, 115], "anim": 113, "announc": 115, "anoth": [66, 103, 112], "another_data": 105, "answer": [13, 14, 50, 88, 103, 105, 106, 112, 113, 115], "answer_extract": 88, "answer_neg": 113, "answer_posit": 113, "answer_typ": [4, 52, 88, 106, 107], "anthropologi": 112, "anyon": 115, "anyth": 112, "api": [1, 103, 115], "api_doc": 66, "app": 66, "appear": 113, "append": 75, "append_messag": 96, "appl": 103, "appli": [4, 69, 75, 103, 105, 112, 115], "applic": [37, 66, 103, 115], "apply_chat_templ": [4, 13, 69], "appreci": 112, "approach": 115, "appropri": [66, 103, 112, 113], "approxim": 55, "ar": [13, 14, 16, 50, 60, 66, 73, 75, 94, 103, 105, 106, 107, 108, 112, 113, 114, 115], "arbitrari": 94, "arc_": 103, "arc_c": 103, "arc_easi": 103, "arch_typ": 4, "architectur": [4, 66], "area": [103, 113, 115], "aren": 112, "arena": 103, "arg": [3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 46, 47, 49, 51, 53, 55, 56, 57, 58, 59, 61, 63, 65, 66, 69, 70, 71, 79, 88, 96, 97, 111], "argmax": 55, "argument": [4, 5, 6, 13, 14, 15, 16, 21, 25, 26, 31, 32, 34, 36, 37, 41, 42, 43, 45, 52, 53, 55, 57, 58, 59, 66, 73, 75, 88, 105, 111], "argv": 111, "around": [13, 14, 103], "arr": 103, "arrai": [66, 103], "arriv": 103, "articl": 103, "arxiv": [26, 31, 33, 36, 41, 43, 55, 112, 113], "asada": 103, "ask": [108, 112], "aspect": 103, "assign": [4, 61, 112], "assist": [75, 80, 81, 103, 105, 106, 108, 112, 113, 114], "assistant_formatt": [75, 81, 108], "assistant_reply_0": 114, "assistant_reply_1": 114, "assistant_response_1": 105, "assistant_response_1_bad": 105, "assistant_response_1_good": 105, "assistant_response_2": 105, "assistant_response_2_bad": 105, "assistant_response_2_good": 105, "associ": 115, "assum": [113, 115], "at_init": 66, "atmospher": 112, "atomic_add": 94, "attack": 112, "attain": 115, "attempt": 103, "attend": 103, "attent": [13, 14, 22, 94], "attention_mask": [13, 22, 23, 89, 90, 91, 93, 113], "attn": 71, "auk": 113, "authent": 103, "author": [103, 115], "auto": [3, 4, 15], "auto_model": [3, 17], "auto_pipelin": [3, 54, 111], "autoapi": 3, "autoargu": [4, 111], "autocast": 66, "autocast_smart_context_manag": 66, "autograd": 94, "automat": [4, 9, 37, 46, 66, 104, 112], "automodel": 9, "automodelforsequenceclassif": 15, "autopipelin": [46, 111], "autoregressive_sampl": 55, "autotoken": 67, "avail": [66, 103, 105, 106, 115], "averag": [103, 115], "avoid": [22, 103, 112], "awar": [103, 115], "b": [44, 88, 106], "back": [4, 108, 112], "backbon": 115, "backend": [5, 6, 13, 14, 15, 16, 66, 94], "backend_dataset": [5, 6], "backward": [66, 94], "bad": 103, "bai": 103, "bake": [103, 112], "bar": [11, 12], "barbecu": 103, "barrel": 103, "base": [3, 4, 7, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 61, 65, 66, 68, 69, 79, 80, 81, 83, 87, 88, 94, 96, 100, 103, 108, 109, 112, 113, 115], "base_align": [3, 50, 51, 54, 57], "base_lr": 26, "base_model": [3, 11, 12, 15, 17, 20, 22], "base_pipelin": [3, 47, 49, 52, 54, 55, 58, 69], "base_trainer_class": 53, "base_tun": [3, 53, 54], "basealign": [47, 50, 51, 57], "basemodel": [10, 11, 12, 15, 20, 22, 57], "basepipelin": [47, 48, 49, 52, 55, 58, 69], "basetun": [47, 49, 53], "basic": [66, 113], "batch": [13, 22, 36, 37, 52, 60, 61, 66, 88, 94, 112, 113], "batch_input": 57, "batch_siz": [22, 58, 61, 66, 69, 88, 94, 112], "batchliz": [55, 88], "battl": 103, "bbq": 103, "beam": 4, "bean": 103, "beauti": 103, "becaus": [66, 103, 112], "been": [26, 31, 36, 41, 43, 45, 66, 94, 103, 112], "befor": [32, 42, 66, 105, 108, 112, 114, 115], "begin": [13, 16, 32, 37, 42, 105, 108, 112, 114], "begin_of_text": [105, 108, 114], "beginn": [108, 115], "behavior": 66, "behind": 103, "being": [66, 75, 80, 81, 103, 112, 113], "belief": [25, 112], "believ": 115, "below": [15, 105, 106, 108, 115], "ben": 103, "benchamrk": 106, "benchmark": [104, 110], "benchmarkingargu": 4, "benefit": 115, "bert": 36, "besid": 103, "best": [51, 65, 66, 103, 112, 113], "bestrun": 66, "beta": [4, 25, 26, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 44, 45, 61], "beta1": 33, "beta2": 33, "beta3": 33, "better": [103, 109, 112, 115], "between": [75, 94, 103, 108, 109], "beyond": 41, "bf16": 4, "bg677mxa": 113, "bia": [4, 94], "bias": 52, "bias_correction1": 33, "bias_correction2": 33, "bias_correction3_sqrt": 33, "bias_typ": 94, "bigger": 112, "bin": 66, "biologi": [103, 115], "bit": [4, 94, 112, 113], "blank": [11, 12], "blend": 103, "bleu": 66, "blip2config": 22, "blip2forconditionalgener": 22, "block": [4, 53, 66, 70, 71], "block_headdim": 94, "block_m": 94, "block_n": 94, "block_siz": [4, 52, 70, 71], "blocking_pair": 71, "blocking_text_to_textlist": 71, "blog": 115, "bloom": [103, 115], "bloom_flash_attent": [3, 92], "bo": [75, 105, 108, 114], "bold": 103, "bolt": 37, "book": 112, "bool": [4, 5, 6, 7, 13, 15, 16, 22, 26, 31, 33, 36, 37, 43, 44, 50, 51, 55, 58, 60, 61, 66, 67, 69, 73, 75, 81, 88, 89, 90, 93, 96, 97, 101], "boolean": 4, "boolq": 103, "booltensor": 89, "bos_token": [75, 108, 114], "both": [66, 94, 103, 112, 115], "bound": 26, "bowl": 103, "branch": [4, 106], "brand": 112, "break": [103, 113], "breakthrough": 103, "brief": [11, 12], "bring": [103, 112], "brisket": 103, "broadcast": 94, "brought": 103, "brown": 112, "buffer": 4, "bug": 112, "bui": 112, "build": [103, 112, 113, 115], "build_dataset": 113, "build_vision_tow": [23, 24], "built": 112, "burden": 112, "burrito": 103, "butter": 112, "byol": 37, "c": [88, 103], "cach": [4, 5, 6, 66], "cache_dir": [4, 50], "cache_en": 66, "cache_key_seqlen_k": 94, "cache_key_seqlen_q": 94, "cake": 103, "calam": 103, "call": [13, 14, 32, 42, 66, 103, 108, 112], "call_model_init": 66, "callabl": [25, 32, 34, 42, 61, 66], "callback": [61, 66], "callback_handl": 66, "calm": 103, "can": [4, 13, 14, 32, 42, 66, 73, 75, 103, 105, 106, 107, 108, 112, 113, 115], "can_return_loss": 66, "cannot": [15, 103], "cant": [112, 113], "capabl": 112, "capac": 115, "capit": 103, "capitol": 103, "caption": 22, "captur": 44, "card": 66, "care": 112, "carefulli": [103, 112], "caribbean": 112, "carn": 103, "carnita": 103, "carri": [103, 112], "carrier": 103, "casa": 103, "case": [60, 65, 66, 94, 103, 107, 112], "casual": 103, "cat": 112, "categori": 112, "cater": 115, "caus": [103, 112], "causal": 94, "causallmoutputwithpast": 22, "caution": 94, "cc": 45, "cd": [105, 106, 107, 109, 112], "cell": 112, "centuri": 112, "certain": [103, 112, 113], "cevich": 103, "chain": 103, "challeng": [103, 112, 113], "chang": [94, 106, 112], "changelog": [2, 115], "charact": 112, "chat": [4, 69, 105], "chatbot": [103, 105, 108, 114], "chatbot_typ": 55, "chatglm": [3, 81], "chatglm3": 105, "chatglm3_templ": [76, 81], "chatgpt": [103, 108, 115], "chatml": [3, 81, 105], "chatml_templ": [77, 81], "cheap": 103, "check": [5, 6, 66, 103, 105], "check_homogen": 97, "checkout": [106, 112], "checkpoint": [4, 32, 42, 65, 66, 103, 110, 112], "checkpoint_fold": 66, "checkpoint_path": 98, "checkpoint_prefix": 66, "chees": 103, "chemistri": 103, "chesapeak": 103, "chess": 103, "chessboard": 103, "chicken": 103, "child": 112, "chile": 103, "chili": 103, "chines": 103, "chip": 112, "chocol": [103, 112], "choic": [4, 88, 103, 112, 113], "choos": [4, 66, 103, 112], "chop": 112, "chosen": [50, 60, 61, 103, 105, 106, 112, 113], "chosen_attention_mask": 113, "chosen_input_id": 113, "chosen_reward": [61, 113], "circumst": [103, 112], "citi": 103, "civil": 112, "clamp_valu": 36, "class": [73, 108], "class_prefix": 73, "classfoo": [11, 12], "classic": 103, "classif": [13, 14, 66], "classmethod": [5, 6, 9, 46], "clean_text": 112, "clear": 112, "clearer": 113, "clearli": 112, "clinic": 115, "clip_encod": [3, 24], "clip_global_grad_norm": 33, "clipvisiontow": 23, "clone": [106, 115], "closur": [25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45], "clovaai": [31, 43], "co": [4, 112], "coal": 103, "coast": [103, 112], "cob": 103, "code": [5, 6, 7, 23, 26, 31, 36, 37, 41, 43, 44, 45, 55, 66, 103, 105, 114, 115], "code_exec": 55, "coleslaw": 103, "collard": 103, "collat": [7, 60, 66], "collect": [103, 112, 115], "collection_strategi": [4, 112], "colleg": 115, "coloni": 112, "columbia": 103, "column": 66, "column_nam": [70, 71], "com": [66, 103, 106, 112, 115], "comal": 103, "combin": 106, "come": [66, 103], "command": [106, 109, 112, 115], "comment": 108, "commerci": [112, 115], "commit": [4, 66], "commit_messag": 66, "common": [3, 95, 103, 105, 115], "commonli": [15, 74, 103, 105, 115], "commun": [103, 112, 115], "compani": 103, "compar": [103, 112, 113, 115], "comparison": [103, 112], "compet": [103, 115], "competit": 103, "compil": 94, "complet": [66, 112, 114, 115], "complex": [103, 113], "complic": 113, "compliment": 112, "compon": [75, 81, 108, 115], "comprehens": 103, "compress_list": 58, "comput": [61, 66], "compute_loss": [66, 68], "compute_loss_context_manag": 66, "compute_metr": [61, 66, 68], "compute_object": 66, "concaten": [66, 103, 105], "concept": [105, 108, 114], "concis": 113, "conda": [106, 115], "condens": 15, "condenserotaryembed": 100, "condit": [22, 94, 103, 105, 112], "confer": 103, "confid": 94, "config": [4, 15, 22, 23, 52, 55, 98, 111, 113], "config_nam": 4, "config_overrid": 4, "configu": [13, 14, 16], "configur": [4, 15, 112], "conflict": 103, "confus": 105, "conjectur": 103, "connot": 103, "consequ": 103, "consequenti": 115, "consist": [37, 112, 113], "consol": 52, "constant": [3, 95], "constexpr": 94, "constraint": 115, "constructor": 52, "contain": [3, 4, 5, 6, 11, 12, 13, 22, 52, 53, 55, 57, 58, 59, 61, 66, 69, 75, 103, 105, 112], "content": [105, 108, 113, 114], "context": [55, 66, 103, 112, 114], "context_window": 52, "contribut": 112, "contributor": [2, 115], "control": [4, 5, 6, 55, 65, 66], "controller_heart_beat_expir": 74, "conv_llama_2": 96, "conv_llava_llama_2": 96, "conv_llava_plain": 96, "conv_llava_v0": 96, "conv_llava_v0_mmtag": 96, "conv_llava_v1": 96, "conv_llava_v1_mmtag": 96, "conv_mpt": 96, "conv_templ": 96, "conv_vicuna_v0": 96, "conv_vicuna_v1": 96, "conveni": [13, 14, 75, 103, 112, 115], "convent": 115, "convers": [4, 5, 70, 71, 96, 103, 110, 112, 113, 115], "conversation_dataset_descript": 74, "conversation_id": [75, 80, 81, 105], "conversation_role_nam": 74, "conversation_templ": [3, 4, 70, 71, 95, 105, 108, 109], "conversation_tokenize_funct": [70, 71], "conversationtempl": [70, 71, 75, 79, 81, 83, 87, 108, 114], "conversationtemplatefortool": [75, 80, 81], "convert": [50, 51, 55, 60, 66, 75, 81, 88, 107], "convert_llama_weights_to_hf": 107, "convert_to_paired_dataset": 51, "convert_tokens_to_id": 75, "convienc": 105, "convolut": 37, "cook": [103, 112], "cooki": 112, "copi": [23, 73, 96, 112], "copyright": 107, "core": 66, "corn": 103, "corp": 112, "corpora": 103, "corpu": 103, "correct": [9, 105, 112, 113], "correctli": [65, 103, 112], "correl": 103, "correspond": [13, 69, 103, 105], "cosin": 4, "could": [103, 112], "count": [66, 103], "countri": 103, "court": 103, "cozi": 103, "crab": 103, "creat": [3, 5, 6, 10, 11, 12, 15, 19, 20, 22, 48, 52, 60, 65, 66, 69, 73, 75, 108, 110, 112, 113, 115], "create_copied_dataclass": 73, "create_customized_optim": 53, "create_dataload": [52, 55], "create_from_dict": [5, 6], "create_model_card": 66, "create_optim": 66, "create_optimizer_and_schedul": 66, "create_schedul": 66, "create_studi": 66, "creation": 112, "creator": 112, "crispi": 103, "criteria": 112, "critic": 103, "cross": 94, "cross_entropi": 61, "crowd": 103, "crucial": [113, 115], "ctx": 94, "cuda": [88, 94], "cuda_visible_devic": 107, "cue": 115, "cuisin": 103, "culinari": 103, "cultur": [103, 112], "cumul": 55, "cup": 112, "current": [4, 15, 66, 103, 105, 106, 109, 114], "current_flo": 66, "curv": 112, "custom": [4, 15, 66, 112, 113], "custom_model": [4, 14], "custom_vision_model": [4, 22], "customautovision2seqmodel": 22, "customized_cache_dir": 4, "customized_optim": 4, "customized_optim_arg": 4, "custommultimodaldataset": 7, "cybertronai": 36, "d": [88, 94, 103, 112, 113], "dahoa": [112, 113], "dai": 112, "damag": [103, 112, 115], "dampen": [37, 43], "danger": 103, "dark": 103, "data": [4, 5, 6, 7, 13, 16, 21, 52, 53, 57, 58, 66, 69, 75, 80, 81, 88, 103, 106, 107, 109, 112, 113, 115], "data_1": 105, "data_2": 105, "data_arg": [5, 6, 7, 46, 50, 51, 52, 53, 55, 56, 57, 58, 59, 69, 70, 71, 111], "data_col": [53, 59, 61, 66], "data_collect": 112, "data_dict": 7, "data_dir": 50, "data_fil": 113, "data_inst": 73, "data_root": 50, "data_util": [3, 13, 16, 58, 69, 95], "dataclass": [4, 73], "dataclass_object": 73, "datacol": [61, 66], "datacollatorforsuperviseddataset": 7, "datacollatorwithpad": 66, "dataload": [55, 57, 66, 88], "dataset": [1, 3, 4, 8, 13, 14, 16, 21, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 61, 66, 69, 70, 71, 75, 88, 103, 108, 109, 110, 111, 113, 115], "dataset_arg": 66, "dataset_config_nam": 4, "dataset_description_map": 74, "dataset_list": 56, "dataset_nam": [4, 106], "dataset_path": [4, 5, 6, 7, 105, 107, 108, 109, 112, 113], "dataset_path_list": 4, "dataset_s": 55, "dataset_tag": 66, "dataset_typ": [5, 51], "datasetargu": [4, 5, 6, 7, 51, 52, 53, 55, 56, 57, 58, 59, 69, 70, 71, 111], "date": 112, "ddp": 4, "de": 103, "deactiv": 15, "deactivate_model_for_infer": 15, "deadli": 103, "deal": 94, "death": 112, "debia": 36, "debug": 4, "decai": 37, "decid": [103, 106], "declin": 112, "decod": [13, 14, 52, 69, 88, 105], "decoder_model": [3, 13, 17], "decoder_onli": 4, "decodermodel": [11, 13], "decor": 4, "decreas": 113, "dedic": 112, "deep": [33, 36, 112], "deepseek": [3, 81, 105], "deepseek_templ": [78, 81], "deepspe": [4, 13, 14, 16, 66, 105, 106, 107, 111], "deepspeed_arg": 105, "def": [103, 111, 112, 113], "default": [4, 5, 6, 13, 14, 16, 34, 55, 66, 69, 73, 88, 112], "default_callback": 66, "default_compute_object": 66, "default_convers": 96, "default_data_col": 66, "default_hp_space_optuna": 66, "default_hp_space_rai": 66, "default_hp_space_sigopt": 66, "default_im_end_token": 74, "default_im_start_token": 74, "default_image_patch_token": 74, "default_image_token": 74, "default_progress_callback": 66, "defin": [1, 4, 5, 6, 7, 34, 37, 66, 105, 108, 114], "definit": 112, "degenerated_to_sgd": 25, "degrad": 103, "delay_load": 23, "delici": 103, "delta": [31, 43, 94], "demo": 103, "demo_example_in_prompt": 4, "democrat": 115, "demonstr": [103, 112, 115], "denot": 37, "depart": [103, 112], "depend": [4, 66, 103, 112], "deprec": [41, 66], "deriv": 4, "desc": 111, "describ": 103, "descript": [11, 12, 66, 105, 110, 114], "design": [46, 115], "desir": [66, 112, 113], "despit": 115, "detail": [66, 103, 106, 110, 112, 113, 114], "detect": 112, "determin": [66, 103], "detoken": [4, 13], "dev20221202": 94, "develop": [1, 103, 105, 108, 112, 114], "devic": [4, 13, 14, 15, 16, 23, 66, 100, 112], "diao": [0, 115], "dict": [4, 5, 6, 13, 15, 51, 55, 60, 61, 66, 67, 70, 71, 73, 75, 80, 81, 83, 87, 88, 96, 105, 108], "dict_obj": [5, 6], "dictionari": [5, 6, 34, 50, 52, 53, 66], "did": [112, 113], "didn": [112, 113], "diff": 107, "differ": [4, 5, 6, 13, 14, 51, 66, 75, 94, 96, 103, 107, 108, 112, 113, 114], "difficult": 103, "difficulti": 103, "dim": 100, "dimens": 94, "dinosaur": [112, 113], "diplomaci": 103, "diplomat": 112, "dir": [13, 14, 16, 106], "direct": [66, 105, 115], "directli": [75, 103, 106, 107, 115], "director": 112, "directori": [4, 13, 14, 16, 52, 66, 105, 112], "disabl": 112, "disable_dropout": 61, "disable_group_text": 4, "disast": [103, 112], "discard": 112, "discard_sampl": 112, "diseas": 103, "dish": [103, 112], "disk": 4, "distinct": 112, "distress": 103, "distribut": [4, 55, 66], "distributed_inference_num_inst": 4, "distributeddataparallel": 66, "district": 103, "divers": [4, 103, 112], "divis": 112, "dk": 94, "dk_ptr": 94, "do": [15, 66, 75, 94, 103, 105, 108, 112, 113, 114, 115], "do_dpo_align": 4, "do_grad_sc": 66, "do_response_gener": 4, "do_rope_sc": [4, 15], "do_sampl": 4, "do_scor": 4, "do_train": 15, "doc": 66, "docstr": [11, 12, 108], "document": [3, 66, 103], "doe": [34, 66, 103, 112, 113, 114, 115], "doesn": [15, 94, 103, 112], "dog": 103, "domain": [103, 115], "don": [7, 60, 65, 71, 105, 108, 112, 113, 114], "done": [94, 111], "dong": [0, 115], "donut": 103, "door": 103, "double_qu": 4, "down": [31, 43, 103], "download": [4, 103, 105, 106, 107, 109, 112], "dpo": [4, 51, 61, 105], "dpo_align": [3, 54], "dpo_loss": 61, "dpoalign": 50, "dpoalignerargu": 4, "dpotrain": 61, "dpov2": 4, "dpov2_align": [3, 54], "dpov2_dataprocessor": [3, 62], "dpov2_train": [3, 62], "dpov2align": 51, "dpov2alignerargu": [4, 51, 56], "dpov2train": 61, "dq": 94, "draft": [55, 66], "draft_config": 55, "draft_model": 55, "draft_model_arg": 55, "drink": 112, "drl": 112, "drop": [5, 6, 112], "drop_inst": [5, 6], "drop_invalid": [5, 6], "dropout": [66, 94], "ds_config": [4, 13, 14, 15, 16, 106, 107], "dtype": [4, 15, 23, 66], "due": [94, 103, 107], "dummi": [3, 4, 35], "dummy_featur": 23, "dure": [4, 66, 103, 113, 114], "dv": 94, "dv_ptr": 94, "dynam": [26, 66], "e": [4, 55, 57, 66, 88, 94, 105, 106, 112, 115], "each": [4, 13, 55, 61, 66, 69, 105, 108, 112, 113], "earth": 113, "easi": [103, 108, 112, 113], "easier": 66, "easili": [106, 113, 115], "east": 103, "econom": 103, "edit": [112, 113], "educ": 112, "effect": [103, 112, 113, 115], "effici": [1, 103, 109, 112, 115], "effortlessli": 103, "eg": 108, "egg": 112, "either": [66, 105, 112], "el": 103, "elabor": [112, 113], "element": [13, 60, 66, 69, 103, 115], "eleuth": [103, 106], "eleutherai": [103, 106, 112], "elif": 114, "elimin": 113, "ellipsi": 90, "els": [66, 111, 112, 113, 114], "embed": [15, 22], "emerg": 103, "emphas": 115, "employe": 112, "empti": [75, 105], "empty_no_special_token": 105, "empty_no_special_tokens_templ": [75, 81], "empty_templ": [75, 81], "emptyformatt": 75, "en": [66, 103], "en_multi_round_chat": 103, "en_singe_round_chat": 103, "enabl": [4, 115], "enable_decode_inference_result": [4, 69], "enable_distributed_infer": [4, 13, 16, 58, 69], "enchilada": 103, "encod": [13, 14, 52, 75, 81, 105, 114], "encode_convers": [75, 79, 80, 81], "encode_imag": 23, "encoded_pair": [75, 81], "encoder_attention_mask": 90, "encoder_decoder_model": [3, 14, 17], "encoder_hidden_st": 90, "encoderdecodermodel": [12, 14], "encourag": [105, 112], "end": [4, 13, 16, 37, 66, 105, 108, 114], "end_header_id": [105, 114], "end_of_turn": [105, 114], "end_str": 55, "endfor": 114, "endgam": 103, "endif": 114, "endoftext": [105, 114], "endpoint": 66, "endswith": 111, "enemi": 103, "engin": [103, 105], "england": 112, "english": 103, "enhanc": 115, "enjoi": [107, 112], "enough": [4, 113], "ensur": 37, "entail": 103, "enter": 103, "entir": [113, 115], "entri": 66, "enum": 96, "environ": 112, "eo": [4, 75, 105, 108], "eos_pad": 4, "eos_token": [75, 108, 114], "eos_token_id": 69, "eot_id": [105, 114], "ep": [25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 41, 43, 45], "epoch": [66, 103, 112, 113], "eq": 37, "equal": [60, 61, 66, 103], "equat": 37, "err": 106, "error": [66, 113], "escap": 103, "especi": 103, "essai": 103, "essenti": 103, "estim": [66, 113], "etc": [13, 14, 16, 21, 65, 66, 103, 105, 112, 115], "ethic": 103, "ethiopian": 103, "ethnic": 103, "evacu": 103, "eval": [32, 42, 61, 66, 112, 113], "eval_bleu": 66, "eval_dataset": [50, 51, 61, 66, 113], "eval_dataset_path": 4, "eval_pr": 68, "eval_step": [4, 112], "evalloopoutput": [61, 66], "evalpredict": 66, "evalu": [3, 4, 32, 42, 54, 66, 104, 105, 107, 112, 113, 115], "evaluate_block_s": 4, "evaluation_loop": 66, "evaluator_arg": 52, "evaluatorargu": [4, 52], "even": [103, 105, 113, 114], "even_headdim": 94, "even_m": 94, "even_n": 94, "event": 103, "eventu": 112, "ever": 112, "everett": 112, "everi": [57, 66, 105, 108], "everyon": 103, "exact": [106, 112], "exactli": [112, 113], "examin": 112, "exampl": [4, 7, 11, 12, 61, 66, 70, 71, 75, 80, 81, 88, 94, 103, 105, 106, 107, 108, 109, 114, 115], "example_dataset": 105, "excel": 112, "except": 115, "exchang": 112, "excit": 115, "exclud": 37, "execut": [66, 106], "exist": [66, 105, 108, 114], "exp_avg": 33, "exp_avg_diff": 33, "exp_avg_sq": 33, "expans": 115, "expect": [66, 103], "expens": 103, "experi": [66, 103, 112, 115], "experiment": [94, 103], "expert": 115, "explain": 112, "explan": 103, "explanation_in_prompt": 4, "exploit": 112, "explor": [112, 113], "explos": 103, "export": [11, 12], "extend": 37, "extens": [1, 112, 115], "extern": [66, 103], "extinct": 113, "extra": 112, "extra_id_0": [105, 114], "extra_id_1": [105, 114], "extract": [4, 88, 112], "extrem": 115, "face": [5, 6], "facebook": 109, "facebookresearch": 107, "facilit": 112, "factor": [103, 112], "factual": 103, "fail": 103, "falafel": 103, "fals": [4, 7, 13, 14, 15, 16, 22, 23, 25, 26, 31, 33, 36, 37, 39, 43, 44, 50, 51, 55, 58, 60, 61, 66, 68, 69, 75, 81, 89, 90, 91, 93, 94, 96, 101, 106, 112, 113, 114], "famou": 103, "far": 112, "fashion": [37, 66], "fast": 4, "faster": [33, 94, 103], "fate": 103, "featur": [60, 66, 67, 103], "feature_select": 23, "fed": [13, 14, 66], "feder": 103, "feed": [57, 66, 105], "feedback": [112, 113], "feel": [108, 112], "ferret": 103, "few": [103, 112, 115], "field": [4, 73, 105, 112, 113, 115], "field_prefix": 73, "fifth": 103, "fight": 112, "figur": [103, 112], "file": [4, 5, 6, 52, 66, 88, 105, 108, 110, 111, 112, 115], "file_nam": 88, "file_path": [5, 6], "fill": [103, 105, 114], "filter": [103, 113], "final": [65, 103], "final_lr": 26, "financi": 103, "find": [103, 112, 113], "fine": [7, 13, 14, 66, 112, 113, 115], "finetun": [1, 3, 54, 59, 103, 105, 107, 108, 115], "finetune_part": 4, "finetuned_from": 66, "finetuned_galactica_lora": 109, "finetuned_gpt2": 109, "finetuned_llama2_7b": 109, "finetuned_llama2_7b_lisa": 109, "finetuned_llama2_7b_lora": 109, "finetuned_llama3_8b": 109, "finetuner_arg": [53, 59], "finetunerargu": [4, 53], "fingerprint": [5, 6], "finish": [66, 106, 113], "fire": [103, 112], "firefight": 112, "fireplac": 112, "first": [1, 60, 66, 75, 80, 81, 103, 106, 107, 112, 113, 114], "fish": 103, "fit": [37, 103], "fix": [4, 94], "fixed_decai": 25, "flag": 22, "flame": 103, "flammabl": 103, "flash_attent": [3, 95], "flash_attn_func": 94, "flash_attn_kvpacked_func": 94, "flash_attn_qkvpacked_func": 94, "flashattent": 94, "flashattnfunc": 94, "flashattnkvpackedfunc": 94, "flashattnqkvpackedfunc": 94, "flatbread": 103, "flatten_list": 58, "flavor": 103, "flexibl": 108, "float": [4, 5, 6, 15, 16, 21, 26, 31, 33, 34, 36, 37, 41, 43, 45, 51, 52, 55, 58, 61, 66, 88, 112], "float32": 66, "float_onli": 5, "float_only_dataset_descript": 74, "floating_point_op": 66, "floattensor": [22, 61, 90], "florida": 112, "flour": 112, "folder": 65, "follow": [37, 50, 66, 105, 106, 108, 112, 113, 115], "foo": [11, 12], "food": [103, 112], "force_system": [75, 81], "foreach": [32, 33, 42], "foreign": 112, "forget": 103, "fork": 106, "form": [53, 66, 112], "format": [5, 6, 50, 55, 73, 75, 81, 108, 110, 114], "formatt": [75, 81], "former": [112, 113], "fort": [112, 113], "fortun": [112, 113], "forward": [22, 23, 66, 89, 90, 91, 93, 94, 100], "found": [66, 103, 112, 113, 115], "foundat": [103, 112, 115], "four": [105, 113], "fp16": 4, "framework": [1, 104, 112, 113], "free": [32, 42, 108], "frequent": 75, "fresh": 103, "fri": [103, 112], "friend": 103, "friendli": 115, "from": [4, 5, 6, 13, 14, 23, 25, 37, 44, 51, 52, 55, 66, 73, 88, 94, 103, 107, 108, 111, 112, 113, 114, 115], "from_dict": [5, 6], "from_pretrain": 66, "front": 7, "frustrat": 112, "fsdp": 66, "ft": 4, "fuel": 112, "full": [13, 14, 16, 65, 103, 110, 112, 113, 115], "fun": [112, 113], "function": [11, 12, 21, 22, 57, 66, 112, 113, 115], "function_formatt": [75, 81], "functionbar": [11, 12], "funtion": 88, "furnitur": [112, 113], "further": [4, 103, 112, 115], "futur": [15, 22, 112], "g": [4, 37, 66, 105, 112], "g_": 37, "ga": 103, "gain": [103, 112, 115], "galactica": [109, 115], "game": 112, "gamma": [26, 55], "gap": 103, "gather": [66, 112], "gear": 112, "gemma": [3, 81, 105], "gemma_templ": [79, 81], "gemmaconversationtempl": 79, "gener": [3, 4, 7, 13, 14, 16, 20, 22, 52, 55, 57, 66, 69, 88, 94, 103, 107, 110, 112, 113, 114, 115], "generate_during_ev": 61, "generate_kwarg": 22, "generate_qrcod": [105, 114], "generation_kwarg": 57, "genet": 115, "georg": 103, "get": [9, 21, 57, 66, 103, 106, 107, 110, 111], "get_backend": [5, 6], "get_backend_dataset": [5, 6], "get_backend_model": [14, 15, 22], "get_batch_loss_metr": 61, "get_batch_metr": 61, "get_data_arg": [5, 6], "get_eval_dataload": 66, "get_fingerprint": [5, 6], "get_imag": 96, "get_linear_schedule_with_warmup": 66, "get_max_length": [14, 15, 111], "get_model": 9, "get_optimizer_cls_and_kwarg": 66, "get_paired_dataset": 50, "get_peft_without_qlora": 13, "get_pipelin": [46, 111], "get_pipeline_args_class": [4, 111], "get_prompt": 96, "get_python_vers": 101, "get_reward_funct": 112, "get_test_dataload": 66, "get_token": [14, 15, 22], "get_train_dataload": 66, "get_typ": [5, 6], "giant": 113, "girl": 112, "girlfriend": 112, "git": [66, 106, 115], "github": [15, 103, 106, 112, 115], "gitignor": 66, "give": [103, 112, 113], "given": [4, 5, 6, 21, 52, 53, 55, 57, 58, 61, 66, 103, 105, 106, 112, 113, 114], "glad": [105, 112], "global": [66, 112], "gmask": [105, 114], "go": [66, 103, 107, 112], "goal": [112, 115], "golden": 112, "good": [103, 105, 107, 108, 112, 113], "goodi": 112, "gopher": 115, "govern": 103, "gpt": [103, 109, 112, 113, 115], "gpt2": [109, 112], "gpt2_flash_attent": [3, 92], "gpt3": 115, "gpt4_en_instruct": 103, "gpt_neo_flash_attent": [3, 92], "gpu": [4, 13, 14, 15, 16, 66, 69, 109, 112], "grad": [31, 33, 43], "grad_averag": 39, "grade": 112, "gradient": [25, 26, 37], "gradient_accumulation_step": 4, "gradient_checkpoint": 4, "gradient_checkpointing_use_reentr": 4, "grammar": 113, "great": [112, 113], "greater": [66, 103], "greatest": 112, "green": 103, "grill": 103, "groundtruth": 52, "group": [34, 53, 66, 111], "group_rank": 74, "group_text": [53, 111], "group_texts_batch_s": 4, "grow": 115, "guarante": [75, 80, 81, 115], "guess": [112, 113], "guest": 112, "guid": [110, 112, 113], "ha": [7, 13, 14, 26, 31, 36, 41, 43, 45, 52, 66, 75, 94, 103, 105, 108], "had": [108, 112, 113], "half": 112, "hallucin": 103, "hamburg": 103, "hand": [103, 112, 115], "handel": [70, 71], "handl": [60, 66, 75, 81, 112], "hanz": [0, 115], "happi": [103, 112], "har": [103, 106], "hard": [103, 112, 113], "hardship": 103, "hardwar": 112, "harm": 112, "has_imag": 7, "has_placehold": 75, "hasattr": [32, 42], "hasn": 66, "hate": 112, "have": [4, 15, 66, 94, 103, 105, 106, 107, 108, 112, 113, 114, 115], "hawaii": 103, "hazard": 112, "he": 112, "head": [94, 112], "head_mask": [89, 90, 91], "headdim": 94, "health": 103, "hear": 105, "heard": 112, "hearti": 103, "heat": [103, 112], "heater": 112, "heavi": 112, "heavili": 112, "height": [22, 103], "held": [103, 115], "hellaswag": 103, "hello": [13, 75, 80, 81, 115], "help": [4, 103, 105, 112, 114, 115], "helper": [10, 11, 12, 15, 19, 20, 22, 48, 66, 69, 75], "her": 112, "here": [52, 66, 71, 75, 80, 81, 103, 109, 112, 113], "hero": 112, "hf": [15, 105, 107, 109], "hf_auto_model": 15, "hf_auto_model_additional_arg": 15, "hf_automodel_map": 15, "hf_automodel_typ": 15, "hf_dataset_sanity_check": [5, 6], "hf_decoder_model": [3, 17, 51, 55, 56, 69, 72], "hf_encoder_decoder_model": [3, 17], "hf_model_config": 15, "hf_model_mixin": [3, 13, 16, 17], "hf_text_regression_model": [3, 17, 56, 58, 59, 72], "hfargumentpars": 111, "hfdecodermodel": [13, 14, 51, 52, 55, 56, 69], "hfencoderdecodermodel": 14, "hfmodelmixin": [13, 15, 16], "hftextregressionmodel": [16, 56, 58, 59], "hh": [112, 113], "hh_rlhf": [112, 113], "hh_rlhf_llama": 112, "hh_rlhf_raft_align": 112, "hh_rlhf_rm": 112, "hh_rlhf_rm_sft_gptneo_2_7b": 112, "hh_rlhf_rm_train": 112, "hh_rlhf_sft": 112, "hi": [75, 80, 81, 105, 112], "hidden": 108, "hidden_s": [22, 23], "hidden_st": [89, 90, 91, 93], "hide": [66, 112, 113], "hideo": 112, "high": 112, "higher": [55, 103, 112], "highlight": 115, "him": 112, "hing": 61, "hint": [4, 5, 6], "histor": 112, "histori": [96, 103, 112], "hit": 112, "hm": 112, "home": [103, 112, 113], "homeown": 103, "homework": 112, "homogen": 4, "honei": 103, "host": 112, "hostil": 103, "hot": [103, 112], "hous": [103, 112, 113], "how": [66, 103, 105, 108, 110, 112, 113, 114], "howev": [13, 14, 103, 107, 112, 115], "howpublish": 115, "hp": 66, "hp_name": 66, "hp_search_backend": 66, "hp_space": 66, "hpsearchbackend": 66, "html": [66, 103, 112], "http": [26, 31, 33, 36, 41, 43, 45, 55, 66, 103, 106, 112, 113, 115], "hub": [66, 103], "hub_model_id": 66, "hug": [5, 6, 105], "huge": [103, 113], "huggingfac": [4, 5, 6, 13, 14, 16, 107, 112, 113], "human": [103, 105, 106, 108, 112, 113, 114, 115], "hundr": 113, "hurrican": 112, "hymba": [3, 81, 105], "hymba_templ": [80, 81], "hymbaconversationtempl": 80, "hyper": [66, 110], "hyperparamet": 66, "hyperparameter_search": 66, "i": [4, 7, 13, 14, 15, 22, 32, 37, 42, 47, 49, 50, 52, 55, 57, 60, 66, 69, 75, 81, 94, 103, 105, 107, 108, 109, 112, 113, 114, 115], "ianz2020": 113, "icml": 103, "id": [4, 13, 14, 22, 69, 75, 81], "idea": [103, 112, 113], "ident": 66, "identifi": [66, 105, 113], "idx_gap": 113, "ignor": [61, 66], "ignore_bias_buff": 4, "ignore_index": 74, "ignore_kei": 66, "ignore_keys_for_ev": 66, "ignored_args_list": 73, "ill": 103, "illeg": 103, "illustr": [108, 113], "im_end": [74, 105, 114], "im_patch": 74, "im_start": [74, 105, 114], "imag": [7, 22, 23, 74], "image_aspect_ratio": 4, "image_encoder_name_or_path": [4, 22], "image_flag": 88, "image_fold": [4, 7], "image_forward_out": [22, 23], "image_processor": 7, "image_text": [5, 55], "image_token_index": [7, 22, 74], "imageher": 88, "imagin": [112, 113], "immedi": 103, "impact": [112, 113], "imperfect": 112, "implement": [13, 14, 15, 25, 26, 31, 33, 36, 41, 43, 45, 51, 66, 94, 103, 106, 112], "impli": 103, "implicitli": 61, "import": [4, 52, 66, 103, 108, 110, 111, 112, 115], "improp": 115, "improv": [103, 112, 113, 115], "incent": 112, "incentiv": 112, "incident": 115, "includ": [4, 5, 6, 51, 66, 88, 103, 112, 113, 115], "incompat": 66, "incomplet": 103, "inconveni": 103, "incorpor": 115, "incorrect": 103, "incorrectli": 112, "increas": [31, 43, 112, 113], "inde": 103, "index": [22, 66, 115], "index0": 114, "indian": 103, "indic": [4, 5, 6, 22, 103, 105], "indirect": 115, "induc": 103, "inf": 57, "infer": [1, 4, 13, 14, 16, 21, 22, 52, 55, 58, 69, 71, 105, 112, 115], "infer_batch_s": 57, "inferenc": [3, 4, 54, 58, 105], "inference_arg": 69, "inference_batch_s": 4, "inference_batch_size_per_devic": [4, 112], "inference_func": 21, "inference_result": 16, "inferencer_arg": [55, 58, 69], "inferencer_file_path": 69, "inferencerargu": [4, 55, 56, 58, 69], "inferencerwithoffload": 69, "influenc": 112, "info": 106, "inform": [4, 5, 6, 52, 66, 112, 115], "inher": 103, "inherit": [10, 11, 12, 15, 19, 20, 22, 48, 66, 69, 75, 108], "init": 66, "init_git_repo": 66, "init_to_zero": 94, "initi": [4, 5, 6, 13, 14, 16, 21, 52, 53, 55, 57, 58, 59, 66, 111, 112, 113], "initial_accumul": 45, "initial_iter_idx": 4, "inject": 66, "injera": 103, "injur": [103, 112], "injuri": 103, "injustic": 103, "inner": 66, "innov": 115, "inplac": 4, "input": [4, 7, 13, 14, 15, 16, 21, 22, 52, 55, 57, 61, 66, 68, 69, 71, 88, 103, 105, 106, 107, 108, 113], "input_dataset": 55, "input_dir": 107, "input_id": [7, 13, 22, 23, 55, 71, 113], "input_shap": [89, 90, 93], "inputs_emb": [22, 90, 93], "insert": 22, "inspir": 112, "inst": [105, 114], "instal": [66, 106], "instanc": [5, 6, 7, 13, 14, 16, 21, 51, 52, 53, 66, 73, 103, 105, 112, 113, 115], "instance_fields_map": 74, "instanti": 66, "instead": [4, 75, 94, 103], "institut": 103, "instruct": [1, 113], "instructgpt": [112, 113, 115], "int": [4, 5, 6, 13, 14, 15, 16, 51, 55, 58, 60, 61, 66, 67, 69, 70, 71, 75, 80, 81, 83, 87, 88, 89, 96, 112, 113], "int8": 4, "integ": [4, 75, 81], "integr": 106, "intellig": 115, "intend": 115, "intens": [103, 112], "interact": [108, 112], "interest": [112, 115], "interfac": [3, 13, 14, 16, 17], "intermedi": 65, "intern": [66, 103], "internal_vers": 8, "internlm": [3, 81], "internlm2": 105, "internlm2_templ": [81, 82], "interpol": 15, "interpret": 105, "interrupt": [65, 66], "intrins": 103, "introduc": [103, 112, 115], "introduct": 110, "invalid": 4, "invis": 108, "invok": 103, "involv": [103, 112, 113], "io": [66, 103, 112, 115], "ipex_optimize_model": 66, "irrelev": 103, "is_caus": 94, "is_custom_dataset": 4, "is_encoder_decod": [60, 61], "is_first_tim": 66, "is_flash_attn_avail": 101, "is_flask_avail": 101, "is_gradio_avail": 101, "is_in_train": 66, "is_load": 23, "is_local_process_zero": 66, "is_model_parallel": 66, "is_multimod": 4, "is_multimodal_avail": [6, 101], "is_package_version_at_least": 101, "is_ray_avail": 101, "is_sagemaker_mp_post_1_10": 66, "is_torch_greater_or_equal_than_1_10": 66, "is_torch_less_than_1_11": 66, "is_trl_avail": 101, "is_vllm_avail": 101, "is_world_process_zero": 66, "island": 103, "isn": 112, "issu": [4, 15, 103, 107, 112, 115], "item": [103, 106], "iter": [4, 34, 52, 55, 57, 66, 112], "iter_id": 57, "iterabledataset": 66, "iteration_nam": 56, "iterative_dpo_align": [3, 54], "iterativealignerargu": 4, "iterativedpoalign": 56, "iterativedpoalignerargu": [4, 56], "its": [46, 66, 103, 112, 115], "itself": 103, "j": [52, 112], "jack": 112, "japanes": 103, "jfk": 112, "jinja": 114, "jipeng": [0, 115], "job": 108, "join": 115, "joint": 103, "journal": 115, "journei": 112, "json": [4, 5, 6, 66, 75, 80, 81, 88, 105, 106, 107, 111, 112, 113], "json_fil": 111, "jsonl": 115, "judg": 112, "juic": 103, "just": [7, 15, 32, 42, 60, 94, 103, 105, 108, 112, 113, 115], "k": [57, 94, 103, 112], "ka": 0, "ka9v1ywd": 113, "kashun": 115, "katrina": 112, "kebab": 103, "keep": [96, 112, 113], "keep_end": [60, 61], "keep_linebreak": 4, "kei": [66, 91, 103, 105, 106, 112, 113], "keith": 112, "kennedi": 112, "key_1": [5, 6, 105], "key_2": [5, 6, 105], "key_3": 105, "key_4": 105, "key_inst": 5, "key_scor": 5, "key_typ": 5, "keyword": [5, 6, 13, 14, 16, 21, 53, 57, 59, 66, 75], "kid": [112, 113], "kind": [112, 113], "king": 103, "kitchen": 112, "kitfo": 103, "kl": 61, "knive": 112, "know": [112, 113], "knowledg": [103, 115], "known": 103, "kojima": 112, "konami": 112, "korean": 103, "kv": 94, "kwarg": [5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 20, 21, 23, 24, 46, 47, 49, 53, 56, 57, 58, 59, 65, 66, 69, 75, 79, 80, 81, 83, 87], "kwd": 96, "l": 94, "label": [7, 22, 23, 60, 66, 71, 103, 112, 113], "label_column": [70, 71], "label_id": 66, "label_nam": 66, "label_pad_token_id": [60, 61], "lamb": [3, 4, 35], "lambda": 113, "lambdalr": [61, 66], "land": 113, "landmark": 103, "languag": [4, 13, 14, 44, 52, 53, 66, 94, 103, 109, 115], "language_model": [22, 23], "language_model_from_pretrain": 22, "language_model_input": 22, "language_model_name_or_path": 22, "language_project": [4, 23], "lar": [3, 4, 35], "larg": [36, 37, 103, 112, 115], "lars_lr": 37, "last": [66, 105, 112, 113, 114], "last_checkpoint": 53, "latest": [66, 109], "laugh": 113, "launch": 66, "layer": [4, 37, 66, 109], "layer_past": [89, 90, 91], "layerwis": 110, "lead": [13, 16, 103, 112], "leader": 112, "leadership": 112, "leak": 103, "learn": [26, 32, 34, 36, 41, 42, 66, 112, 113, 115], "learning_r": [4, 112], "leav": [11, 12, 103, 112], "led": 112, "left": [94, 103], "legal": [103, 115], "len": [88, 103, 111, 113], "len_penalti": 61, "length": [4, 14, 15, 22, 51, 52, 53, 55, 60, 66, 88, 94, 103, 105], "length_penalti": [4, 51], "less": 103, "let": [111, 112, 113, 115], "level": [103, 115], "li": 115, "liabil": 115, "librari": [4, 66], "licens": [66, 103, 112], "light": 115, "lighter": 103, "lightn": 37, "lightweight": 115, "like": [37, 66, 94, 103, 105, 106, 108, 112, 114, 115], "likelihood": [52, 103, 106], "lime": 103, "limit": 103, "line": [11, 12, 103], "link": 105, "lisa": [110, 113], "lisa_activated_lay": [4, 109], "lisa_interval_step": [4, 109], "lisa_layers_attribut": 4, "list": [4, 5, 6, 13, 14, 16, 22, 33, 50, 51, 56, 58, 60, 61, 66, 67, 69, 71, 73, 75, 80, 81, 83, 87, 88, 96, 97, 101, 105, 108, 112, 115], "list_of_list": 58, "list_to_compress": 58, "listformatt": 75, "liter": [61, 75], "littl": 103, "liuhong99": 44, "live": [112, 113], "liyuanlucasliu": 41, "ll": [94, 112, 113], "llama": [3, 15, 81, 103, 105, 108, 109, 110, 112, 113, 115], "llama2": [105, 109], "llama2_templ": [81, 83], "llama2_template_for_tool": 83, "llama2conversationtempl": 83, "llama2conversationtemplatefortool": 83, "llama3": [105, 109], "llama3_templ": [81, 83], "llama3_template_for_tool": [81, 83], "llama_2": 96, "llama_flash_attent": [3, 92], "llama_rope_scaled_monkey_patch": [3, 99], "llava": 23, "llava_conversation_lib": [3, 95], "llava_load": 4, "llava_pretrain_model_path": 4, "llm": [4, 104, 108, 112, 115], "llm_model_name_or_path": 4, "lm": [4, 103, 110], "lm_dataset": 111, "lm_eval_dataset_map": 106, "lm_evaluation_metr": 4, "lmflow": [3, 104, 105, 108, 110, 111, 112, 113, 114], "lmflow_lora_target_modules_map": 74, "lmsy": 103, "ln": 52, "lntwmcyd": 113, "lo": 103, "load": [4, 5, 6, 13, 14, 22, 50, 52, 53, 55, 57, 58, 59, 66, 88, 107], "load_data": 88, "load_dataset": [112, 113], "load_in_4bit": 4, "load_inference_result": 69, "load_llava_pretrain_model": 98, "load_model": 23, "load_prompt_cach": 22, "load_result": 66, "loader": 52, "local": [66, 103, 112], "local_datset_answertype_map": 106, "local_datset_group_map": 106, "local_datset_map": 106, "local_rank": [4, 52, 55, 57, 58, 74], "locat": [103, 108], "lock": 103, "locksmith": 103, "log": [52, 61, 66, 103, 106], "log_dir": 106, "log_freq": 4, "logdir": 74, "logger": [4, 5, 13, 14, 15, 16, 51, 53, 55, 56, 57, 58, 59, 60, 61, 63, 64, 66, 67, 69, 70, 71, 73, 75, 79, 83, 87, 97, 101], "logging_step": 4, "logit": 66, "logsigmoid": 113, "long": [60, 66, 103, 105, 112], "longer": [51, 103], "longtensor": [22, 61, 93], "look": [108, 112], "loop": [66, 114], "loop_messag": 114, "lora": [1, 13, 14, 110, 113, 115], "lora_alpha": 4, "lora_dropout": 4, "lora_merg": 109, "lora_model_path": [4, 107, 109], "lora_r": 4, "lora_target_modul": 4, "lora_target_modules_map": 15, "loss": [25, 26, 31, 32, 34, 36, 37, 41, 42, 43, 45, 61, 66, 113], "loss_typ": [4, 61], "lot": [112, 113], "low": [110, 113], "low_resourc": [4, 22], "lower": [55, 66, 103], "loyal": 103, "lr": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45], "lr_schedul": [61, 66], "lr_scheduler_typ": 4, "lse": 94, "lst": 66, "luck": 103, "luolc": 26, "m": [94, 103, 105, 112, 113], "macaroni": 103, "machin": [66, 115], "made": [66, 103, 112, 113], "magic": 112, "magnitud": 103, "mai": [11, 12, 66, 103, 105, 106, 112, 113], "main": [4, 63, 64, 66, 106, 111, 112, 115], "main_process_first": 111, "mainstream": 112, "maintain": 115, "major": 103, "make": [55, 66, 75, 81, 94, 103, 105, 106, 108, 112, 113, 115], "make_shell_args_from_dataclass": 73, "malfunct": 112, "manag": 66, "mani": [94, 103, 112, 113], "manipul": [5, 6], "manual": [66, 103], "map": [4, 5, 6, 21, 111, 113], "mar": 2, "marathon": 113, "margarita": 103, "margin": 61, "margin_scal": [4, 51], "marin": 103, "maryland": 103, "mask": [4, 13, 14, 22, 71, 75, 94], "mask_prompt": [4, 60, 61], "master": 103, "match": [5, 6, 103], "materi": 112, "math": [37, 103], "mathemat": 115, "matter": 115, "max": [14, 15, 52], "max_eval_sampl": 4, "max_grad_norm": 33, "max_length": [4, 60, 61, 67], "max_max": 51, "max_min": 51, "max_new_token": [4, 55], "max_position_embed": 100, "max_prompt_length": [4, 60, 61], "max_random": [4, 51], "max_seq_len_cach": 100, "max_step": 4, "max_target_length": [60, 61], "max_train_sampl": 4, "maxim": [44, 66, 115], "maximum": [4, 52, 53, 55, 66], "mayb": [112, 113], "me": [112, 113], "mean": [66, 103, 112, 113], "meaning": 112, "meantim": 103, "measur": 113, "meat": [103, 112], "medic": 115, "medicin": 115, "medmcqa": 115, "medqa": 115, "melt": 112, "member": [66, 112], "memor": 103, "memori": [4, 109, 112], "memory_safe_dpov2_align": [3, 62], "memory_safe_dpov2_align_env_var_to_remov": 74, "memory_safe_vllm_infer": [3, 62], "memory_safe_vllm_inference_don": 74, "memory_safe_vllm_inference_env_var_to_remov": 74, "memory_safe_vllm_inference_finish_flag": 74, "memorysafedpov2align": 51, "memorysafevllminferenc": 69, "mention": 103, "menu": [103, 112], "merg": 110, "merge_lora": 112, "merge_lora_weight": [13, 14], "messag": [4, 5, 6, 66, 73, 75, 80, 81, 83, 87, 96, 105, 108, 113, 114], "meta": [105, 109], "metadata": [4, 66, 112], "metal": 112, "method": [5, 6, 13, 14, 15, 26, 45, 52, 66, 75, 103, 112, 115], "metric": [4, 52, 61, 65, 66, 106, 112], "metric_key_prefix": 66, "mexican": 103, "middl": 103, "might": [66, 112, 113], "mild": 103, "milk": 112, "million": 113, "min_vers": 101, "mini": 52, "mini_gpt": 55, "miniatur": 112, "minim": [66, 75], "minut": 36, "misc": 115, "misfortun": 103, "mistak": [103, 112], "mix": [4, 112], "mixed_arg": 56, "mixed_precis": 4, "mizuzu": 112, "mkdir": 106, "mlir": 94, "mmlu": 115, "modal": 7, "mode": [4, 32, 42, 66, 112], "model": [1, 3, 4, 7, 8, 25, 26, 31, 32, 33, 34, 36, 37, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 65, 66, 68, 69, 95, 98, 103, 105, 107, 108, 109, 110, 111, 114, 115], "model_arg": [9, 13, 14, 15, 16, 21, 46, 50, 51, 52, 53, 55, 56, 57, 58, 59, 69, 98, 111], "model_args_list": 97, "model_config_class": 4, "model_for_causal_lm_map": 4, "model_init": [61, 66], "model_input": [58, 69], "model_max_length": [4, 53, 70, 71, 111], "model_nam": [66, 106], "model_name_or_path": [4, 105, 106, 107, 108, 109, 112], "model_output": 58, "model_revis": 4, "model_s": 107, "model_typ": 4, "model_wrap": 66, "modelargu": [4, 15, 16, 51, 52, 53, 55, 56, 57, 58, 59, 63, 69, 97, 111], "modelconfig": 15, "modeling_output": [16, 22, 58], "modeling_util": 66, "modern": 103, "modif": 66, "modifi": [25, 37, 112, 113], "mole": 103, "momentum": [31, 33, 37, 42, 43], "momentum_decai": 38, "monei": 103, "monitor": 103, "monument": 103, "more": [55, 66, 103, 105, 109, 112, 113, 114, 115], "moreov": [113, 115], "morgan": 103, "most": [66, 103, 105, 112, 113], "mostli": [75, 105], "motiv": 112, "mpi4pi": [106, 115], "mpt": 96, "mu": 37, "much": 94, "multi": [7, 103], "multi_modal_dataset": [3, 6], "multimod": [3, 95], "multimodaldatasetargu": 4, "multipl": [22, 51, 94, 103, 112, 113, 114, 115], "museum": 103, "must": [66, 111, 114, 115], "mutipl": 88, "mv": 106, "my": [103, 112, 113], "n": [5, 6, 13, 52, 69, 103, 105, 106, 108, 113, 114, 115], "n_trial": 66, "nadam": [3, 4, 35], "name": [4, 13, 14, 16, 21, 32, 42, 46, 66, 73, 88, 94, 103, 105, 106, 108, 112, 114], "namedtupl": 66, "nassist": 114, "nation": [103, 112], "natur": [103, 115], "ndarrai": 66, "necessari": [4, 50, 66, 103, 108, 113], "need": [7, 32, 42, 65, 66, 71, 75, 103, 106, 107, 108, 112, 115], "neg": [52, 103, 106, 112, 113, 115], "negro": 103, "neighborhood": 103, "neither": 103, "neo": [112, 113], "nest": 66, "nestedtensor": 94, "nesterov": [31, 33, 37, 43], "network": [37, 112], "neurip": 25, "nevertheless": 103, "new": [5, 6, 66, 73, 94, 103, 106, 112, 113, 115], "new_default": 73, "next": [55, 108, 112], "nf4": 4, "nhead": 94, "nhello": 105, "nhow": 114, "ni": 114, "nice": 112, "nif": 113, "nip": 45, "nll": [52, 103, 110], "nlp": [13, 14, 103], "nn": [23, 34, 61, 66, 100, 113], "no_prox": 33, "nogada": 103, "nois": [112, 113], "noisi": 112, "non": [94, 112], "nonconvex": 45, "none": [4, 5, 6, 7, 13, 14, 15, 16, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 50, 52, 53, 57, 59, 60, 61, 65, 66, 67, 69, 73, 75, 80, 81, 83, 87, 88, 89, 90, 91, 93, 94, 96, 100, 113], "nonsens": 103, "noqa": 45, "nor": 103, "norm": [31, 43], "normal": [13, 14, 16, 52, 103], "north": 113, "northern": 103, "notat": 112, "note": [4, 15, 26, 31, 36, 37, 41, 43, 45, 66, 71, 103, 106, 115], "noth": 34, "notic": 106, "novograd": [3, 4, 35], "now": [103, 105, 107, 112, 113, 114], "np": 66, "ntk_ratio": 100, "num_capt": 22, "num_channel": 22, "num_exampl": 66, "num_inst": [58, 69], "num_label": 15, "num_new_token": 55, "num_output_sequ": 4, "num_patch": 23, "num_proc": 50, "num_raft_iter": [4, 112], "num_sampl": 55, "num_train_epoch": 112, "num_training_step": 66, "number": [4, 5, 6, 52, 55, 66, 109, 112, 113], "numpi": [66, 88], "nuser": 114, "nwhat": 105, "nwho": 114, "nyou": [105, 114], "o": [94, 103, 111], "oaxaca": 103, "obei": 103, "obj": [75, 81], "object": [5, 6, 7, 13, 16, 21, 52, 53, 55, 57, 58, 59, 66, 69, 73, 75, 81, 105, 114], "obqa": 103, "observ": [15, 25, 103, 112, 113, 115], "observation_formatt": [75, 81], "obstacl": 103, "obtain": [103, 107, 112, 113, 115], "occasion": 112, "occup": 112, "occupi": 113, "ocean": 112, "off": 112, "offer": [103, 112], "offici": [15, 107, 114], "offs_d": 94, "offs_n": 94, "offset": 96, "often": [103, 112], "oil": 112, "okai": 112, "old": [105, 108, 114], "omit": 103, "omp_num_thread": 74, "on_epoch_end": 65, "on_sav": 65, "on_train_end": 65, "onc": [66, 94], "one": [11, 12, 51, 66, 103, 105, 106, 109, 111, 112, 113], "one_sample_multiple_imag": 22, "ones": 113, "onli": [4, 21, 66, 94, 103, 105, 106, 108, 109, 111, 112, 113, 114, 115], "onlin": 103, "open": [104, 106, 115], "openai": 94, "oper": [4, 66], "opportun": 112, "oppress": 103, "opt": [103, 115], "optim": [3, 8, 61, 65, 66, 105, 112, 115], "optim_adam_beta1": 4, "optim_adam_beta2": 4, "optim_beta1": 4, "optim_beta2": 4, "optim_beta3": 4, "optim_dummy_beta1": 4, "optim_dummy_beta2": 4, "optim_momentum": 4, "optim_weight_decai": 4, "optimalscal": [103, 112, 115], "optimizer_kera": 45, "optimizer_nam": 66, "optimizer_typ": 4, "optimizernam": 4, "option": [4, 5, 6, 11, 12, 13, 14, 15, 16, 21, 22, 25, 32, 34, 42, 53, 55, 57, 59, 66, 69, 73, 94, 103, 105, 107, 108, 112], "optuna": 66, "order": [44, 103, 105], "org": [26, 31, 33, 36, 41, 43, 55, 103, 112, 113], "organ": [103, 112, 113], "orient": 115, "origin": [66, 73, 75, 103, 107, 112, 113], "original_dataclass": 73, "other": [52, 61, 66, 94, 103, 112, 113, 115], "otherwis": 66, "otherworld": 112, "ouptut": 103, "our": [15, 103, 105, 106, 107, 108, 109, 110, 111, 112, 115], "out": [66, 94, 103, 108, 112, 113, 115], "outag": 112, "outcom": 115, "output": [4, 13, 14, 16, 51, 52, 55, 57, 66, 69, 71, 88, 103, 105], "output_attent": [22, 89, 90, 91, 93], "output_dataset": 55, "output_dir": [4, 56, 66, 107, 112], "output_hidden_st": 22, "output_lora_path": 109, "output_max_length": [4, 57], "output_min_length": [4, 57], "output_model": [107, 108, 109, 112], "output_model_path": [108, 109], "output_reward_path": [4, 57], "over": [52, 103, 105, 112, 113], "overal": [11, 12, 13, 14, 94, 115], "overfit": 113, "overrid": [4, 15, 22, 66], "overridden": 66, "overse": 112, "overview": [110, 113], "overwrite_cach": 4, "overwrite_output_dir": 66, "overwritten": 112, "own": [66, 103, 105, 106, 108, 112, 113, 115], "oyster": 103, "p": [31, 37, 43, 52, 55], "p2ju3r1a": 113, "p_": [37, 52], "pacif": 103, "packag": [52, 101, 110, 115], "package_nam": 101, "pad": [4, 22, 60, 66, 67], "pad_index": 66, "pad_to_multiple_of": 67, "pad_token_id": [70, 71], "padding_sid": [4, 70, 71], "padding_valu": [60, 61], "paddingstrategi": 67, "page": [3, 103, 115], "paged_adamw_32bit": 4, "pain": 112, "pair": [51, 75, 80, 81, 103, 106, 108, 110], "paired_convers": [5, 105], "paired_conversation_dataset_descript": 74, "paired_conversation_tokenize_funct": 71, "paired_text_to_text_dataset_descript": 74, "pan": [0, 115], "panda": 113, "paper": [37, 45, 112, 113], "par": 103, "parallel": [4, 66, 94], "param": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45], "paramet": [4, 5, 6, 13, 14, 15, 16, 21, 32, 34, 37, 42, 52, 53, 55, 57, 58, 59, 61, 66, 69, 73, 75, 81, 88, 105, 110, 113, 114, 115], "parent": 112, "pars": 111, "parse_args_into_dataclass": 111, "parse_json_fil": 111, "parse_to_sampling_param": 69, "parser": 111, "part": [37, 103], "partial": 103, "particip": 115, "particular": [112, 113, 115], "partit": 103, "pass": [4, 15, 66, 94, 103, 105, 111, 115], "past_key_valu": [22, 23, 93], "past_key_values_length": [89, 90, 93], "pasta": 103, "pastor": 103, "path": [4, 5, 6, 13, 14, 16, 21, 22, 66, 106, 107, 111, 112], "path_to_dataset": 105, "path_to_your_model": 108, "patient": 112, "pattern": 66, "peac": 112, "peakier": 55, "peanut": 112, "pecan": 112, "peft": 65, "peft_config": [15, 61], "peft_train": [3, 62, 68], "peftrewardtrain": 68, "peftsavingcallback": 65, "pefttrain": [65, 68], "penal": [4, 51], "peopl": [103, 112, 115], "pepper": 103, "per": [4, 112], "per_device_eval_batch_s": 4, "per_device_train_batch_s": [4, 112], "percentag": 113, "perfect": 112, "perform": [5, 6, 13, 14, 16, 22, 25, 26, 31, 32, 33, 34, 36, 37, 41, 42, 43, 45, 52, 53, 55, 57, 58, 59, 66, 69, 109, 112, 115], "period": [11, 12, 103], "permiss": 103, "permit": 103, "perplex": [4, 103], "persecut": [103, 112], "person": 112, "perturb": [31, 43], "pet": 103, "pete": 103, "phantom": 112, "phenomenon": [103, 112], "phi": [3, 81], "phi3": 105, "phi3_templ": [81, 84], "phil": 94, "phone": 112, "pi_ratio": 100, "pick": 66, "pie": 103, "piec": [105, 108, 114], "pile": [112, 113], "pioneer": 103, "pip": [106, 115], "pipelin": [3, 4, 8, 105, 111, 112, 115], "pipeline_arg": [14, 46, 111], "pipeline_argument_map": 4, "pipeline_map": 46, "pipeline_nam": [46, 111], "pipeline_needs_extra": 46, "pipelineargu": 111, "piqa": 103, "pit": 103, "pivot": 103, "pixel_valu": 22, "place": [32, 42, 66, 112, 113], "place_model_on_devic": 66, "placehold": 15, "plai": 103, "plain": [4, 88, 96], "plan": [94, 112], "plantain": 112, "platform": 115, "plausibl": 103, "pleas": [41, 75, 105, 106, 108, 109, 112, 113, 114, 115], "plot": 112, "poblano": 103, "pocket": 112, "point": [66, 94, 112], "polic": 103, "polici": [4, 61, 103, 112], "policy_chosen_logp": 61, "policy_rejected_logp": 61, "polish": 23, "poor": 112, "pop": 66, "pop_callback": 66, "popish": 112, "popul": [103, 113], "popular": [103, 112], "pork": 103, "portion": 103, "posit": [5, 6, 13, 14, 15, 16, 21, 53, 57, 59, 103, 112, 113, 115], "position_id": 93, "position_interpol": [3, 95], "possess": 103, "possibl": [103, 113], "post": [112, 113], "post_process_pair": [75, 81], "postprocess_distributed_inference_output": 16, "postprocess_inference_output": 16, "potenti": [66, 103], "powder": 112, "power": [112, 115], "ppl": 103, "ppo": 112, "practic": 103, "pre": 44, "pre_grad": 33, "precis": 4, "predict": [55, 66, 103, 108], "predict_next_token": 55, "predicted_answ": 52, "prediction_loop": 66, "prediction_loss_onli": 66, "prediction_step": 66, "predictionoutput": 66, "prefer": [105, 112, 113], "preferencedatacollatorwithpad": 60, "prefix": [66, 73, 113], "prefix_checkpoint_dir": 66, "prelat": 112, "prepar": [13, 15, 51, 57, 66, 106, 112, 113, 115], "prepare_inputs_for_infer": [13, 16], "prepare_inputs_labels_for_multimod": 23, "prepend": 66, "preprocess": [66, 113], "preprocess_llama_from_llava_plain": 7, "preprocess_llama_from_llava_v1": 7, "preprocess_logits_for_metr": [61, 66], "preprocess_multimodal_llava": 7, "preprocessing_num_work": [4, 61], "present": [66, 112], "preset": [15, 105, 108, 114], "preset_templ": [81, 108], "presid": 103, "pretrain": [4, 13, 14, 66, 103, 107, 115], "pretrained_language_projection_path": 4, "pretrained_path": 22, "pretrainedmodel": [60, 61, 66], "pretrainedtoken": [7, 15, 70, 71, 75, 80, 81, 83, 87], "pretrainedtokenizerbas": [60, 61, 66], "pretrainedtokenizerfast": [15, 70, 71], "pretti": 113, "previou": [66, 112, 113], "price": 103, "print_bann": 73, "print_change_log": 25, "priorit": 103, "privat": 4, "privileg": 112, "prob": 55, "probabilist": 115, "probabl": [55, 61, 66, 103, 112, 113], "problem": [103, 110, 112], "procedur": [103, 112, 113], "proceed": 103, "process": [7, 13, 14, 16, 22, 52, 53, 55, 57, 66, 103, 105, 110, 111, 112, 113, 115], "process_image_flag": 88, "processor_image_token_in_minigpt4": 22, "produc": 103, "product": [112, 115], "profession": 115, "profici": 115, "program": [11, 12, 88, 112], "progress": 66, "prohibit": 103, "project": [15, 103, 112, 113], "project_dir": 112, "prompt": [4, 7, 13, 14, 16, 22, 50, 55, 57, 60, 69, 75, 105, 112, 113, 115], "prompt_cache_path": 4, "prompt_id": 22, "prompt_keys_valu": 22, "prompt_structur": [4, 55, 106, 107], "proper": 103, "properli": [103, 112], "properti": [23, 103, 105, 114], "propon": 112, "proport": [4, 5, 6], "propos": [26, 31, 33, 36, 41, 43, 45], "protect": 112, "provid": [4, 10, 11, 12, 13, 14, 15, 19, 20, 22, 41, 48, 52, 55, 66, 69, 75, 103, 105, 106, 108, 110, 112, 114, 115], "pt": [66, 67], "public": [1, 112], "publicli": 115, "publish": 115, "pubmedqa": 115, "pull": 103, "punctuat": 113, "purpos": 108, "purs": 112, "push": 66, "push_to_hub": 66, "put": [7, 106], "py": [94, 105, 106, 107, 108, 112, 113], "python": [5, 6, 7, 75, 103, 106, 107, 115], "pytorch": [25, 33, 36, 37, 60, 66], "pytorch_": 41, "pytorchlightn": 37, "q": [94, 103], "q1": 103, "q2": 103, "q3": 103, "qa": [88, 103], "qformer_from_pretrain": 22, "qformer_name_or_path": [4, 22], "qkv": 94, "qr": [105, 114], "qualit": 103, "qualiti": [103, 112], "quant_config": 15, "quant_typ": 4, "quantit": 103, "quantiti": 66, "quantiz": 4, "queri": 91, "quesadilla": 103, "queso": 103, "question": [13, 14, 50, 57, 103, 105, 113, 115], "quick": 112, "quicker": 4, "quickli": [103, 115], "quicksort": 103, "quit": 94, "qwen": [3, 81, 109], "qwen1": 109, "qwen2": 105, "qwen2_templ": [81, 85], "qwen2_template_for_tool": [81, 85], "r": [32, 42], "r1": 103, "r2": 103, "r3": 103, "rabi": 103, "race": 94, "radam": [3, 4, 35], "raft": [4, 61, 110], "raft_align": [3, 4, 54, 112], "raft_aligner_arg": 57, "raft_batch_s": [4, 112], "raft_train": [3, 62], "raftalign": 57, "raftalignerargu": [4, 57], "rafttrain": 66, "raggedtensor": 94, "rai": [13, 16, 58, 66, 69], "rais": [5, 6, 66], "raise_except": 114, "random": [51, 55, 66, 88, 112], "random_se": 4, "random_shuffl": [4, 88], "randomli": [51, 109, 112], "rang": [61, 103, 113, 115], "rank": [74, 110, 112, 113], "rare": 113, "rarest": 113, "rate": [26, 32, 34, 41, 42, 66, 112, 113], "rather": [32, 42], "raw": [103, 105], "re": [60, 66, 112, 113], "read": [112, 113], "reader": 112, "readi": 112, "readm": 115, "readthedoc": 66, "real": [103, 105], "realli": [112, 113], "reason": [66, 112], "recal": 108, "receiv": 66, "recent": 103, "recip": 112, "recommend": [103, 112], "record": [112, 113], "rectifi": 25, "recurs": [66, 103], "reduc": [94, 112], "redund": 112, "reevalu": [25, 26, 31, 32, 34, 36, 37, 41, 42, 43, 45], "ref": 55, "ref_model": [51, 61], "ref_model_arg": [51, 56], "refer": [25, 26, 31, 36, 37, 41, 43, 45, 61, 66, 71, 105, 106, 108, 110, 112, 114, 115], "reference_chosen_logp": 61, "reference_fre": 61, "reference_rejected_logp": 61, "referencemodelargu": [51, 63], "reflect": [66, 103], "reform": 112, "reformul": 112, "regard": 103, "regist": [15, 21, 94], "register_inference_funct": 21, "register_prompt_cach": 22, "register_token": 7, "registr": 110, "regress": [20, 21], "regression_model": [3, 17, 21], "regressionmodel": [20, 21, 57], "reinforc": [112, 113], "reiniti": 66, "reject": [50, 51, 60, 61, 105, 112, 113], "rejected_attention_mask": 113, "rejected_input_id": 113, "rejected_reward": [61, 113], "rel": 113, "relat": [52, 112, 115], "releas": [13, 15, 16, 69, 112, 115], "release_gpu": [13, 16, 69], "relev": 115, "reli": 115, "reliabl": [103, 112, 115], "relianc": 115, "religion": 112, "relleno": 103, "reload": 66, "remain": [51, 103], "remark": [112, 113, 115], "rememb": [75, 106, 112], "remind": 112, "remov": [66, 73, 112], "remove_callback": 66, "remove_dataclass_attr_prefix": 73, "remove_image_flag": 55, "remove_last_sep": [75, 81], "remove_last_separ": [75, 81], "remove_unused_column": 4, "repetit": 4, "repetition_penalti": 4, "replac": [15, 75, 105, 112], "replace_bloom_attn_with_flash_attn": 89, "replace_gpt2_attn_with_flash_attn": 90, "replace_gpt_neo_attn_with_flash_attn": 91, "replace_llama_attn_with_flash_attn": 93, "replace_llama_with_condens": 100, "repli": 112, "repo": [66, 106, 112], "report_to": 4, "repositori": [66, 103, 115], "repres": [4, 5, 6, 13, 14, 16, 52, 75], "requir": [5, 6, 32, 42, 52, 53, 55, 57, 58, 59, 103, 105, 108, 112, 113, 114, 115], "require_vers": 4, "rerun": 66, "rescu": 112, "research": [103, 112], "reset": 25, "residu": 89, "resolv": 112, "resourc": [13, 15, 16, 69, 112], "respect": [32, 37, 42, 61, 112], "respond": 108, "respons": [60, 61, 66, 88, 103, 112, 113, 115], "rest": [11, 12], "restart": 112, "restart_opt": 33, "restaur": 103, "restor": 112, "result": [4, 21, 69, 103, 112, 113, 115], "result_cache_path": 56, "results_path": [4, 69], "resum": 66, "resume_from_checkpoint": 66, "retrain": 112, "retriev": [5, 6], "return": [4, 5, 6, 7, 13, 14, 16, 22, 25, 26, 31, 32, 34, 36, 37, 41, 42, 43, 45, 46, 52, 53, 55, 57, 61, 66, 69, 73, 75, 81, 88, 103, 112, 113], "return_code_error_buff": 74, "return_dict": 22, "return_output": [66, 68], "return_pil": 96, "return_tensor": [7, 67], "reus": [22, 66], "rev_kl": 61, "review": 112, "revis": [13, 14, 16, 21], "reward": [4, 15, 51, 57, 61, 105, 110], "reward_model": [47, 50, 57], "reward_model_arg": 56, "reward_model_inference_batch_s": 4, "reward_model_inference_block_s": 4, "reward_model_or_path": 112, "rewarddatacollatorwithpad": 67, "rewardmodelinferenc": 58, "rewardmodelinferenceresultwithinput": [16, 58, 88], "rewardmodeltun": 59, "rewardmodeltunerargu": [4, 59], "rewardtrain": 68, "rewrit": 113, "rho": [27, 44], "rib": 103, "rich": 103, "right": [4, 66, 70, 71, 103, 112, 114], "risk": 115, "rl": 112, "rlhf": [112, 113], "rlhf_prompt": 112, "rm": [71, 112, 113], "rm_dataprocessor": [3, 62], "rm_inferenc": [3, 54], "rm_loss": 68, "rm_trainer": [3, 62], "rm_tuner": [3, 54], "rng": 66, "robin": 103, "robust": [94, 115], "role": [75, 80, 81, 96, 103, 105, 108, 112, 113, 114], "role_nam": 74, "role_rank": 74, "room": [112, 113], "root": 112, "rope_ntk_ratio": 4, "rope_pi_ratio": 4, "roughli": 103, "round": [103, 105, 112, 114], "rstrip_partial_utf8": 55, "rui": [0, 115], "run": [4, 52, 53, 57, 66, 103, 105, 106, 107, 112, 113], "run_evaluation_with_lora": 107, "run_finetun": [105, 108, 109, 112], "run_finetune_with_lisa": 109, "run_finetune_with_lora": [109, 112], "run_merge_lora": 109, "run_nam": 4, "run_raft_align": 112, "run_reward_model": [112, 113], "run_summari": 66, "rwandan": 112, "safe": [66, 103, 112], "safeti": [103, 112], "sagemak": 66, "sai": [108, 112, 113], "said": [108, 112], "salam": 112, "salem": 112, "salmonellosi": 103, "salt": [103, 112], "same": [4, 66, 105, 112, 113], "samoa": 112, "sampl": [4, 5, 6, 13, 51, 52, 55, 66, 69, 103, 105, 110, 112, 113], "sample_dataset": [5, 6], "sample_input_1": 105, "sample_input_2": 105, "sample_input_3": 105, "sample_output_1": 105, "sample_output_2": 105, "sample_output_3": 105, "sample_text_1": 105, "sample_text_2": 105, "sample_text_3": 105, "sampler": 66, "sampling_paired_idx_from_reward": 51, "sampling_paired_method": [4, 51], "sampling_param": [13, 16, 69], "samplingparam": [13, 16, 69], "saniti": [5, 6], "sanity_check": [4, 5, 6, 50], "sauc": [103, 112], "save": [4, 5, 6, 13, 14, 16, 22, 32, 42, 65, 66, 69, 107, 112, 115], "save_aggregated_lora": 4, "save_count": 66, "save_file_path": 69, "save_full_model": [13, 14], "save_inference_result": 69, "save_language_project": 4, "save_model": 66, "save_pretrain_model_path": 4, "save_prompt_cach": 22, "save_result": [4, 69], "save_step": 4, "scalabl": [44, 103, 115], "scalar": 4, "scale": 37, "scaler": 66, "scaler_nam": 66, "scenario": 103, "scene": 103, "schedul": [32, 42, 66], "scheduler_nam": 66, "scienc": 112, "scope": 113, "score": [5, 16, 51, 55], "score_to_prob": 55, "scout": 112, "scratch": 4, "screen": 112, "script": [4, 66, 105, 107, 108, 109, 111, 112, 113], "seafood": 103, "search": [4, 66, 112, 115], "second": [44, 51, 66, 75, 80, 81, 107, 113], "section": [55, 103, 112], "see": [15, 66, 103, 108, 112, 113], "seed": [4, 5, 6, 66, 88], "seek": 115, "seem": [94, 112], "select": [51, 113], "select_featur": 23, "select_lay": 23, "selected_dataset": 57, "self": [5, 6, 66, 89, 90, 91, 93, 94, 112], "sens": [103, 105, 108, 114], "sentenc": [4, 13, 16, 103, 105, 113, 114], "sep": 96, "sep2": 96, "sep_styl": [4, 96], "separ": [75, 81, 96, 106], "separatorstyl": 96, "seq_len": 100, "seqlen": 94, "seqlen_k": 94, "seqlen_q": 94, "seqlen_q_round": 94, "sequenc": [4, 13, 14, 16, 22, 51, 66, 75, 80, 81, 83, 87, 94, 103], "sequence_length": 22, "sequence_parallel": 94, "sequenceclassifieroutputwithpast": [16, 58], "seri": 112, "serv": [66, 103, 112, 115], "servic": [103, 108], "session": [66, 108], "set": [4, 5, 6, 13, 14, 32, 37, 42, 66, 69, 75, 88, 103, 105, 107, 108, 110, 112, 113, 114], "set_epoch": 66, "set_random_se": 88, "setback": 103, "setup": [66, 110, 112], "seventeenth": 112, "sever": [4, 13, 14, 66, 88, 103, 105, 106, 110], "sft": [105, 110], "sgd": [37, 42], "sgd_schedule_fre": [3, 4, 35], "sgdp": [3, 4, 35], "sgdschedulefre": 42, "sh": [105, 106, 107, 108, 109, 112, 113], "shall": [105, 115], "shape": [22, 61, 94], "sharded_ddp": 66, "share": [66, 112, 115], "sharegpt": [4, 103, 105], "shaw": 103, "she": 112, "sheet": 103, "shell": [73, 105], "shizh": [0, 115], "shop": 103, "should": [4, 11, 12, 13, 15, 16, 23, 32, 42, 66, 75, 80, 81, 94, 103, 105, 112], "show": [103, 110, 112, 113], "shrimp": 103, "shuffl": [5, 6, 88], "shum": [0, 115], "shun": 0, "sick": 112, "side": [4, 103, 112], "sigmoid": [4, 61], "sign_sgd": 4, "signific": [112, 113, 115], "sigopt": 66, "simclr": 37, "similar": [103, 107, 108, 112], "similarli": 106, "simpl": [1, 66, 103, 108, 112, 113, 115], "simplest": [112, 113], "simpli": [106, 112], "simplifi": [1, 52, 53, 55, 57, 113, 115], "sinc": [75, 103, 105, 108, 112], "singl": [13, 25, 26, 31, 32, 33, 34, 36, 37, 41, 42, 43, 45, 60, 66, 96, 103, 105, 109, 112, 113], "situat": [66, 103, 112], "sixteenth": 112, "size": [4, 22, 52, 66, 94, 103, 112, 113], "skill": 115, "skillet": 112, "skip": [73, 112], "skip_default": 73, "skip_first_batch": 66, "skip_next": 96, "skippabl": 101, "slight": [103, 113], "slightli": [94, 107, 114], "slow": [31, 43, 103], "slower": 94, "small": [94, 103, 113], "smaller": [103, 112], "smell": 103, "smoke": 103, "smokehous": 103, "smoother": 108, "smoothli": 112, "so": [7, 15, 66, 103, 105, 108, 112, 113, 114, 115], "social": 103, "societi": 112, "soda": 112, "softmax": 55, "softmax_scal": 94, "softwar": [105, 108, 112, 114], "sole": 115, "solid": 112, "solv": 103, "some": [4, 15, 52, 66, 103, 106, 112, 113, 115], "someon": 112, "someth": [61, 66, 103, 112, 113], "sometim": [103, 112], "soon": [105, 114], "sop": [105, 114], "sophia": [3, 4, 35], "sophiag": 44, "sorri": [103, 105], "sort": [103, 112], "soul": 103, "sourc": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 100, 101, 102, 104, 105, 112, 115], "source_dataset": 51, "sourdough": 103, "southern": 103, "sovereign": 103, "space": [66, 105, 112], "special": [13, 15, 16, 75, 105, 108, 112, 114, 115], "special_start": [75, 81, 108], "special_stopp": [75, 81, 108], "specif": [4, 103, 105, 112, 115], "specifi": [105, 106, 108, 109, 112], "speculativeinferenc": 55, "speed": 94, "speedi": 115, "spell": 113, "spend": 112, "sphinx": 3, "spice": 103, "spici": [103, 112], "spill": 94, "split": [5, 6, 66, 112, 113], "split_arg": 4, "spot": 103, "src": [108, 112], "stabl": 66, "stage": [60, 103], "stai": [103, 105, 109, 112], "stand": 103, "standard": [10, 11, 12, 15, 19, 20, 22, 37, 48, 69, 75], "start": [52, 66, 94, 105, 112, 113], "start_header_id": [105, 114], "start_n": 94, "start_of_turn": [105, 114], "starter": 108, "state": [25, 26, 30, 33, 37, 38, 39, 41, 44, 65, 66, 103, 112], "state_dict": [66, 98], "static": [16, 31, 43, 55, 66, 94], "step": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 66, 106, 108, 110, 112], "stepsiz": 25, "stew": 103, "stext": 112, "still": [60, 66, 94, 103, 112, 113, 115], "stochast": 44, "storag": 115, "store": [4, 94, 112], "store_flo": 66, "storm": 112, "str": [4, 5, 6, 7, 13, 14, 15, 16, 50, 51, 55, 56, 58, 60, 61, 66, 67, 69, 70, 71, 73, 75, 80, 81, 83, 87, 88, 96, 101, 112], "strand": 112, "strategi": [13, 14, 51, 112], "stream": 4, "stream_infer": 55, "streamlin": 115, "street": 103, "strictli": 103, "stride_bb": 94, "stride_bh": 94, "stride_bm": 94, "stride_dkb": 94, "stride_dkh": 94, "stride_dkn": 94, "stride_dob": 94, "stride_doh": 94, "stride_dom": 94, "stride_dqb": 94, "stride_dqh": 94, "stride_dqm": 94, "stride_dvb": 94, "stride_dvh": 94, "stride_dvn": 94, "stride_kb": 94, "stride_kh": 94, "stride_kn": 94, "stride_ob": 94, "stride_oh": 94, "stride_om": 94, "stride_qb": 94, "stride_qh": 94, "stride_qm": 94, "stride_vb": 94, "stride_vh": 94, "stride_vn": 94, "string": [4, 5, 6, 13, 14, 16, 22, 55, 66, 69, 73, 75, 88, 105, 108, 114], "stringformatt": [75, 108], "strip": [112, 114], "strong": 112, "stronger": 112, "strongest": 112, "strongli": 105, "structur": [5, 6, 50, 112, 113], "struggl": 103, "studi": [66, 112], "studio": 112, "stuf": 103, "stuff": [112, 113], "sturdier": [112, 113], "style": [96, 103], "sub": 103, "subarrai": 103, "subclass": [47, 49, 66], "subject": 115, "sublist_length": 58, "submit": 115, "subprocess": 73, "subsect": 112, "subtract": 51, "succe": 112, "success": 113, "suffer": 103, "sugar": 112, "suggest": [32, 42, 103, 112], "sum": [60, 66], "sum_": 52, "summar": 103, "summari": [11, 12, 66], "superior": 112, "superstit": 112, "supervis": [7, 110], "supervisor": 112, "support": [13, 14, 55, 75, 94, 106, 107, 110, 113], "supported_dataset_typ": 55, "suprem": 103, "sure": [75, 81, 94, 103, 105, 112, 113], "surfac": 113, "surpass": [103, 115], "surpris": 103, "surprisingli": 113, "surround": 112, "suspect": 112, "switch": [66, 112], "sy": [105, 111, 114], "synonym": 103, "sysinfo1": [75, 80, 81], "system": [75, 80, 81, 83, 87, 96, 105, 108, 114], "system_formatt": [75, 81, 108], "system_messag": 114, "system_propmt": 105, "t": [7, 15, 37, 60, 65, 66, 71, 94, 103, 105, 108, 112, 113, 114], "t3uwm8yp": 113, "tabl": [103, 106, 112], "taco": 103, "tag": [4, 66], "take": [13, 14, 52, 57, 66, 112], "talk": 112, "taller": [112, 113], "target": [7, 55, 66, 115], "target_cl": 56, "target_model_arg": [55, 56], "task": [1, 13, 14, 66, 103, 110, 112], "task_1": 106, "task_2": 106, "task_combin": 106, "task_guid": 103, "tast": 112, "teach": [112, 113, 115], "team": [105, 108, 114], "teaspoon": 112, "technic": 115, "techniqu": [105, 115], "technologi": 112, "tee": 106, "tell": [108, 112, 113], "temperatur": [4, 55, 61, 112], "templat": [4, 69, 75, 81], "template_nam": [75, 81, 108], "templatecompon": [75, 81, 108], "tend": [103, 112], "tensor": [4, 13, 16, 22, 33, 55, 60, 61, 66, 89, 90, 93], "tensor_parallel_s": 4, "term": [14, 15, 103, 112], "termin": [11, 12], "test": [5, 6, 52, 61, 66, 94, 103, 105, 107, 109, 112, 113, 115], "test_13": 105, "test_bleu": 66, "test_dataset": [5, 6, 66], "test_fil": 4, "test_flash_attn": 94, "test_flash_attn_triton_race_condit": 94, "test_siz": [5, 6], "text": [4, 7, 13, 14, 37, 52, 53, 55, 57, 88, 103, 105, 107, 108, 111, 112, 113, 114, 115], "text2text": [5, 70, 71, 106, 110], "text2text_dataset_descript": 74, "text2text_dataset_detail": 74, "text2text_dataset_long_descrit": 74, "text_onli": [5, 21, 55, 70, 71, 105, 106, 112], "text_only_dataset_descript": 74, "text_only_dataset_detail": 74, "text_only_dataset_long_descrit": 74, "text_regression_model": [3, 16, 17], "text_to_scored_textlist": 51, "text_to_scored_textlist_dataset_descript": 74, "text_to_textlist_dataset_descript": 74, "text_to_textlist_tokenize_funct": 71, "textonli": 110, "textregressionmodel": [16, 21], "th": 52, "than": [32, 42, 94, 103, 109, 112], "thank": 112, "thankfulli": 112, "thei": [4, 13, 16, 66, 103, 105, 108, 112, 113], "them": [66, 103, 105, 106, 107, 108, 112, 113, 115], "therefor": [112, 115], "theses": 112, "thi": [3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16, 32, 37, 42, 57, 60, 66, 75, 88, 94, 103, 105, 106, 108, 109, 112, 113, 114, 115], "thing": 112, "think": [112, 113], "thoma": 112, "thoroughli": 115, "those": [66, 103, 112], "thoughtfulli": 115, "three": [52, 61, 103, 105, 112], "threshold": 55, "thrive": 103, "through": [66, 103], "thu": [15, 103, 108], "tillet": 94, "time": [66, 103, 105, 112, 113], "tip": [66, 105], "titl": 115, "tmp": [4, 94], "tmp_trainer": 66, "to_dict": [5, 6], "to_gradio_chatbot": 96, "to_list": [5, 6], "todai": [108, 113], "todo": 111, "togeth": [53, 66, 112, 115], "tojson": 114, "tok_logg": [70, 71], "token": [3, 4, 7, 8, 13, 14, 15, 16, 22, 50, 52, 55, 57, 60, 61, 66, 67, 69, 75, 80, 81, 83, 87, 103, 105, 108, 111, 112, 113, 114], "token_dict": [70, 71], "token_id": 75, "token_per_step": 55, "token_type_id": 13, "tokenization_utils_bas": 66, "tokenize_batch_el": 60, "tokenize_funct": [70, 71], "tokenized_column_ord": [70, 71], "tokenized_dataset": [13, 14, 16, 53, 111], "tokenized_neg": 113, "tokenized_po": 113, "tokenizer_image_token": 7, "tokenizer_nam": 4, "told": 113, "tong": [0, 115], "too": [60, 103, 113], "tool": [75, 80, 81, 83, 87, 105, 108, 114, 115], "tool_1_desc": [75, 80, 81], "tool_description_1": 105, "tool_description_2": 105, "tool_description_3": 105, "tool_description_x": 105, "tool_info": 114, "toolbox": 115, "toolinferenc": 55, "toolkit": [103, 112, 115], "tools_formatt": [75, 81], "top": [4, 55, 103, 112, 113], "top_k": 4, "top_p": [4, 55], "top_reward_percentag": [4, 112], "torch": [7, 13, 15, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 55, 57, 61, 66, 88, 89, 90, 93, 94, 100], "torch_dtyp": [4, 15], "torch_jit_model_ev": 66, "tortilla": 103, "total": [103, 113], "touch": 112, "toxoplasmosi": 103, "tr_loss": 66, "track": [66, 105, 112], "tradeoff": 109, "tradit": [103, 105, 108, 112, 114], "trail": [13, 16], "train": [4, 5, 6, 13, 14, 32, 36, 37, 42, 44, 51, 53, 57, 59, 61, 65, 66, 88, 103, 105, 106, 109, 112, 113, 114, 115], "train_50": 105, "train_convers": 109, "train_dataset": [5, 6, 50, 51, 61, 66, 113], "train_ev": 61, "train_fil": 4, "train_on_prompt": 4, "train_test_split": [5, 6], "trainer": [57, 65, 66, 68], "trainer_callback": [61, 65, 66], "trainer_st": 66, "trainer_state_nam": 66, "trainer_util": [61, 66], "trainercallback": [61, 65, 66], "trainercontrol": 65, "trainerst": 65, "training_arg": [57, 65, 66], "training_args_nam": 66, "training_step": 66, "training_util": 66, "trainingargu": [4, 51, 61, 65, 66], "transform": [4, 7, 13, 14, 15, 16, 22, 51, 58, 60, 61, 65, 66, 67, 68, 70, 71, 75, 80, 81, 83, 87, 111], "transform_dataset_in_plac": [51, 53, 58, 59], "tri": 112, "trial": [65, 66, 103, 112], "tribul": 103, "trick": 108, "trim": [105, 114], "triton": 94, "triton_flash_attent": [3, 92], "trl": 61, "troubl": [103, 112], "truck": 103, "true": [4, 5, 6, 13, 14, 16, 25, 33, 51, 52, 53, 58, 59, 60, 61, 66, 67, 69, 73, 75, 88, 112, 113], "truncat": [4, 60, 113], "truncate_to_model_max_length": 4, "truncation_mod": [60, 61], "truncation_sid": [4, 70, 71], "trust_coeffici": 37, "trust_remote_cod": 4, "try": [75, 103, 112, 113], "tunabl": [3, 13, 14, 16, 18, 49], "tunable_model": 111, "tunablemodel": [52, 53, 55, 59, 111], "tune": [1, 7, 13, 14, 49, 53, 59, 66, 103, 105, 109, 111, 112, 113], "tune_strategi": [13, 14, 16], "tuned_model": 111, "tupl": [4, 22, 34, 51, 58, 61, 66, 75, 80, 81, 83, 87, 89, 90, 93, 101], "turn": [103, 112], "tweak": 66, "two": [51, 52, 66, 75, 96, 103, 106, 112, 113], "type": [4, 5, 6, 9, 21, 66, 75, 103, 105, 106, 108, 112, 113, 114, 115], "typeddict": 88, "typic": [11, 12, 61, 103, 112, 113], "u": [112, 115], "udpat": 22, "unabl": 103, "unclear": 113, "under": [4, 66, 103, 105, 106, 115], "understand": [103, 112, 115], "underw": 113, "unfair": 103, "unfinish": 112, "unfreez": 109, "uniform": 55, "union": [13, 16, 66, 73, 75], "unit": [75, 103, 112], "univers": 112, "unknown": 96, "unlock": 115, "unnecessari": 113, "unpack": 66, "unpleas": 103, "unseen": 115, "unsort": 103, "until": 112, "unus": 66, "unusu": 112, "up": [66, 94, 103, 112, 113], "upcom": 115, "updat": [66, 94, 105, 109, 112, 113, 114], "update_custom_config": 98, "update_hessian": 44, "upload": 66, "upscal": 103, "url": [66, 115], "us": [4, 5, 6, 10, 11, 12, 13, 14, 15, 16, 19, 20, 22, 32, 34, 41, 42, 48, 52, 55, 61, 66, 69, 73, 74, 75, 81, 88, 94, 103, 105, 106, 107, 109, 110, 112, 113, 114, 115], "usa": 103, "usag": [11, 12, 103], "use_acceler": [4, 13, 14, 15, 16], "use_accelerator_for_evalu": 4, "use_apex": 66, "use_beam_search": 4, "use_cach": [22, 89, 90, 91, 93], "use_cpu_amp": 66, "use_cuda_amp": 66, "use_customized_optim": 4, "use_dora": 4, "use_dpo_data_col": 61, "use_fast": 51, "use_fast_token": 4, "use_flash_attent": 4, "use_image_start_end": 4, "use_int8": 4, "use_lisa": 4, "use_lora": 4, "use_mtim": 66, "use_prompt_cach": [4, 22], "use_qlora": 4, "use_ram_optimized_load": [4, 106], "use_trunc": [70, 71], "use_tune_checkpoint": 66, "use_vllm": [4, 13, 15, 16, 58], "use_wandb": [4, 52], "user": [1, 75, 80, 81, 103, 105, 106, 108, 112, 113, 114, 115], "user_formatt": [75, 81, 108], "user_input_1": 105, "user_input_2": 105, "user_message_0": 114, "user_message_1": 114, "usernam": 106, "usml": 115, "usr_nam": 112, "usual": 103, "util": [3, 4, 7, 8, 13, 16, 54, 57, 58, 69, 70, 71, 103, 108, 113, 115], "v": [37, 51, 94, 108], "v_": 37, "valid": 66, "validation_fil": 4, "validation_split_percentag": [4, 112, 113], "valu": [4, 55, 66, 73, 75, 91, 106, 112], "value_1": [5, 6, 105], "value_2": [5, 6, 105], "value_3": 105, "varianc": 41, "variant": 33, "varieti": 103, "variou": [13, 14, 66, 105, 115], "ve": [94, 105, 112], "veget": [103, 112], "vegetarian": 103, "veloc": 37, "ventil": 103, "verbos": 52, "veri": [108, 112, 113], "verifi": [55, 115], "versa": 51, "version": [2, 3, 4, 8, 37, 41, 94, 95, 96, 103], "via": [4, 103, 112], "vibrant": 115, "vice": 51, "victorinox": 112, "vicuna": 103, "video": 112, "videogam": 112, "view_func": [31, 43], "vigil": 112, "virginia": 103, "viru": 103, "vision": 112, "vision2seq_model": [3, 17], "vision_encod": [3, 17], "vision_feature_select": 22, "vision_model_from_pretrain": 22, "vision_select_lay": 4, "vision_tow": 23, "vision_tower_cfg": [23, 24], "vision_tower_nam": 23, "visit": 103, "vismodelargu": 4, "visual": 112, "vllm": [4, 13, 15, 16, 69], "vllm_gpu_memory_util": [4, 15], "vllm_inferenc": [3, 54], "vllm_inference_batch_s": 4, "vllm_tensor_parallel_s": [4, 15], "vllminferenc": 69, "vllminferenceresultwithinput": [13, 69, 88], "vocabulari": 103, "w_": 52, "w_i": 52, "wa": [33, 103, 112, 113], "wai": [10, 11, 12, 15, 19, 20, 22, 48, 66, 69, 75, 103, 105, 106, 107, 112, 113], "wait": 103, "walnut": 103, "wandb": [4, 113], "want": [66, 106, 108, 112, 113], "warmup": [32, 42], "warmup_step": [4, 32, 42], "warn": 66, "washington": 103, "wat": 103, "watch": 66, "wd_ratio": [31, 43], "we": [51, 60, 61, 66, 75, 94, 103, 105, 106, 108, 110, 111, 112, 113, 114, 115], "weather": [105, 112], "wei": [0, 115], "weight": [4, 31, 37, 43, 52, 115], "weight_decai": [4, 25, 26, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45], "weight_decoupl": 25, "weight_lr_pow": [32, 42], "weixiong5237": 113, "welcom": [112, 115], "well": [66, 103, 105, 112, 115], "weqweasda": 112, "were": [112, 113], "what": [108, 112, 113], "when": [4, 13, 16, 32, 42, 51, 55, 66, 69, 73, 75, 103, 108, 112, 113], "whenev": 113, "where": [4, 5, 6, 13, 37, 52, 69, 103, 105, 112, 113, 115], "whether": [4, 7, 13, 14, 16, 66, 69, 73, 112, 115], "which": [4, 5, 6, 13, 14, 47, 49, 52, 60, 66, 75, 103, 105, 112, 113, 115], "while": [66, 75, 94, 103, 115], "white": 103, "who": [105, 108, 112, 114, 115], "whole": 115, "whose": 112, "why": [108, 112], "wide": [103, 115], "width": 22, "wild": 113, "willing": 112, "window": [103, 112], "window_length": 52, "winogrand": 103, "wipe": 66, "wise": 37, "wish": 66, "witch": 112, "witchcraft": 112, "with_deepspe": 14, "with_qform": [4, 22], "within": [55, 108], "without": [13, 16, 66, 103, 112, 113, 114], "won": 112, "word": [103, 108, 112, 113], "wordi": 113, "work": [66, 94, 103, 112, 113, 115], "worker_heart_beat_interv": 74, "workflow": 115, "workspace_path": 56, "world": [13, 103, 112, 113], "world_siz": [52, 55, 58], "wors": 112, "worst": 51, "would": [13, 69, 94, 103, 108, 112, 113], "wrap": 66, "wrapper": [13, 14, 66], "write": [52, 103, 113], "w\u00fcsthof": 112, "x": [31, 43, 100, 103, 112, 113], "xiong": [0, 115], "xiongwei": 112, "y": [31, 43, 106, 115], "ye": [103, 112, 113], "year": [103, 112, 113, 115], "yet": [13, 14, 60, 75, 94], "yi": [3, 81, 105], "yi1_5": 105, "yi1_5_templ": [81, 86], "yogi": [3, 4, 35], "you": [32, 42, 66, 75, 94, 103, 105, 106, 107, 108, 112, 113, 114, 115], "your": [66, 110, 112, 113, 114], "your_conversation_dataset": 108, "your_model": 108, "your_templ": 108, "your_template_fil": 108, "your_template_nam": 108, "yourself": 103, "zephyr": [3, 81, 105], "zephyr_templ": [81, 87], "zephyrconversationtempl": 87, "zero": 66, "zhang": [0, 115]}, "titles": ["Contributors", "Changelog", "About", "API Reference", "lmflow.args", "lmflow.datasets.dataset", "lmflow.datasets", "lmflow.datasets.multi_modal_dataset", "lmflow", "lmflow.models.auto_model", "lmflow.models.base_model", "lmflow.models.decoder_model", "lmflow.models.encoder_decoder_model", "lmflow.models.hf_decoder_model", "lmflow.models.hf_encoder_decoder_model", "lmflow.models.hf_model_mixin", "lmflow.models.hf_text_regression_model", "lmflow.models", "lmflow.models.interfaces", "lmflow.models.interfaces.tunable", "lmflow.models.regression_model", "lmflow.models.text_regression_model", "lmflow.models.vision2seq_model", "lmflow.models.vision_encoder.clip_encoder", "lmflow.models.vision_encoder", "lmflow.optim.adabelief", "lmflow.optim.adabound", "lmflow.optim.adadelta", "lmflow.optim.adagrad", "lmflow.optim.adam", "lmflow.optim.adamax", "lmflow.optim.adamp", "lmflow.optim.adamw_schedule_free", "lmflow.optim.adan", "lmflow.optim.dummy", "lmflow.optim", "lmflow.optim.lamb", "lmflow.optim.lars", "lmflow.optim.nadam", "lmflow.optim.novograd", "lmflow.optim.optimizers", "lmflow.optim.radam", "lmflow.optim.sgd_schedule_free", "lmflow.optim.sgdp", "lmflow.optim.sophia", "lmflow.optim.yogi", "lmflow.pipeline.auto_pipeline", "lmflow.pipeline.base_aligner", "lmflow.pipeline.base_pipeline", "lmflow.pipeline.base_tuner", "lmflow.pipeline.dpo_aligner", "lmflow.pipeline.dpov2_aligner", "lmflow.pipeline.evaluator", "lmflow.pipeline.finetuner", "lmflow.pipeline", "lmflow.pipeline.inferencer", "lmflow.pipeline.iterative_dpo_aligner", "lmflow.pipeline.raft_aligner", "lmflow.pipeline.rm_inferencer", "lmflow.pipeline.rm_tuner", "lmflow.pipeline.utils.dpov2_dataprocessor", "lmflow.pipeline.utils.dpov2_trainer", "lmflow.pipeline.utils", "lmflow.pipeline.utils.memory_safe_dpov2_align", "lmflow.pipeline.utils.memory_safe_vllm_inference", "lmflow.pipeline.utils.peft_trainer", "lmflow.pipeline.utils.raft_trainer", "lmflow.pipeline.utils.rm_dataprocessor", "lmflow.pipeline.utils.rm_trainer", "lmflow.pipeline.vllm_inferencer", "lmflow.tokenization.hf_decoder_model", "lmflow.tokenization.hf_text_regression_model", "lmflow.tokenization", "lmflow.utils.common", "lmflow.utils.constants", "lmflow.utils.conversation_template.base", "lmflow.utils.conversation_template.chatglm", "lmflow.utils.conversation_template.chatml", "lmflow.utils.conversation_template.deepseek", "lmflow.utils.conversation_template.gemma", "lmflow.utils.conversation_template.hymba", "lmflow.utils.conversation_template", "lmflow.utils.conversation_template.internlm", "lmflow.utils.conversation_template.llama", "lmflow.utils.conversation_template.phi", "lmflow.utils.conversation_template.qwen", "lmflow.utils.conversation_template.yi", "lmflow.utils.conversation_template.zephyr", "lmflow.utils.data_utils", "lmflow.utils.flash_attention.bloom_flash_attention", "lmflow.utils.flash_attention.gpt2_flash_attention", "lmflow.utils.flash_attention.gpt_neo_flash_attention", "lmflow.utils.flash_attention", "lmflow.utils.flash_attention.llama_flash_attention", "lmflow.utils.flash_attention.triton_flash_attention", "lmflow.utils", "lmflow.utils.llava_conversation_lib", "lmflow.utils.model", "lmflow.utils.multimodal", "lmflow.utils.position_interpolation", "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch", "lmflow.utils.versioning", "lmflow.version", "LMFlow Benchmark: An Automatic Evaluation Framework for Open-Source LLMs", "Blogs", "Dataset", "LMFlow Benchmark Guide", "Checkpoints", "Customize Conversation Template", "Finetuning", "Examples", "Finetune", "RAFT", "Reward Modeling", "Supported Conversation Template", "LMFlow"], "titleterms": {"0": 1, "1": [1, 106, 108, 112, 113, 114], "2": [106, 108, 112, 113, 114], "2023": [1, 104], "28": 1, "3": [108, 112, 114], "4": 108, "5": [108, 114], "8x22b": 114, "8x7b": 114, "about": 2, "adabelief": 25, "adabound": 26, "adadelta": 27, "adagrad": 28, "adam": 29, "adamax": 30, "adamp": 31, "adamw": 109, "adamw_schedule_fre": 32, "adan": 33, "adapt": 109, "algorithm": 112, "align": 112, "an": 103, "api": 3, "arg": 4, "attribut": [4, 5, 8, 13, 14, 15, 16, 46, 51, 53, 55, 56, 57, 58, 59, 60, 61, 63, 64, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 94, 96, 97, 101, 102], "auto_model": 9, "auto_pipelin": 46, "automat": 103, "base": 75, "base_align": 47, "base_model": 10, "base_pipelin": 48, "base_tun": 49, "benchmark": [103, 106], "blog": 104, "bloom_flash_attent": 89, "build": 108, "changelog": 1, "chat": 103, "chatglm": [76, 114], "chatml": [77, 114], "checkpoint": [107, 115], "choos": 108, "citat": 115, "class": [4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 65, 66, 67, 68, 69, 75, 79, 80, 81, 83, 87, 88, 94, 96, 100], "clip_encod": 23, "common": 73, "commonsens": 103, "conclus": 103, "constant": 74, "content": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 100, 101, 102, 115], "contributor": 0, "convers": [105, 108, 109, 114], "conversation_templ": [75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87], "creat": 106, "custom": [105, 108], "data": [105, 110], "data_util": 88, "dataset": [5, 6, 7, 105, 106, 112], "decoder_model": 11, "decompos": 108, "deepseek": [78, 114], "descript": 112, "detail": 105, "disclaim": 115, "dpo_align": 50, "dpov2_align": 51, "dpov2_dataprocessor": 60, "dpov2_train": 61, "dummi": 34, "encoder_decoder_model": 12, "end": 112, "evalu": [52, 103, 106, 110], "exampl": [110, 112, 113], "featur": 115, "file": 106, "finetun": [53, 109, 110, 111, 112, 113], "flash_attent": [89, 90, 91, 92, 93, 94], "follow": 103, "format": 105, "formatt": 108, "framework": 103, "full": 109, "function": [4, 6, 7, 23, 24, 33, 50, 55, 63, 64, 68, 70, 71, 73, 88, 89, 90, 91, 93, 94, 97, 98, 100, 101], "gemma": [79, 114], "gener": 105, "get": 112, "gpt2_flash_attent": 90, "gpt_neo_flash_attent": 91, "guid": 106, "hf_decoder_model": [13, 70], "hf_encoder_decoder_model": 14, "hf_model_mixin": 15, "hf_text_regression_model": [16, 71], "hymba": [80, 114], "hyper": 112, "import": 109, "indic": 115, "infer": 110, "inferenc": 55, "instal": 115, "instruct": [103, 115], "interfac": [18, 19], "internlm": 82, "internlm2": 114, "introduct": [103, 112, 113, 115], "iterative_dpo_align": 56, "lamb": 36, "lar": 37, "layerwis": 109, "lisa": 109, "llama": [83, 107, 114], "llama_flash_attent": 93, "llama_rope_scaled_monkey_patch": 100, "llava_conversation_lib": 96, "llm": 103, "lm": 106, "lmflow": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 115], "lora": [109, 112], "low": 109, "mar": 1, "memory_safe_dpov2_align": 63, "memory_safe_vllm_infer": 64, "merg": [109, 112], "metric": 103, "mixtral": 114, "model": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 97, 112, 113], "modul": [4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 100, 101, 102], "multi_modal_dataset": 7, "multimod": 98, "nadam": 38, "nll": 106, "note": 112, "notic": 114, "novograd": 39, "open": 103, "optim": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45], "overview": 112, "packag": [6, 8, 24, 81], "pair": 105, "paramet": [109, 112], "peft_train": 65, "perform": 103, "phi": [84, 114], "pipelin": [46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "position_interpol": [99, 100], "prepar": 110, "progress": [105, 114], "proper": 108, "qwen": [85, 114], "radam": 41, "raft": 112, "raft_align": 57, "raft_train": 66, "rank": 109, "refer": [3, 103], "regist": 108, "registr": 106, "regression_model": 20, "return": 15, "reward": [112, 113], "rm_dataprocessor": 67, "rm_inferenc": 58, "rm_trainer": 68, "rm_tuner": 59, "sampl": 109, "set": 106, "setup": 106, "sft": [112, 113], "sgd_schedule_fre": 42, "sgdp": 43, "sophia": 44, "sourc": 103, "step": 113, "submodul": [6, 8, 17, 18, 24, 35, 54, 62, 72, 81, 92, 95, 99], "supervis": [112, 113], "support": [105, 114, 115], "tabl": 115, "task": [106, 115], "templat": [105, 108, 109, 114], "text2text": 105, "text_regression_model": 21, "textonli": 105, "token": [70, 71, 72], "triton_flash_attent": 94, "tunabl": 19, "tune": 115, "us": 108, "util": [60, 61, 62, 63, 64, 65, 66, 67, 68, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101], "version": [1, 101, 102], "vision": 115, "vision2seq_model": 22, "vision_encod": [23, 24], "vllm_inferenc": 69, "weight": 109, "work": [105, 114], "yi": [86, 114], "yogi": 45, "your": [106, 108], "zephyr": [87, 114]}})